{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0a12cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "%pip install opendatasets pandas numpy legacy-cgi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb7ae6d3-1d64-4cfe-b289-bfba11f00a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TroTro Dataset Cleaning and Analysis ===\n",
      "Starting analysis at: 2025-08-11 02:56:13\n",
      "Downloading dataset...\n",
      "Skipping, found downloaded files in \".\\trotro\" (use force=True to force download)\n",
      "✓ Dataset downloaded successfully\n",
      "Using data directory: ./trotro/trotrolive-datasets\n",
      "Found 110 TXT files.\n",
      "\n",
      "==================================================\n",
      "Processing: abidjan\\agency.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (25, 8)\n",
      "\n",
      "Cleaning data for abidjan\\agency.txt...\n",
      "  - Converted 'agency_timezone' to datetime\n",
      "  ✓ Cleaned data shape: (25, 8) → (25, 4)\n",
      "\n",
      "--- Analysis for abidjan\\agency.txt ---\n",
      "Shape: (25, 4)\n",
      "Memory usage: 0.01 MB\n",
      "\n",
      "Missing values:\n",
      "agency_timezone    25\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "object            3\n",
      "datetime64[ns]    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "agency_id:\n",
      "agency_id\n",
      "Gbaka d'Abobo           1\n",
      "Gbaka d'Adjamé          1\n",
      "Gbaka d'Attécoubé       1\n",
      "Gbaka de Bingerville    1\n",
      "Gbaka de Cocody         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_name:\n",
      "agency_name\n",
      "Woro-woro d'Attécoubé    3\n",
      "Gbaka d'Adjamé           1\n",
      "Gbaka d'Abobo            1\n",
      "Gbaka de Bingerville     1\n",
      "Gbaka de Cocody          1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_url:\n",
      "agency_url\n",
      "https://data-transport.org    25\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "              agency_id           agency_name agency_timezone  \\\n",
      "0         Gbaka d'Abobo         Gbaka d'Abobo             NaT   \n",
      "1        Gbaka d'Adjamé        Gbaka d'Adjamé             NaT   \n",
      "2     Gbaka d'Attécoubé     Gbaka d'Attécoubé             NaT   \n",
      "3  Gbaka de Bingerville  Gbaka de Bingerville             NaT   \n",
      "4       Gbaka de Cocody       Gbaka de Cocody             NaT   \n",
      "\n",
      "                   agency_url  \n",
      "0  https://data-transport.org  \n",
      "1  https://data-transport.org  \n",
      "2  https://data-transport.org  \n",
      "3  https://data-transport.org  \n",
      "4  https://data-transport.org  \n",
      "✓ Saved cleaned data to: cleaned_data\\abidjan\\cleaned_agency.csv\n",
      "\n",
      "==================================================\n",
      "Processing: abidjan\\calendar.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 10)\n",
      "\n",
      "Cleaning data for abidjan\\calendar.txt...\n",
      "  - Converted 'start_date' to datetime\n",
      "  - Converted 'end_date' to datetime\n",
      "  ✓ Cleaned data shape: (1, 10) → (1, 10)\n",
      "\n",
      "--- Analysis for abidjan\\calendar.txt ---\n",
      "Shape: (1, 10)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64             7\n",
      "datetime64[ns]    2\n",
      "object            1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       monday  tuesday  wednesday  thursday  friday  saturday  sunday\n",
      "count     1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "mean      1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "std       NaN      NaN        NaN       NaN     NaN       NaN     NaN\n",
      "min       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "25%       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "50%       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "75%       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "max       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "service_id:\n",
      "service_id\n",
      "Mo-Su    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  service_id  monday  tuesday  wednesday  thursday  friday  saturday  sunday  \\\n",
      "0      Mo-Su       1        1          1         1       1         1       1   \n",
      "\n",
      "                     start_date                      end_date  \n",
      "0 1970-01-01 00:00:00.020230101 1970-01-01 00:00:00.020231231  \n",
      "✓ Saved cleaned data to: cleaned_data\\abidjan\\cleaned_calendar.csv\n",
      "\n",
      "==================================================\n",
      "Processing: abidjan\\calendar_dates.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (0, 3)\n",
      "⚠ Warning: abidjan\\calendar_dates.txt could not be parsed into multiple columns\n",
      "\n",
      "==================================================\n",
      "Processing: abidjan\\fare_attributes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (0, 7)\n",
      "⚠ Warning: abidjan\\fare_attributes.txt could not be parsed into multiple columns\n",
      "\n",
      "==================================================\n",
      "Processing: abidjan\\fare_rules.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (0, 5)\n",
      "⚠ Warning: abidjan\\fare_rules.txt could not be parsed into multiple columns\n",
      "\n",
      "==================================================\n",
      "Processing: abidjan\\feed_info.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 9)\n",
      "\n",
      "Cleaning data for abidjan\\feed_info.txt...\n",
      "  - Converted 'feed_start_date' to datetime\n",
      "  - Converted 'feed_end_date' to datetime\n",
      "  ✓ Cleaned data shape: (1, 9) → (1, 8)\n",
      "\n",
      "--- Analysis for abidjan\\feed_info.txt ---\n",
      "Shape: (1, 8)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object            5\n",
      "datetime64[ns]    2\n",
      "float64           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       feed_version\n",
      "count           1.0\n",
      "mean            0.1\n",
      "std             NaN\n",
      "min             0.1\n",
      "25%             0.1\n",
      "50%             0.1\n",
      "75%             0.1\n",
      "max             0.1\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "feed_publisher_name:\n",
      "feed_publisher_name\n",
      "Data Transport    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_publisher_url:\n",
      "feed_publisher_url\n",
      "http://data-transport.org    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_lang:\n",
      "feed_lang\n",
      "fr    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_contact_email:\n",
      "feed_contact_email\n",
      "labs@data-transport.org    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_contact_url:\n",
      "feed_contact_url\n",
      "http://data-transport.org    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  feed_publisher_name         feed_publisher_url feed_lang  \\\n",
      "0      Data Transport  http://data-transport.org        fr   \n",
      "\n",
      "                feed_start_date                 feed_end_date  feed_version  \\\n",
      "0 1970-01-01 00:00:00.020230101 1970-01-01 00:00:00.020231231           0.1   \n",
      "\n",
      "        feed_contact_email           feed_contact_url  \n",
      "0  labs@data-transport.org  http://data-transport.org  \n",
      "✓ Saved cleaned data to: cleaned_data\\abidjan\\cleaned_feed_info.csv\n",
      "\n",
      "==================================================\n",
      "Processing: abidjan\\frequencies.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1076, 5)\n",
      "\n",
      "Cleaning data for abidjan\\frequencies.txt...\n",
      "  - Converted 'start_time' to datetime\n",
      "  - Converted 'end_time' to datetime\n",
      "  - Converted 'exact_times' to datetime\n",
      "  - Capped 18 outliers in 'headway_secs'\n",
      "  ✓ Cleaned data shape: (1076, 5) → (1076, 5)\n",
      "\n",
      "--- Analysis for abidjan\\frequencies.txt ---\n",
      "Shape: (1076, 5)\n",
      "Memory usage: 0.04 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "datetime64[ns]    3\n",
      "int64             2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "          trip_id  headway_secs\n",
      "count  1076.00000   1076.000000\n",
      "mean    458.89777   1251.500000\n",
      "std     290.82871    982.664719\n",
      "min       0.00000    120.000000\n",
      "25%     200.75000    600.000000\n",
      "50%     441.50000    900.000000\n",
      "75%     710.25000   1800.000000\n",
      "max     979.00000   3600.000000\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   trip_id          start_time            end_time  headway_secs exact_times\n",
      "0        0 2025-08-11 05:00:00 2025-08-11 22:00:00           900  1970-01-01\n",
      "1        1 2025-08-11 05:00:00 2025-08-11 22:00:00           900  1970-01-01\n",
      "2       10 2025-08-11 05:00:00 2025-08-11 22:00:00           600  1970-01-01\n",
      "3      100 2025-08-11 05:00:00 2025-08-11 22:00:00           420  1970-01-01\n",
      "4      101 2025-08-11 05:00:00 2025-08-11 22:00:00           420  1970-01-01\n",
      "✓ Saved cleaned data to: cleaned_data\\abidjan\\cleaned_frequencies.csv\n",
      "\n",
      "==================================================\n",
      "Processing: abidjan\\levels.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (0, 3)\n",
      "⚠ Warning: abidjan\\levels.txt could not be parsed into multiple columns\n",
      "\n",
      "==================================================\n",
      "Processing: abidjan\\pathways.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (0, 12)\n",
      "⚠ Warning: abidjan\\pathways.txt could not be parsed into multiple columns\n",
      "\n",
      "==================================================\n",
      "Processing: abidjan\\routes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (490, 12)\n",
      "\n",
      "Cleaning data for abidjan\\routes.txt...\n",
      "  ✓ Cleaned data shape: (490, 12) → (490, 6)\n",
      "\n",
      "--- Analysis for abidjan\\routes.txt ---\n",
      "Shape: (490, 6)\n",
      "Memory usage: 0.18 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object    4\n",
      "int64     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "           route_id  route_type\n",
      "count  4.900000e+02       490.0\n",
      "mean   1.334756e+07         3.0\n",
      "std    2.032172e+06         0.0\n",
      "min    1.017901e+07         3.0\n",
      "25%    1.158108e+07         3.0\n",
      "50%    1.349794e+07         3.0\n",
      "75%    1.534721e+07         3.0\n",
      "max    1.582049e+07         3.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "agency_id:\n",
      "agency_id\n",
      "Woro-woro de Cocody      87\n",
      "Woro-woro Banalisé       85\n",
      "Gbaka d'Adjamé           65\n",
      "Woro-woro de Yopougon    58\n",
      "Gbaka d'Abobo            37\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_long_name:\n",
      "route_long_name\n",
      "gbaka : Adjamé Liberté ↔ Treichville Gare de Bassam    1\n",
      "gbaka : Adjamé ↔ Abobo Gare Mairie                     1\n",
      "gbaka : Adjamé Liberté ↔ Abobo Gare Mairie             1\n",
      "gbaka : Abobo Gare Mairie ↔Akeïkoi Village             1\n",
      "gbaka : Abobo Gare Mairie ↔ Kennedy Marché             1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_color:\n",
      "route_color\n",
      "1779C2    490\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_text_color:\n",
      "route_text_color\n",
      "FFFFFF    490\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "        agency_id  route_id  route_type  \\\n",
      "0  Gbaka d'Adjamé  10179006           3   \n",
      "1   Gbaka d'Abobo  10179435           3   \n",
      "2   Gbaka d'Abobo  10184139           3   \n",
      "3   Gbaka d'Abobo  10184730           3   \n",
      "4   Gbaka d'Abobo  10184964           3   \n",
      "\n",
      "                                     route_long_name route_color  \\\n",
      "0  gbaka : Adjamé Liberté ↔ Treichville Gare de B...      1779C2   \n",
      "1                 gbaka : Adjamé ↔ Abobo Gare Mairie      1779C2   \n",
      "2         gbaka : Adjamé Liberté ↔ Abobo Gare Mairie      1779C2   \n",
      "3         gbaka : Abobo Gare Mairie ↔Akeïkoi Village      1779C2   \n",
      "4         gbaka : Abobo Gare Mairie ↔ Kennedy Marché      1779C2   \n",
      "\n",
      "  route_text_color  \n",
      "0           FFFFFF  \n",
      "1           FFFFFF  \n",
      "2           FFFFFF  \n",
      "3           FFFFFF  \n",
      "4           FFFFFF  \n",
      "✓ Saved cleaned data to: cleaned_data\\abidjan\\cleaned_routes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: abidjan\\shapes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (74504, 4)\n",
      "\n",
      "Cleaning data for abidjan\\shapes.txt...\n",
      "  - Capped 9063 outliers in 'shape_pt_lat'\n",
      "  - Capped 3391 outliers in 'shape_pt_lon'\n",
      "  - Capped 1440 outliers in 'shape_pt_sequence'\n",
      "  ✓ Cleaned data shape: (74504, 4) → (74504, 4)\n",
      "\n",
      "--- Analysis for abidjan\\shapes.txt ---\n",
      "Shape: (74504, 4)\n",
      "Memory usage: 2.27 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64      2\n",
      "float64    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "           shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence\n",
      "count  7.450400e+04  74504.000000  74504.000000       74504.000000\n",
      "mean   1.361995e+07      5.351968     -4.011938          59.320775\n",
      "std    2.144032e+06      0.032583      0.046324          48.859261\n",
      "min    1.017867e+07      5.283110     -4.131610           0.000000\n",
      "25%    1.156933e+07      5.332025     -4.042980          19.000000\n",
      "50%    1.508844e+07      5.353904     -4.014915          46.000000\n",
      "75%    1.541301e+07      5.364635     -3.983893          89.000000\n",
      "max    1.582049e+07      5.413550     -3.895263         194.000000\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence\n",
      "0  10178669      5.353258     -4.014545                  0\n",
      "1  10178669      5.353220     -4.014481                  1\n",
      "2  10178669      5.353076     -4.014356                  2\n",
      "3  10178669      5.352920     -4.014262                  3\n",
      "4  10178669      5.352342     -4.014083                  4\n",
      "✓ Saved cleaned data to: cleaned_data\\abidjan\\cleaned_shapes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: abidjan\\stops.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (4834, 14)\n",
      "\n",
      "Cleaning data for abidjan\\stops.txt...\n",
      "  - Capped 163 outliers in 'stop_lat'\n",
      "  - Capped 122 outliers in 'stop_lon'\n",
      "  ✓ Cleaned data shape: (4834, 14) → (4834, 4)\n",
      "\n",
      "--- Analysis for abidjan\\stops.txt ---\n",
      "Shape: (4834, 4)\n",
      "Memory usage: 0.77 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object     2\n",
      "float64    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "          stop_lat     stop_lon\n",
      "count  4834.000000  4834.000000\n",
      "mean      5.358113    -3.999570\n",
      "std       0.050646     0.067331\n",
      "min       5.238013    -4.180979\n",
      "25%       5.327884    -4.050139\n",
      "50%       5.355141    -4.004590\n",
      "75%       5.387798    -3.962913\n",
      "max       5.477670    -3.832073\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "stop_id:\n",
      "stop_id\n",
      "node/10218963489    1\n",
      "node/10218963490    1\n",
      "node/10218963491    1\n",
      "node/10218963492    1\n",
      "node/10218963494    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "stop_name:\n",
      "stop_name\n",
      "Carrefour Marché     40\n",
      "Carrefour Mosquée    29\n",
      "Boulangerie          25\n",
      "Garage               22\n",
      "Lavage               20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "            stop_id            stop_name  stop_lat  stop_lon\n",
      "0  node/10218963489           Chez Rifat  5.349222 -3.975893\n",
      "1  node/10218963490     Carrefour garage  5.347851 -3.975529\n",
      "2  node/10218963491    Gorille carrefour  5.346528 -3.975153\n",
      "3  node/10218963492     Carrefour lavage  5.345986 -3.974986\n",
      "4  node/10218963494  Carrefour chefferie  5.341507 -3.974229\n",
      "✓ Saved cleaned data to: cleaned_data\\abidjan\\cleaned_stops.csv\n",
      "\n",
      "==================================================\n",
      "Processing: abidjan\\stop_times.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (15683, 11)\n",
      "\n",
      "Cleaning data for abidjan\\stop_times.txt...\n",
      "  - Converted 'arrival_time' to datetime\n",
      "  - Converted 'departure_time' to datetime\n",
      "  - Converted 'timepoint' to datetime\n",
      "  - Capped 501 outliers in 'stop_sequence'\n",
      "  ✓ Cleaned data shape: (15683, 11) → (15683, 6)\n",
      "\n",
      "--- Analysis for abidjan\\stop_times.txt ---\n",
      "Shape: (15683, 6)\n",
      "Memory usage: 1.68 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "datetime64[ns]    3\n",
      "int64             2\n",
      "object            1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "            trip_id  stop_sequence\n",
      "count  15683.000000   15683.000000\n",
      "mean     513.637059      12.968820\n",
      "std      297.657314      10.524426\n",
      "min        0.000000       0.000000\n",
      "25%      256.000000       5.000000\n",
      "50%      560.000000      10.000000\n",
      "75%      769.000000      19.000000\n",
      "max      979.000000      40.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "stop_id:\n",
      "stop_id\n",
      "node/7052366501    27\n",
      "node/7055147058    24\n",
      "node/7054787060    24\n",
      "node/7052366502    24\n",
      "node/7098748084    23\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   trip_id           stop_id  stop_sequence        arrival_time  \\\n",
      "0        0  node/10591673049              7 2025-08-11 07:49:56   \n",
      "1        0  node/10591673050              6 2025-08-11 07:45:08   \n",
      "2        0  node/10591673051              4 2025-08-11 07:38:38   \n",
      "3        0  node/10855579565              3 2025-08-11 07:37:14   \n",
      "4        0  node/10863748340             11 2025-08-11 08:00:00   \n",
      "\n",
      "       departure_time  timepoint  \n",
      "0 2025-08-11 07:49:56 1970-01-01  \n",
      "1 2025-08-11 07:45:08 1970-01-01  \n",
      "2 2025-08-11 07:38:38 1970-01-01  \n",
      "3 2025-08-11 07:37:14 1970-01-01  \n",
      "4 2025-08-11 08:00:00 1970-01-01  \n",
      "✓ Saved cleaned data to: cleaned_data\\abidjan\\cleaned_stop_times.csv\n",
      "\n",
      "==================================================\n",
      "Processing: abidjan\\transfers.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (0, 4)\n",
      "⚠ Warning: abidjan\\transfers.txt could not be parsed into multiple columns\n",
      "\n",
      "==================================================\n",
      "Processing: abidjan\\trips.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (980, 10)\n",
      "\n",
      "Cleaning data for abidjan\\trips.txt...\n",
      "  ✓ Cleaned data shape: (980, 10) → (980, 6)\n",
      "\n",
      "--- Analysis for abidjan\\trips.txt ---\n",
      "Shape: (980, 6)\n",
      "Memory usage: 0.16 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64     4\n",
      "object    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "           route_id      shape_id     trip_id  direction_id\n",
      "count  9.800000e+02  9.800000e+02  980.000000    980.000000\n",
      "mean   1.334756e+07  1.334893e+07  489.500000      0.500000\n",
      "std    2.031134e+06  2.027481e+06  283.045933      0.500255\n",
      "min    1.017901e+07  1.017867e+07    0.000000      0.000000\n",
      "25%    1.158107e+07  1.158111e+07  244.750000      0.000000\n",
      "50%    1.349794e+07  1.349807e+07  489.500000      0.500000\n",
      "75%    1.534722e+07  1.534717e+07  734.250000      1.000000\n",
      "max    1.582049e+07  1.582049e+07  979.000000      1.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "service_id:\n",
      "service_id\n",
      "Mo-Su    980\n",
      "Name: count, dtype: int64\n",
      "\n",
      "trip_headsign:\n",
      "trip_headsign\n",
      "Adjamé Liberté     12\n",
      "Palmeraie          12\n",
      "Mairie d'Adjamé    11\n",
      "Abobo Gare         11\n",
      "Riviera 2          11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   route_id service_id  shape_id  trip_id               trip_headsign  \\\n",
      "0  10179006      Mo-Su  10178669        0  Treichville Gare de Bassam   \n",
      "1  10179006      Mo-Su  10178996        1              Adjamé Liberté   \n",
      "2  10185142      Mo-Su  10185123       10                 Mosquée Ado   \n",
      "3  10461146      Mo-Su  10474251      100          Angré Petro Ivoire   \n",
      "4  10461146      Mo-Su  10474250      101                  Abobo Gare   \n",
      "\n",
      "   direction_id  \n",
      "0             0  \n",
      "1             1  \n",
      "2             0  \n",
      "3             0  \n",
      "4             1  \n",
      "✓ Saved cleaned data to: cleaned_data\\abidjan\\cleaned_trips.csv\n",
      "\n",
      "==================================================\n",
      "Processing: accra\\agency.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (91, 4)\n",
      "\n",
      "Cleaning data for accra\\agency.txt...\n",
      "  - Converted 'agency_timezone' to datetime\n",
      "  ✓ Cleaned data shape: (91, 4) → (91, 4)\n",
      "\n",
      "--- Analysis for accra\\agency.txt ---\n",
      "Shape: (91, 4)\n",
      "Memory usage: 0.02 MB\n",
      "\n",
      "Missing values:\n",
      "agency_timezone    91\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "object            2\n",
      "int64             1\n",
      "datetime64[ns]    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "        agency_id\n",
      "count   91.000000\n",
      "mean    51.725275\n",
      "std     30.269554\n",
      "min      0.000000\n",
      "25%     25.500000\n",
      "50%     54.000000\n",
      "75%     78.500000\n",
      "max    101.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "agency_name:\n",
      "agency_name\n",
      "East Legon-La Bawaleshie-M-A-S-A GPRTU                         3\n",
      "Lapaz Branch of Tiger Transport Services Association           2\n",
      "Abeka Lapaz Highway (GPRTU)                                    1\n",
      "Abeka Lapaz Circle Accra Local of Abeka Branch of G.P.R.T.U    1\n",
      "Abeka Trotro Branch of GPRTU                                   1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_url:\n",
      "agency_url\n",
      "https://en.wikipedia.org/wiki/Ghana_Private_Road_Transport_Union    91\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   agency_id                                        agency_name  \\\n",
      "0          0             East Legon-La Bawaleshie-M-A-S-A GPRTU   \n",
      "1          1  Abeka Lapaz Circle Accra Local of Abeka Branch...   \n",
      "2          2                        Abeka Lapaz Highway (GPRTU)   \n",
      "3          3  Abeka Lapaz Madina Adenta (Novotel) Branch of ...   \n",
      "4          4                       Abeka Trotro Branch of GPRTU   \n",
      "\n",
      "                                          agency_url agency_timezone  \n",
      "0  https://en.wikipedia.org/wiki/Ghana_Private_Ro...             NaT  \n",
      "1  https://en.wikipedia.org/wiki/Ghana_Private_Ro...             NaT  \n",
      "2  https://en.wikipedia.org/wiki/Ghana_Private_Ro...             NaT  \n",
      "3  https://en.wikipedia.org/wiki/Ghana_Private_Ro...             NaT  \n",
      "4  https://en.wikipedia.org/wiki/Ghana_Private_Ro...             NaT  \n",
      "✓ Saved cleaned data to: cleaned_data\\accra\\cleaned_agency.csv\n",
      "\n",
      "==================================================\n",
      "Processing: accra\\calendar.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 10)\n",
      "\n",
      "Cleaning data for accra\\calendar.txt...\n",
      "  - Converted 'start_date' to datetime\n",
      "  - Converted 'end_date' to datetime\n",
      "  ✓ Cleaned data shape: (1, 10) → (1, 10)\n",
      "\n",
      "--- Analysis for accra\\calendar.txt ---\n",
      "Shape: (1, 10)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64             7\n",
      "datetime64[ns]    2\n",
      "object            1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       monday  tuesday  wednesday  thursday  friday  saturday  sunday\n",
      "count     1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "mean      1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "std       NaN      NaN        NaN       NaN     NaN       NaN     NaN\n",
      "min       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "25%       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "50%       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "75%       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "max       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "service_id:\n",
      "service_id\n",
      "service    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  service_id  monday  tuesday  wednesday  thursday  friday  saturday  sunday  \\\n",
      "0    service       1        1          1         1       1         1       1   \n",
      "\n",
      "                     start_date                      end_date  \n",
      "0 1970-01-01 00:00:00.020150520 1970-01-01 00:00:00.020170531  \n",
      "✓ Saved cleaned data to: cleaned_data\\accra\\cleaned_calendar.csv\n",
      "\n",
      "==================================================\n",
      "Processing: accra\\fare_attributes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (31, 6)\n",
      "\n",
      "Cleaning data for accra\\fare_attributes.txt...\n",
      "  - Capped 2 outliers in 'price'\n",
      "  ✓ Cleaned data shape: (31, 6) → (31, 4)\n",
      "\n",
      "--- Analysis for accra\\fare_attributes.txt ---\n",
      "Shape: (31, 4)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object     2\n",
      "float64    1\n",
      "int64      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "           price  payment_method\n",
      "count  31.000000            31.0\n",
      "mean    2.275806             0.0\n",
      "std     1.228998             0.0\n",
      "min     0.500000             0.0\n",
      "25%     1.350000             0.0\n",
      "50%     2.100000             0.0\n",
      "75%     2.900000             0.0\n",
      "max     5.225000             0.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "fare_id:\n",
      "fare_id\n",
      "fare_00    1\n",
      "fare_01    1\n",
      "fare_02    1\n",
      "fare_03    1\n",
      "fare_04    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "currency_type:\n",
      "currency_type\n",
      "CAD    31\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   fare_id  price currency_type  payment_method\n",
      "0  fare_00    0.5           CAD               0\n",
      "1  fare_01    0.7           CAD               0\n",
      "2  fare_02    0.8           CAD               0\n",
      "3  fare_03    0.9           CAD               0\n",
      "4  fare_04    1.0           CAD               0\n",
      "✓ Saved cleaned data to: cleaned_data\\accra\\cleaned_fare_attributes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: accra\\fare_rules.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (608, 5)\n",
      "\n",
      "Cleaning data for accra\\fare_rules.txt...\n",
      "  ✓ Cleaned data shape: (608, 5) → (608, 2)\n",
      "\n",
      "--- Analysis for accra\\fare_rules.txt ---\n",
      "Shape: (608, 2)\n",
      "Memory usage: 0.07 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "route_id:\n",
      "route_id\n",
      "002A    1\n",
      "002B    1\n",
      "003A    1\n",
      "003B    1\n",
      "004B    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "fare_id:\n",
      "fare_id\n",
      "fare_09    72\n",
      "fare_07    69\n",
      "fare_14    68\n",
      "fare_08    65\n",
      "fare_06    59\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  route_id  fare_id\n",
      "0     002A  fare_06\n",
      "1     002B  fare_06\n",
      "2     003A  fare_07\n",
      "3     003B  fare_07\n",
      "4     004B  fare_25\n",
      "✓ Saved cleaned data to: cleaned_data\\accra\\cleaned_fare_rules.csv\n",
      "\n",
      "==================================================\n",
      "Processing: accra\\routes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (651, 5)\n",
      "\n",
      "Cleaning data for accra\\routes.txt...\n",
      "  ✓ Cleaned data shape: (651, 5) → (651, 5)\n",
      "\n",
      "--- Analysis for accra\\routes.txt ---\n",
      "Shape: (651, 5)\n",
      "Memory usage: 0.14 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object    3\n",
      "int64     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "        agency_id  route_type\n",
      "count  651.000000       651.0\n",
      "mean    46.145929         3.0\n",
      "std     30.539486         0.0\n",
      "min      0.000000         3.0\n",
      "25%     21.000000         3.0\n",
      "50%     46.000000         3.0\n",
      "75%     70.000000         3.0\n",
      "max    101.000000         3.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "route_id:\n",
      "route_id\n",
      "385B    1\n",
      "056A    1\n",
      "277B    1\n",
      "311A    1\n",
      "200A    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_short_name:\n",
      "route_short_name\n",
      "385B    1\n",
      "056A    1\n",
      "277B    1\n",
      "311A    1\n",
      "200A    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_long_name:\n",
      "route_long_name\n",
      "Abeka lapaz to Circle                          37\n",
      "Circle Odorna Station to Orgle Road Station     3\n",
      "Abeka lapaz to Korle Bu Station                 3\n",
      "Korle Bu Station to Abeka lapaz                 3\n",
      "Arena Station to Zamrara Line                   2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  route_id route_short_name  agency_id  \\\n",
      "0     385B             385B         15   \n",
      "1     056A             056A         67   \n",
      "2     277B             277B         51   \n",
      "3     311A             311A         57   \n",
      "4     200A             200A         31   \n",
      "\n",
      "                                   route_long_name  route_type  \n",
      "0                   37 Station to New Town Station           3  \n",
      "1                       Abeka lapaz to Race Course           3  \n",
      "2                   C to Kaneshie Mamprobi Station           3  \n",
      "3  Kotobabi Down Station to Accra New Tema Station           3  \n",
      "4              Circle Odorna Station to New Melcom           3  \n",
      "✓ Saved cleaned data to: cleaned_data\\accra\\cleaned_routes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: accra\\shapes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (86377, 4)\n",
      "\n",
      "Cleaning data for accra\\shapes.txt...\n",
      "  - Capped 625 outliers in 'shape_pt_lat'\n",
      "  - Capped 8385 outliers in 'shape_pt_lon'\n",
      "  - Capped 2515 outliers in 'shape_pt_sequence'\n",
      "  ✓ Cleaned data shape: (86377, 4) → (86377, 4)\n",
      "\n",
      "--- Analysis for accra\\shapes.txt ---\n",
      "Shape: (86377, 4)\n",
      "Memory usage: 2.64 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64      2\n",
      "float64    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "            shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence\n",
      "count   86377.000000  86377.000000  86377.000000       86377.000000\n",
      "mean   354400.840235      5.594348     -0.218710          88.011774\n",
      "std    195443.109972      0.041122      0.043346          67.710437\n",
      "min      1001.000000      5.521124     -0.316253           1.000000\n",
      "25%    188001.000000      5.562194     -0.244842          34.000000\n",
      "50%    377001.000000      5.588663     -0.220332          72.000000\n",
      "75%    539001.000000      5.620869     -0.197235         126.000000\n",
      "max    651001.000000      5.708882     -0.125824         264.000000\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence\n",
      "0    651001      5.567347     -0.216433                113\n",
      "1      1001      5.607725     -0.246924                  2\n",
      "2      1001      5.607516     -0.247544                  3\n",
      "3      1001      5.607274     -0.248139                  4\n",
      "4      1001      5.606926     -0.248921                  5\n",
      "✓ Saved cleaned data to: cleaned_data\\accra\\cleaned_shapes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: accra\\stops.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (2565, 4)\n",
      "\n",
      "Cleaning data for accra\\stops.txt...\n",
      "  - Capped 42 outliers in 'stop_lat'\n",
      "  - Capped 219 outliers in 'stop_lon'\n",
      "  ✓ Cleaned data shape: (2565, 4) → (2565, 4)\n",
      "\n",
      "--- Analysis for accra\\stops.txt ---\n",
      "Shape: (2565, 4)\n",
      "Memory usage: 0.36 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object     2\n",
      "float64    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "          stop_lat     stop_lon\n",
      "count  2565.000000  2565.000000\n",
      "mean      5.595498    -0.228509\n",
      "std       0.046857     0.045382\n",
      "min       5.521120    -0.328380\n",
      "25%       5.559720    -0.254170\n",
      "50%       5.586580    -0.232579\n",
      "75%       5.625255    -0.204697\n",
      "max       5.723558    -0.130487\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "stop_id:\n",
      "stop_id\n",
      "S4842    1\n",
      "S1001    1\n",
      "S3829    1\n",
      "T208     1\n",
      "T1471    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "stop_name:\n",
      "stop_name\n",
      "Abelemkpe          8\n",
      "Caprice            6\n",
      "Abeka Junction     6\n",
      "Abrantie           6\n",
      "Ofankor Barrier    6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  stop_id                  stop_name  stop_lat  stop_lon\n",
      "0   S4842                 Junction 1  5.563420 -0.152562\n",
      "1   S1001                  Total 447  5.535621 -0.228926\n",
      "2   S3829            Water Works 406  5.580180 -0.276891\n",
      "3    T208  Terminal Accra Zongo Lane  5.544865 -0.209994\n",
      "4   T1471    Terminal Ridge Hospital  5.562655 -0.200297\n",
      "✓ Saved cleaned data to: cleaned_data\\accra\\cleaned_stops.csv\n",
      "\n",
      "==================================================\n",
      "Processing: accra\\stop_times.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (4796, 5)\n",
      "\n",
      "Cleaning data for accra\\stop_times.txt...\n",
      "  - Converted 'arrival_time' to datetime\n",
      "  - Converted 'departure_time' to datetime\n",
      "  - Capped 106 outliers in 'stop_sequence'\n",
      "  ✓ Cleaned data shape: (4796, 5) → (4796, 5)\n",
      "\n",
      "--- Analysis for accra\\stop_times.txt ---\n",
      "Shape: (4796, 5)\n",
      "Memory usage: 0.68 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object            2\n",
      "datetime64[ns]    2\n",
      "float64           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       stop_sequence\n",
      "count    4796.000000\n",
      "mean        5.158465\n",
      "std         3.461604\n",
      "min         1.000000\n",
      "25%         2.000000\n",
      "50%         4.000000\n",
      "75%         7.000000\n",
      "max        14.500000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "406A_1    26\n",
      "256A_1    23\n",
      "009A_1    22\n",
      "120B_1    22\n",
      "104A_1    21\n",
      "Name: count, dtype: int64\n",
      "\n",
      "stop_id:\n",
      "stop_id\n",
      "T0      112\n",
      "T75      66\n",
      "T136     47\n",
      "T251     46\n",
      "T244     44\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  trip_id        arrival_time      departure_time  stop_sequence stop_id\n",
      "0  002A_1 2025-08-11 12:51:38 2025-08-11 12:51:38            1.0   T5622\n",
      "1  002A_1 2025-08-11 13:01:28 2025-08-11 13:01:28            2.0   S5624\n",
      "2  002A_1 2025-08-11 13:02:48 2025-08-11 13:02:48            3.0   S3975\n",
      "3  002A_1 2025-08-11 13:03:43 2025-08-11 13:03:43            4.0   S3974\n",
      "4  002A_1 2025-08-11 13:05:20 2025-08-11 13:05:20            5.0   S5627\n",
      "✓ Saved cleaned data to: cleaned_data\\accra\\cleaned_stop_times.csv\n",
      "\n",
      "==================================================\n",
      "Processing: accra\\trips.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (651, 4)\n",
      "\n",
      "Cleaning data for accra\\trips.txt...\n",
      "  ✓ Cleaned data shape: (651, 4) → (651, 4)\n",
      "\n",
      "--- Analysis for accra\\trips.txt ---\n",
      "Shape: (651, 4)\n",
      "Memory usage: 0.12 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object    3\n",
      "int64     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "            shape_id\n",
      "count     651.000000\n",
      "mean   326001.000000\n",
      "std    188071.794802\n",
      "min      1001.000000\n",
      "25%    163501.000000\n",
      "50%    326001.000000\n",
      "75%    488501.000000\n",
      "max    651001.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "route_id:\n",
      "route_id\n",
      "018A    1\n",
      "005A    1\n",
      "005B    1\n",
      "016A    1\n",
      "016B    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "service_id:\n",
      "service_id\n",
      "service    651\n",
      "Name: count, dtype: int64\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "018A_1    1\n",
      "005A_1    1\n",
      "005B_1    1\n",
      "016A_1    1\n",
      "016B_1    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  route_id service_id trip_id  shape_id\n",
      "0     018A    service  018A_1      1001\n",
      "1     005A    service  005A_1      2001\n",
      "2     005B    service  005B_1      3001\n",
      "3     016A    service  016A_1      4001\n",
      "4     016B    service  016B_1      5001\n",
      "✓ Saved cleaned data to: cleaned_data\\accra\\cleaned_trips.csv\n",
      "\n",
      "==================================================\n",
      "Processing: addisababa\\agency.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 5)\n",
      "\n",
      "Cleaning data for addisababa\\agency.txt...\n",
      "  - Converted 'agency_timezone' to datetime\n",
      "  ✓ Cleaned data shape: (1, 5) → (1, 5)\n",
      "\n",
      "--- Analysis for addisababa\\agency.txt ---\n",
      "Shape: (1, 5)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "Missing values:\n",
      "agency_timezone    1\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "object            4\n",
      "datetime64[ns]    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "agency_url:\n",
      "agency_url\n",
      "https://addismaptransit.com/    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_lang:\n",
      "agency_lang\n",
      "en    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_name:\n",
      "agency_name\n",
      "Addis Ababa Transport (all)    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_id:\n",
      "agency_id\n",
      "AA    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "                     agency_url agency_lang                  agency_name  \\\n",
      "0  https://addismaptransit.com/          en  Addis Ababa Transport (all)   \n",
      "\n",
      "  agency_id agency_timezone  \n",
      "0        AA             NaT  \n",
      "✓ Saved cleaned data to: cleaned_data\\addisababa\\cleaned_agency.csv\n",
      "\n",
      "==================================================\n",
      "Processing: addisababa\\calendar.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 10)\n",
      "\n",
      "Cleaning data for addisababa\\calendar.txt...\n",
      "  - Converted 'start_date' to datetime\n",
      "  - Converted 'end_date' to datetime\n",
      "  ✓ Cleaned data shape: (1, 10) → (1, 10)\n",
      "\n",
      "--- Analysis for addisababa\\calendar.txt ---\n",
      "Shape: (1, 10)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64             8\n",
      "datetime64[ns]    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       service_id  monday  tuesday  wednesday  thursday  friday  saturday  \\\n",
      "count         1.0     1.0      1.0        1.0       1.0     1.0       1.0   \n",
      "mean          0.0     1.0      1.0        1.0       1.0     1.0       1.0   \n",
      "std           NaN     NaN      NaN        NaN       NaN     NaN       NaN   \n",
      "min           0.0     1.0      1.0        1.0       1.0     1.0       1.0   \n",
      "25%           0.0     1.0      1.0        1.0       1.0     1.0       1.0   \n",
      "50%           0.0     1.0      1.0        1.0       1.0     1.0       1.0   \n",
      "75%           0.0     1.0      1.0        1.0       1.0     1.0       1.0   \n",
      "max           0.0     1.0      1.0        1.0       1.0     1.0       1.0   \n",
      "\n",
      "       sunday  \n",
      "count     1.0  \n",
      "mean      1.0  \n",
      "std       NaN  \n",
      "min       1.0  \n",
      "25%       1.0  \n",
      "50%       1.0  \n",
      "75%       1.0  \n",
      "max       1.0  \n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   service_id                    start_date                      end_date  \\\n",
      "0           0 1970-01-01 00:00:00.020191201 1970-01-01 00:00:00.020991231   \n",
      "\n",
      "   monday  tuesday  wednesday  thursday  friday  saturday  sunday  \n",
      "0       1        1          1         1       1         1       1  \n",
      "✓ Saved cleaned data to: cleaned_data\\addisababa\\cleaned_calendar.csv\n",
      "\n",
      "==================================================\n",
      "Processing: addisababa\\feed_info.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 8)\n",
      "\n",
      "Cleaning data for addisababa\\feed_info.txt...\n",
      "  - Converted 'feed_end_date' to datetime\n",
      "  - Converted 'feed_start_date' to datetime\n",
      "  ✓ Cleaned data shape: (1, 8) → (1, 8)\n",
      "\n",
      "--- Analysis for addisababa\\feed_info.txt ---\n",
      "Shape: (1, 8)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object            5\n",
      "datetime64[ns]    2\n",
      "float64           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       feed_version\n",
      "count           1.0\n",
      "mean            1.0\n",
      "std             NaN\n",
      "min             1.0\n",
      "25%             1.0\n",
      "50%             1.0\n",
      "75%             1.0\n",
      "max             1.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "feed_publisher_name:\n",
      "feed_publisher_name\n",
      "AddisMap + DT4A    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_publisher_url:\n",
      "feed_publisher_url\n",
      "https://digitaltransport4africa.org/    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_lang:\n",
      "feed_lang\n",
      "en    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_contact_email:\n",
      "feed_contact_email\n",
      "info@addismap.com    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_contact_url:\n",
      "feed_contact_url\n",
      "https://addismaptransit.com/support/    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   feed_version feed_publisher_name                    feed_publisher_url  \\\n",
      "0           1.0     AddisMap + DT4A  https://digitaltransport4africa.org/   \n",
      "\n",
      "  feed_lang feed_contact_email                 feed_end_date  \\\n",
      "0        en  info@addismap.com 1970-01-01 00:00:00.020991231   \n",
      "\n",
      "                feed_start_date                      feed_contact_url  \n",
      "0 1970-01-01 00:00:00.020191201  https://addismaptransit.com/support/  \n",
      "✓ Saved cleaned data to: cleaned_data\\addisababa\\cleaned_feed_info.csv\n",
      "\n",
      "==================================================\n",
      "Processing: addisababa\\frequencies.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (881, 5)\n",
      "\n",
      "Cleaning data for addisababa\\frequencies.txt...\n",
      "  - Converted 'start_time' to datetime\n",
      "  - Converted 'end_time' to datetime\n",
      "  - Converted 'exact_times' to datetime\n",
      "  - Capped 175 outliers in 'headway_secs'\n",
      "  ✓ Cleaned data shape: (881, 5) → (881, 5)\n",
      "\n",
      "--- Analysis for addisababa\\frequencies.txt ---\n",
      "Shape: (881, 5)\n",
      "Memory usage: 0.03 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "datetime64[ns]    3\n",
      "int64             2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "         trip_id  headway_secs\n",
      "count  881.00000         881.0\n",
      "mean   440.00000        3000.0\n",
      "std    254.46709           0.0\n",
      "min      0.00000        3000.0\n",
      "25%    220.00000        3000.0\n",
      "50%    440.00000        3000.0\n",
      "75%    660.00000        3000.0\n",
      "max    880.00000        3000.0\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   trip_id          start_time            end_time  headway_secs exact_times\n",
      "0        0 2025-08-11 05:00:00 2025-08-11 22:00:00          3000  1970-01-01\n",
      "1        1 2025-08-11 05:00:00 2025-08-11 22:00:00          3000  1970-01-01\n",
      "2        2 2025-08-11 05:00:00 2025-08-11 22:00:00          3000  1970-01-01\n",
      "3        3 2025-08-11 05:00:00 2025-08-11 22:00:00          3000  1970-01-01\n",
      "4        4 2025-08-11 05:00:00 2025-08-11 22:00:00          3000  1970-01-01\n",
      "✓ Saved cleaned data to: cleaned_data\\addisababa\\cleaned_frequencies.csv\n",
      "\n",
      "==================================================\n",
      "Processing: addisababa\\routes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (442, 8)\n",
      "\n",
      "Cleaning data for addisababa\\routes.txt...\n",
      "  - Capped 144 outliers in 'route_id'\n",
      "  - Capped 2 outliers in 'route_type'\n",
      "  ✓ Cleaned data shape: (442, 8) → (442, 7)\n",
      "\n",
      "--- Analysis for addisababa\\routes.txt ---\n",
      "Shape: (442, 7)\n",
      "Memory usage: 0.17 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object     5\n",
      "float64    1\n",
      "int64      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "           route_id  route_type\n",
      "count  4.420000e+02       442.0\n",
      "mean   1.600921e+07         3.0\n",
      "std    2.780725e+05         0.0\n",
      "min    1.553149e+07         3.0\n",
      "25%    1.587665e+07         3.0\n",
      "50%    1.596085e+07         3.0\n",
      "75%    1.610676e+07         3.0\n",
      "max    1.645192e+07         3.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "route_long_name:\n",
      "route_long_name\n",
      "Megenagna Terminal ↔ Aba Kiros Roundabout    3\n",
      "kera ↔ Addisu Gebeya                         2\n",
      "Bole Bridge ↔ Autobus Tera (Minibus)         2\n",
      "Yeshi Debele ↔ Autobis Tera                  2\n",
      "Mexico ↔ Lafto                               2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_short_name:\n",
      "route_short_name\n",
      "AB097    1\n",
      "AB101    1\n",
      "AB049    1\n",
      "AB083    1\n",
      "AB010    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_id:\n",
      "agency_id\n",
      "AA    442\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_color:\n",
      "route_color\n",
      "1779c2    442\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_text_color:\n",
      "route_text_color\n",
      "ffffff    442\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "                               route_long_name route_short_name agency_id  \\\n",
      "0        Megenegna Terminal ↔ Legedadi Mission            AB097        AA   \n",
      "1    Megenagna Terminal ↔ Aba Kiros Roundabout            AB101        AA   \n",
      "2  Megenegna Terminal ↔ Ayat Chefe Condominium            AB049        AA   \n",
      "3              Ayat Chefe Condominium ↔ 6 Kilo            AB083        AA   \n",
      "4       Kotebe Teachers College ↔ Piassa Arada            AB010        AA   \n",
      "\n",
      "     route_id  route_type route_color route_text_color  \n",
      "0  15531489.5           3      1779c2           ffffff  \n",
      "1  15531489.5           3      1779c2           ffffff  \n",
      "2  15531489.5           3      1779c2           ffffff  \n",
      "3  15531489.5           3      1779c2           ffffff  \n",
      "4  15531489.5           3      1779c2           ffffff  \n",
      "✓ Saved cleaned data to: cleaned_data\\addisababa\\cleaned_routes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: addisababa\\shapes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (278945, 5)\n",
      "\n",
      "Cleaning data for addisababa\\shapes.txt...\n",
      "  - Capped 33775 outliers in 'shape_id'\n",
      "  - Capped 13790 outliers in 'shape_pt_lat'\n",
      "  - Capped 21869 outliers in 'shape_pt_lon'\n",
      "  - Capped 10186 outliers in 'shape_pt_sequence'\n",
      "  ✓ Cleaned data shape: (278945, 5) → (278945, 4)\n",
      "\n",
      "--- Analysis for addisababa\\shapes.txt ---\n",
      "Shape: (278945, 4)\n",
      "Memory usage: 8.51 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "float64    4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "           shape_id   shape_pt_lat   shape_pt_lon  shape_pt_sequence\n",
      "count  2.789450e+05  278945.000000  278945.000000      278945.000000\n",
      "mean   1.602016e+07       9.006533      38.754195         196.138239\n",
      "std    7.061667e+05       0.040940       0.043790         147.210936\n",
      "min    1.452149e+07       8.910051      38.653545           1.000000\n",
      "25%    1.586742e+07       8.984446      38.726165          80.000000\n",
      "50%    1.596310e+07       9.012617      38.750209         165.000000\n",
      "75%    1.676471e+07       9.034042      38.774578         277.000000\n",
      "max    1.708233e+07       9.108437      38.847198         572.500000\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "     shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence\n",
      "0  14521488.5      9.081773     38.847198                1.0\n",
      "1  14521488.5      9.081302     38.847198                2.0\n",
      "2  14521488.5      9.080956     38.847198                3.0\n",
      "3  14521488.5      9.080310     38.847198                4.0\n",
      "4  14521488.5      9.079291     38.847198                5.0\n",
      "✓ Saved cleaned data to: cleaned_data\\addisababa\\cleaned_shapes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: addisababa\\stops.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (2259, 6)\n",
      "\n",
      "Cleaning data for addisababa\\stops.txt...\n",
      "  - Capped 196 outliers in 'stop_lat'\n",
      "  - Capped 218 outliers in 'stop_lon'\n",
      "  ✓ Cleaned data shape: (2259, 6) → (2259, 5)\n",
      "\n",
      "--- Analysis for addisababa\\stops.txt ---\n",
      "Shape: (2259, 5)\n",
      "Memory usage: 0.36 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "float64    2\n",
      "object     2\n",
      "int64      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       location_type     stop_lat     stop_lon\n",
      "count         2259.0  2259.000000  2259.000000\n",
      "mean             0.0     9.004545    38.761756\n",
      "std              0.0     0.047789     0.054354\n",
      "min              0.0     8.901948    38.647217\n",
      "25%              0.0     8.981719    38.732173\n",
      "50%              0.0     9.012176    38.756828\n",
      "75%              0.0     9.034900    38.788811\n",
      "max              0.0     9.114671    38.873767\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "stop_name:\n",
      "stop_name\n",
      "Mexico          39\n",
      "Megenagna       36\n",
      "Piassa Arada    26\n",
      "Ayer Tena       21\n",
      "Kera            17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "stop_id:\n",
      "stop_id\n",
      "way/604046026    1\n",
      "way/604046027    1\n",
      "way/604046028    1\n",
      "way/604046029    1\n",
      "way/604046052    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   location_type  stop_lat stop_name        stop_id   stop_lon\n",
      "0              0  9.021026     C.M.C  way/604046026  38.850456\n",
      "1              0  9.020937     C.M.C  way/604046027  38.850449\n",
      "2              0  9.020631      Meri  way/604046028  38.860390\n",
      "3              0  9.020534      Meri  way/604046029  38.860397\n",
      "4              0  9.021228      Ayat  way/604046052  38.871795\n",
      "✓ Saved cleaned data to: cleaned_data\\addisababa\\cleaned_stops.csv\n",
      "\n",
      "==================================================\n",
      "Processing: addisababa\\stop_times.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (8925, 12)\n",
      "\n",
      "Cleaning data for addisababa\\stop_times.txt...\n",
      "  - Converted 'arrival_time' to datetime\n",
      "  - Converted 'departure_time' to datetime\n",
      "  - Converted 'timepoint' to datetime\n",
      "  - Capped 327 outliers in 'stop_sequence'\n",
      "  ✓ Cleaned data shape: (8925, 12) → (8925, 8)\n",
      "\n",
      "--- Analysis for addisababa\\stop_times.txt ---\n",
      "Shape: (8925, 8)\n",
      "Memory usage: 1.09 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "datetime64[ns]    3\n",
      "int64             2\n",
      "float64           2\n",
      "object            1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "           trip_id  stop_sequence  continuous_pickup  continuous_drop_off\n",
      "count  8925.000000    8925.000000             8925.0               8925.0\n",
      "mean    475.656583       6.679552                0.0                  0.0\n",
      "std     269.109326       4.585772                0.0                  0.0\n",
      "min       0.000000       1.000000                0.0                  0.0\n",
      "25%     231.000000       3.000000                0.0                  0.0\n",
      "50%     520.000000       6.000000                0.0                  0.0\n",
      "75%     709.000000       9.000000                0.0                  0.0\n",
      "max     880.000000      18.000000                0.0                  0.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "stop_id:\n",
      "stop_id\n",
      "node/10913863177    26\n",
      "node/7041071395     24\n",
      "node/10842129026    24\n",
      "node/10842129098    23\n",
      "node/7078406239     23\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   trip_id        arrival_time      departure_time           stop_id  \\\n",
      "0        0 2025-08-11 06:00:00 2025-08-11 06:00:00   node/7037183574   \n",
      "1        0 2025-08-11 06:15:55 2025-08-11 06:15:55   node/7105158908   \n",
      "2        0 2025-08-11 06:17:24 2025-08-11 06:17:24   node/7105158907   \n",
      "3        0 2025-08-11 06:18:45 2025-08-11 06:18:45   node/7037183557   \n",
      "4        0 2025-08-11 06:20:22 2025-08-11 06:20:22  node/10823916391   \n",
      "\n",
      "   stop_sequence                     timepoint  continuous_pickup  \\\n",
      "0              1 1970-01-01 00:00:00.000000001                0.0   \n",
      "1              2 1970-01-01 00:00:00.000000000                0.0   \n",
      "2              3 1970-01-01 00:00:00.000000000                0.0   \n",
      "3              4 1970-01-01 00:00:00.000000000                0.0   \n",
      "4              5 1970-01-01 00:00:00.000000000                0.0   \n",
      "\n",
      "   continuous_drop_off  \n",
      "0                  0.0  \n",
      "1                  0.0  \n",
      "2                  0.0  \n",
      "3                  0.0  \n",
      "4                  0.0  \n",
      "✓ Saved cleaned data to: cleaned_data\\addisababa\\cleaned_stop_times.csv\n",
      "\n",
      "==================================================\n",
      "Processing: addisababa\\trips.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (881, 6)\n",
      "\n",
      "Cleaning data for addisababa\\trips.txt...\n",
      "  - Capped 287 outliers in 'route_id'\n",
      "  - Capped 317 outliers in 'shape_id'\n",
      "  ✓ Cleaned data shape: (881, 6) → (881, 6)\n",
      "\n",
      "--- Analysis for addisababa\\trips.txt ---\n",
      "Shape: (881, 6)\n",
      "Memory usage: 0.09 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64     5\n",
      "object    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "         trip_id  service_id      route_id      shape_id  direction_id\n",
      "count  881.00000       881.0  8.810000e+02  8.810000e+02    881.000000\n",
      "mean   440.00000         0.0  1.601135e+07  1.597542e+07      0.498297\n",
      "std    254.46709         0.0  2.847510e+05  2.600590e+05      0.500281\n",
      "min      0.00000         0.0  1.552261e+07  1.555962e+07      0.000000\n",
      "25%    220.00000         0.0  1.587672e+07  1.586715e+07      0.000000\n",
      "50%    440.00000         0.0  1.596088e+07  1.591807e+07      0.000000\n",
      "75%    660.00000         0.0  1.611280e+07  1.607217e+07      1.000000\n",
      "max    880.00000         0.0  1.646692e+07  1.637970e+07      1.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "trip_headsign:\n",
      "trip_headsign\n",
      "Megenagna       58\n",
      "Piassa Arada    52\n",
      "Mexico          46\n",
      "Autobis Tera    29\n",
      "Ayer Tena       19\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   trip_id  service_id  route_id  shape_id  direction_id         trip_headsign\n",
      "0        0           0  15522608  15559623             0    Megenagna Terminal\n",
      "1        1           0  15522608  15559623             1      Legedadi Mission\n",
      "2        2           0  15522608  15559623             0    Megenagna Terminal\n",
      "3        3           0  15522608  15559623             1  Aba Kiros Roundabout\n",
      "4        4           0  15522608  15559623             0    Megenagna Terminal\n",
      "✓ Saved cleaned data to: cleaned_data\\addisababa\\cleaned_trips.csv\n",
      "\n",
      "==================================================\n",
      "Processing: addisababa-minibus\\agency.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 5)\n",
      "\n",
      "Cleaning data for addisababa-minibus\\agency.txt...\n",
      "  - Converted 'agency_timezone' to datetime\n",
      "  ✓ Cleaned data shape: (1, 5) → (1, 5)\n",
      "\n",
      "--- Analysis for addisababa-minibus\\agency.txt ---\n",
      "Shape: (1, 5)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "Missing values:\n",
      "agency_timezone    1\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "object            4\n",
      "datetime64[ns]    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "agency_url:\n",
      "agency_url\n",
      "https://addismaptransit.com/    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_id:\n",
      "agency_id\n",
      "AA    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_lang:\n",
      "agency_lang\n",
      "en    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_name:\n",
      "agency_name\n",
      "Addis Ababa Transport (Minibus)    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "                     agency_url agency_id agency_timezone agency_lang  \\\n",
      "0  https://addismaptransit.com/        AA             NaT          en   \n",
      "\n",
      "                       agency_name  \n",
      "0  Addis Ababa Transport (Minibus)  \n",
      "✓ Saved cleaned data to: cleaned_data\\addisababa-minibus\\cleaned_agency.csv\n",
      "\n",
      "==================================================\n",
      "Processing: addisababa-minibus\\calendar.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 10)\n",
      "\n",
      "Cleaning data for addisababa-minibus\\calendar.txt...\n",
      "  - Converted 'start_date' to datetime\n",
      "  - Converted 'end_date' to datetime\n",
      "  ✓ Cleaned data shape: (1, 10) → (1, 10)\n",
      "\n",
      "--- Analysis for addisababa-minibus\\calendar.txt ---\n",
      "Shape: (1, 10)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64             8\n",
      "datetime64[ns]    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       service_id  monday  tuesday  wednesday  thursday  friday  saturday  \\\n",
      "count         1.0     1.0      1.0        1.0       1.0     1.0       1.0   \n",
      "mean          0.0     1.0      1.0        1.0       1.0     1.0       1.0   \n",
      "std           NaN     NaN      NaN        NaN       NaN     NaN       NaN   \n",
      "min           0.0     1.0      1.0        1.0       1.0     1.0       1.0   \n",
      "25%           0.0     1.0      1.0        1.0       1.0     1.0       1.0   \n",
      "50%           0.0     1.0      1.0        1.0       1.0     1.0       1.0   \n",
      "75%           0.0     1.0      1.0        1.0       1.0     1.0       1.0   \n",
      "max           0.0     1.0      1.0        1.0       1.0     1.0       1.0   \n",
      "\n",
      "       sunday  \n",
      "count     1.0  \n",
      "mean      1.0  \n",
      "std       NaN  \n",
      "min       1.0  \n",
      "25%       1.0  \n",
      "50%       1.0  \n",
      "75%       1.0  \n",
      "max       1.0  \n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   service_id                    start_date                      end_date  \\\n",
      "0           0 1970-01-01 00:00:00.020191201 1970-01-01 00:00:00.020991231   \n",
      "\n",
      "   monday  tuesday  wednesday  thursday  friday  saturday  sunday  \n",
      "0       1        1          1         1       1         1       1  \n",
      "✓ Saved cleaned data to: cleaned_data\\addisababa-minibus\\cleaned_calendar.csv\n",
      "\n",
      "==================================================\n",
      "Processing: addisababa-minibus\\feed_info.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 8)\n",
      "\n",
      "Cleaning data for addisababa-minibus\\feed_info.txt...\n",
      "  - Converted 'feed_end_date' to datetime\n",
      "  - Converted 'feed_start_date' to datetime\n",
      "  ✓ Cleaned data shape: (1, 8) → (1, 8)\n",
      "\n",
      "--- Analysis for addisababa-minibus\\feed_info.txt ---\n",
      "Shape: (1, 8)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object            5\n",
      "datetime64[ns]    2\n",
      "float64           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       feed_version\n",
      "count           1.0\n",
      "mean            1.0\n",
      "std             NaN\n",
      "min             1.0\n",
      "25%             1.0\n",
      "50%             1.0\n",
      "75%             1.0\n",
      "max             1.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "feed_contact_url:\n",
      "feed_contact_url\n",
      "https://addismaptransit.com/support/    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_publisher_url:\n",
      "feed_publisher_url\n",
      "https://digitaltransport4africa.org/    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_publisher_name:\n",
      "feed_publisher_name\n",
      "AddisMap + DT4A    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_lang:\n",
      "feed_lang\n",
      "en    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_contact_email:\n",
      "feed_contact_email\n",
      "info@addismap.com    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "                       feed_contact_url                    feed_publisher_url  \\\n",
      "0  https://addismaptransit.com/support/  https://digitaltransport4africa.org/   \n",
      "\n",
      "   feed_version feed_publisher_name                 feed_end_date feed_lang  \\\n",
      "0           1.0     AddisMap + DT4A 1970-01-01 00:00:00.020991231        en   \n",
      "\n",
      "                feed_start_date feed_contact_email  \n",
      "0 1970-01-01 00:00:00.020191201  info@addismap.com  \n",
      "✓ Saved cleaned data to: cleaned_data\\addisababa-minibus\\cleaned_feed_info.csv\n",
      "\n",
      "==================================================\n",
      "Processing: addisababa-minibus\\frequencies.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (492, 5)\n",
      "\n",
      "Cleaning data for addisababa-minibus\\frequencies.txt...\n",
      "  - Converted 'start_time' to datetime\n",
      "  - Converted 'end_time' to datetime\n",
      "  - Converted 'exact_times' to datetime\n",
      "  - Capped 1 outliers in 'headway_secs'\n",
      "  ✓ Cleaned data shape: (492, 5) → (492, 5)\n",
      "\n",
      "--- Analysis for addisababa-minibus\\frequencies.txt ---\n",
      "Shape: (492, 5)\n",
      "Memory usage: 0.02 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "datetime64[ns]    3\n",
      "int64             2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "          trip_id  headway_secs\n",
      "count  492.000000         492.0\n",
      "mean   245.500000        3000.0\n",
      "std    142.172431           0.0\n",
      "min      0.000000        3000.0\n",
      "25%    122.750000        3000.0\n",
      "50%    245.500000        3000.0\n",
      "75%    368.250000        3000.0\n",
      "max    491.000000        3000.0\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   trip_id          start_time            end_time  headway_secs exact_times\n",
      "0        0 2025-08-11 05:00:00 2025-08-11 22:00:00          3000  1970-01-01\n",
      "1        1 2025-08-11 05:00:00 2025-08-11 22:00:00          3000  1970-01-01\n",
      "2        2 2025-08-11 05:00:00 2025-08-11 22:00:00          3000  1970-01-01\n",
      "3        3 2025-08-11 05:00:00 2025-08-11 22:00:00          3000  1970-01-01\n",
      "4        4 2025-08-11 05:00:00 2025-08-11 22:00:00          3000  1970-01-01\n",
      "✓ Saved cleaned data to: cleaned_data\\addisababa-minibus\\cleaned_frequencies.csv\n",
      "\n",
      "==================================================\n",
      "Processing: addisababa-minibus\\routes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (247, 8)\n",
      "\n",
      "Cleaning data for addisababa-minibus\\routes.txt...\n",
      "  - Capped 8 outliers in 'route_id'\n",
      "  ✓ Cleaned data shape: (247, 8) → (247, 7)\n",
      "\n",
      "--- Analysis for addisababa-minibus\\routes.txt ---\n",
      "Shape: (247, 7)\n",
      "Memory usage: 0.10 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object     5\n",
      "int64      1\n",
      "float64    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       route_type      route_id\n",
      "count       247.0  2.470000e+02\n",
      "mean          3.0  1.591469e+07\n",
      "std           0.0  6.197220e+04\n",
      "min           3.0  1.574856e+07\n",
      "25%           3.0  1.587668e+07\n",
      "50%           3.0  1.591034e+07\n",
      "75%           3.0  1.596208e+07\n",
      "max           3.0  1.602889e+07\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "agency_id:\n",
      "agency_id\n",
      "AA    247\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_long_name:\n",
      "route_long_name\n",
      "Wello Sefer ↔ Kera (Minibus)             2\n",
      "Kality Menaheria ↔ 4 Kilo (Minibus)      2\n",
      "Kality Total ↔ Autobus Tera (Minibus)    2\n",
      "Kera ↔ Autobus Tera (Minibus)            2\n",
      "Bole Bridge ↔ Autobus Tera (Minibus)     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_short_name:\n",
      "route_short_name\n",
      "TX341    1\n",
      "TX002    1\n",
      "TX200    1\n",
      "TX065    1\n",
      "TX005    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_color:\n",
      "route_color\n",
      "1779c2    247\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_text_color:\n",
      "route_text_color\n",
      "ffffff    247\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   route_type agency_id                         route_long_name  \\\n",
      "0           3        AA        Olympia ↔ Agona Cinema (Minibus)   \n",
      "1           3        AA  Total 3 kuter Mazoria ↔ Kera (Minibus)   \n",
      "2           3        AA            Wello Sefer ↔ Kera (Minibus)   \n",
      "3           3        AA   Safari (Summit) ↔ Megenagna (Minibus)   \n",
      "4           3        AA     Kality Menaheria ↔ 4 Kilo (Minibus)   \n",
      "\n",
      "  route_short_name    route_id route_color route_text_color  \n",
      "0            TX341  15748561.5      1779c2           ffffff  \n",
      "1            TX002  15748561.5      1779c2           ffffff  \n",
      "2            TX200  15748561.5      1779c2           ffffff  \n",
      "3            TX065  15748561.5      1779c2           ffffff  \n",
      "4            TX005  15748561.5      1779c2           ffffff  \n",
      "✓ Saved cleaned data to: cleaned_data\\addisababa-minibus\\cleaned_routes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: addisababa-minibus\\shapes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (121486, 5)\n",
      "\n",
      "Cleaning data for addisababa-minibus\\shapes.txt...\n",
      "  - Capped 3720 outliers in 'shape_id'\n",
      "  - Capped 4587 outliers in 'shape_pt_lat'\n",
      "  - Capped 6976 outliers in 'shape_pt_lon'\n",
      "  - Capped 3184 outliers in 'shape_pt_sequence'\n",
      "  ✓ Cleaned data shape: (121486, 5) → (121486, 4)\n",
      "\n",
      "--- Analysis for addisababa-minibus\\shapes.txt ---\n",
      "Shape: (121486, 4)\n",
      "Memory usage: 3.71 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "float64    4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "           shape_id   shape_pt_lat   shape_pt_lon  shape_pt_sequence\n",
      "count  1.214860e+05  121486.000000  121486.000000      121486.000000\n",
      "mean   1.591629e+07       9.000803      38.751003         146.734546\n",
      "std    6.138246e+04       0.038153       0.035701         105.897885\n",
      "min    1.574872e+07       8.909213      38.662900           1.000000\n",
      "25%    1.587675e+07       8.980714      38.725983          62.000000\n",
      "50%    1.591308e+07       9.010690      38.747729         127.000000\n",
      "75%    1.596210e+07       9.028382      38.768038         209.000000\n",
      "max    1.600831e+07       9.069924      38.831120         429.500000\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "     shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence\n",
      "0  15748723.5      8.987489     38.760896                1.0\n",
      "1  15748723.5      8.987486     38.761126                2.0\n",
      "2  15748723.5      8.987481     38.761715                3.0\n",
      "3  15748723.5      8.987477     38.762190                4.0\n",
      "4  15748723.5      8.987479     38.762338                5.0\n",
      "✓ Saved cleaned data to: cleaned_data\\addisababa-minibus\\cleaned_shapes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: addisababa-minibus\\stops.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (905, 6)\n",
      "\n",
      "Cleaning data for addisababa-minibus\\stops.txt...\n",
      "  - Capped 36 outliers in 'stop_lon'\n",
      "  - Capped 50 outliers in 'stop_lat'\n",
      "  ✓ Cleaned data shape: (905, 6) → (905, 5)\n",
      "\n",
      "--- Analysis for addisababa-minibus\\stops.txt ---\n",
      "Shape: (905, 5)\n",
      "Memory usage: 0.14 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "float64    2\n",
      "object     2\n",
      "int64      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "         stop_lon    stop_lat  location_type\n",
      "count  905.000000  905.000000          905.0\n",
      "mean    38.760473    9.000823            0.0\n",
      "std      0.043347    0.038663            0.0\n",
      "min     38.663952    8.911398            0.0\n",
      "25%     38.732906    8.982268            0.0\n",
      "50%     38.753349    9.010012            0.0\n",
      "75%     38.784342    9.029514            0.0\n",
      "max     38.861497    9.069169            0.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "stop_name:\n",
      "stop_name\n",
      "Megenagna     19\n",
      "Mexico        18\n",
      "Kera          13\n",
      "Torhayloch    10\n",
      "Ayer Tena      9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "stop_id:\n",
      "stop_id\n",
      "node/6728583386    1\n",
      "node/6967281242    1\n",
      "node/7041052978    1\n",
      "node/7041071612    1\n",
      "node/7049122264    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "    stop_lon  stop_lat         stop_name          stop_id  location_type\n",
      "0  38.751676  9.033148             Arada  node/6728583386              0\n",
      "1  38.752624  9.033012  Piassa Arada (2)  node/6967281242              0\n",
      "2  38.762999  8.965927  kadisco Building  node/7041052978              0\n",
      "3  38.713510  9.033582        18 Mazoria  node/7041071612              0\n",
      "4  38.744323  8.947377             Lafto  node/7049122264              0\n",
      "✓ Saved cleaned data to: cleaned_data\\addisababa-minibus\\cleaned_stops.csv\n",
      "\n",
      "==================================================\n",
      "Processing: addisababa-minibus\\stop_times.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (3894, 12)\n",
      "\n",
      "Cleaning data for addisababa-minibus\\stop_times.txt...\n",
      "  - Converted 'arrival_time' to datetime\n",
      "  - Converted 'departure_time' to datetime\n",
      "  - Converted 'timepoint' to datetime\n",
      "  - Capped 109 outliers in 'stop_sequence'\n",
      "  ✓ Cleaned data shape: (3894, 12) → (3894, 8)\n",
      "\n",
      "--- Analysis for addisababa-minibus\\stop_times.txt ---\n",
      "Shape: (3894, 8)\n",
      "Memory usage: 0.48 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64             3\n",
      "datetime64[ns]    3\n",
      "object            1\n",
      "float64           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "           trip_id  stop_sequence  continuous_pickup  continuous_drop_off\n",
      "count  3894.000000    3894.000000             3894.0               3894.0\n",
      "mean    246.466102       5.157550                0.0                  0.0\n",
      "std     145.069130       3.388327                0.0                  0.0\n",
      "min       0.000000       1.000000                0.0                  0.0\n",
      "25%     118.000000       2.000000                0.0                  0.0\n",
      "50%     252.000000       4.000000                0.0                  0.0\n",
      "75%     368.000000       7.000000                0.0                  0.0\n",
      "max     491.000000      14.500000                0.0                  0.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "stop_id:\n",
      "stop_id\n",
      "node/10913863177    26\n",
      "node/10842129026    24\n",
      "node/10842129098    23\n",
      "node/10899150568    22\n",
      "node/10846106471    21\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   trip_id        arrival_time      departure_time          stop_id  \\\n",
      "0        0 2025-08-11 06:00:00 2025-08-11 06:00:00  node/7123265066   \n",
      "1        0 2025-08-11 06:02:30 2025-08-11 06:02:30  node/7123265065   \n",
      "2        0 2025-08-11 06:05:03 2025-08-11 06:05:03  node/7123265064   \n",
      "3        0 2025-08-11 06:07:09 2025-08-11 06:07:09  node/7123265063   \n",
      "4        0 2025-08-11 06:09:03 2025-08-11 06:09:03  node/7123265062   \n",
      "\n",
      "   stop_sequence                     timepoint  continuous_pickup  \\\n",
      "0            1.0 1970-01-01 00:00:00.000000001                  0   \n",
      "1            2.0 1970-01-01 00:00:00.000000000                  0   \n",
      "2            3.0 1970-01-01 00:00:00.000000000                  0   \n",
      "3            4.0 1970-01-01 00:00:00.000000000                  0   \n",
      "4            5.0 1970-01-01 00:00:00.000000000                  0   \n",
      "\n",
      "   continuous_drop_off  \n",
      "0                    0  \n",
      "1                    0  \n",
      "2                    0  \n",
      "3                    0  \n",
      "4                    0  \n",
      "✓ Saved cleaned data to: cleaned_data\\addisababa-minibus\\cleaned_stop_times.csv\n",
      "\n",
      "==================================================\n",
      "Processing: addisababa-minibus\\trips.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (492, 6)\n",
      "\n",
      "Cleaning data for addisababa-minibus\\trips.txt...\n",
      "  - Capped 16 outliers in 'route_id'\n",
      "  - Capped 16 outliers in 'shape_id'\n",
      "  ✓ Cleaned data shape: (492, 6) → (492, 6)\n",
      "\n",
      "--- Analysis for addisababa-minibus\\trips.txt ---\n",
      "Shape: (492, 6)\n",
      "Memory usage: 0.05 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64     5\n",
      "object    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "          trip_id      route_id  service_id      shape_id  direction_id\n",
      "count  492.000000  4.920000e+02       492.0  4.920000e+02    492.000000\n",
      "mean   245.500000  1.591495e+07         0.0  1.591318e+07      0.497967\n",
      "std    142.172431  6.189762e+04         0.0  6.235302e+04      0.500505\n",
      "min      0.000000  1.574866e+07         0.0  1.573603e+07      0.000000\n",
      "25%    122.750000  1.587672e+07         0.0  1.587162e+07      0.000000\n",
      "50%    245.500000  1.591038e+07         0.0  1.591025e+07      0.000000\n",
      "75%    368.250000  1.596210e+07         0.0  1.596202e+07      1.000000\n",
      "max    491.000000  1.602889e+07         0.0  1.600831e+07      1.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "trip_headsign:\n",
      "trip_headsign\n",
      "Megenagna       30\n",
      "Piassa Arada    23\n",
      "Mexico          20\n",
      "Autobus Tera    18\n",
      "Bole Bridge     15\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   trip_id  route_id  service_id  shape_id  direction_id  \\\n",
      "0        0  15748658           0  15736031             0   \n",
      "1        1  15748658           0  15736031             1   \n",
      "2        2  15748658           0  15736031             0   \n",
      "3        3  15748658           0  15736031             1   \n",
      "4        4  15748658           0  15736031             0   \n",
      "\n",
      "           trip_headsign  \n",
      "0                Olympia  \n",
      "1           Agona Cinema  \n",
      "2  Total 3 Kuter Mazoria  \n",
      "3                   Kera  \n",
      "4            Wello Sefer  \n",
      "✓ Saved cleaned data to: cleaned_data\\addisababa-minibus\\cleaned_trips.csv\n",
      "\n",
      "==================================================\n",
      "Processing: alexendria\\agency.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (5, 4)\n",
      "\n",
      "Cleaning data for alexendria\\agency.txt...\n",
      "  - Converted 'agency_timezone' to datetime\n",
      "  ✓ Cleaned data shape: (5, 4) → (5, 4)\n",
      "\n",
      "--- Analysis for alexendria\\agency.txt ---\n",
      "Shape: (5, 4)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "Missing values:\n",
      "agency_timezone    5\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "object            3\n",
      "datetime64[ns]    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "agency_id:\n",
      "agency_id\n",
      "P_B_8      1\n",
      "P_O_14     1\n",
      "COOP       1\n",
      "Minibus    1\n",
      "Bus        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_name:\n",
      "agency_name\n",
      "Paratransit 8 Seater Suzuki Chevrolet or DMF (Blue Licenseplates)    1\n",
      "Paratransit 14 Seater Microbus (Orange Licenseplates)                1\n",
      "Cooperative paratransit 29 Seater (Grey Licenseplates)               1\n",
      "LTRA                                                                 1\n",
      "APTA                                                                 1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_url:\n",
      "agency_url\n",
      "https://digitaltransport4africa.org/    5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  agency_id                                        agency_name  \\\n",
      "0     P_B_8  Paratransit 8 Seater Suzuki Chevrolet or DMF (...   \n",
      "1    P_O_14  Paratransit 14 Seater Microbus (Orange License...   \n",
      "2      COOP  Cooperative paratransit 29 Seater (Grey Licens...   \n",
      "3   Minibus                                               LTRA   \n",
      "4       Bus                                               APTA   \n",
      "\n",
      "                             agency_url agency_timezone  \n",
      "0  https://digitaltransport4africa.org/             NaT  \n",
      "1  https://digitaltransport4africa.org/             NaT  \n",
      "2  https://digitaltransport4africa.org/             NaT  \n",
      "3  https://digitaltransport4africa.org/             NaT  \n",
      "4  https://digitaltransport4africa.org/             NaT  \n",
      "✓ Saved cleaned data to: cleaned_data\\alexendria\\cleaned_agency.csv\n",
      "\n",
      "==================================================\n",
      "Processing: alexendria\\calendar.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 10)\n",
      "\n",
      "Cleaning data for alexendria\\calendar.txt...\n",
      "  - Converted 'start_date' to datetime\n",
      "  - Converted 'end_date' to datetime\n",
      "  ✓ Cleaned data shape: (1, 10) → (1, 10)\n",
      "\n",
      "--- Analysis for alexendria\\calendar.txt ---\n",
      "Shape: (1, 10)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64             7\n",
      "datetime64[ns]    2\n",
      "object            1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       monday  tuesday  wednesday  thursday  friday  saturday  sunday\n",
      "count     1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "mean      1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "std       NaN      NaN        NaN       NaN     NaN       NaN     NaN\n",
      "min       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "25%       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "50%       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "75%       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "max       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "service_id:\n",
      "service_id\n",
      "Ground_Daily    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   monday  tuesday  wednesday  thursday  friday  saturday  sunday  \\\n",
      "0       1        1          1         1       1         1       1   \n",
      "\n",
      "                     start_date                      end_date    service_id  \n",
      "0 1970-01-01 00:00:00.020230101 1970-01-01 00:00:00.020231230  Ground_Daily  \n",
      "✓ Saved cleaned data to: cleaned_data\\alexendria\\cleaned_calendar.csv\n",
      "\n",
      "==================================================\n",
      "Processing: alexendria\\feed_info.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 7)\n",
      "\n",
      "Cleaning data for alexendria\\feed_info.txt...\n",
      "  - Converted 'feed_start_date' to datetime\n",
      "  - Converted 'feed_end_date' to datetime\n",
      "  ✓ Cleaned data shape: (1, 7) → (1, 7)\n",
      "\n",
      "--- Analysis for alexendria\\feed_info.txt ---\n",
      "Shape: (1, 7)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object            5\n",
      "datetime64[ns]    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "feed_publisher_name:\n",
      "feed_publisher_name\n",
      "DigitalTransport4Africa    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_publisher_url:\n",
      "feed_publisher_url\n",
      "https://digitaltransport4africa.org/    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_contact_url:\n",
      "feed_contact_url\n",
      "https://digitaltransport4africa.org/    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_version:\n",
      "feed_version\n",
      "alex_dt4a    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_lang:\n",
      "feed_lang\n",
      "en    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "       feed_publisher_name                    feed_publisher_url  \\\n",
      "0  DigitalTransport4Africa  https://digitaltransport4africa.org/   \n",
      "\n",
      "                       feed_contact_url               feed_start_date  \\\n",
      "0  https://digitaltransport4africa.org/ 1970-01-01 00:00:00.020230101   \n",
      "\n",
      "                  feed_end_date feed_version feed_lang  \n",
      "0 1970-01-01 00:00:00.020240101    alex_dt4a        en  \n",
      "✓ Saved cleaned data to: cleaned_data\\alexendria\\cleaned_feed_info.csv\n",
      "\n",
      "==================================================\n",
      "Processing: alexendria\\frequencies.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (192, 4)\n",
      "\n",
      "Cleaning data for alexendria\\frequencies.txt...\n",
      "  - Converted 'start_time' to datetime\n",
      "  - Converted 'end_time' to datetime\n",
      "  - Capped 28 outliers in 'headway_secs'\n",
      "  ✓ Cleaned data shape: (192, 4) → (192, 4)\n",
      "\n",
      "--- Analysis for alexendria\\frequencies.txt ---\n",
      "Shape: (192, 4)\n",
      "Memory usage: 0.02 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "datetime64[ns]    2\n",
      "object            1\n",
      "int64             1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       headway_secs\n",
      "count    192.000000\n",
      "mean     342.875000\n",
      "std      235.063019\n",
      "min       60.000000\n",
      "25%      180.000000\n",
      "50%      300.000000\n",
      "75%      420.000000\n",
      "max      780.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "OvxARhItfijPV-_xuvfnZ-07:00:00    1\n",
      "7OIDYqQb_VCEwYHFGH_e5-07:00:00    1\n",
      "zivMUtHDofqSlzEUoK8F0-07:00:00    1\n",
      "Hn0eoDFbdIiLk49QaqFeX-07:00:00    1\n",
      "OI7bd_u7laDmk8SxgppK0-07:00:00    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "                          trip_id          start_time            end_time  \\\n",
      "0  OvxARhItfijPV-_xuvfnZ-07:00:00 2025-08-11 07:00:00 2025-08-11 22:00:00   \n",
      "1  7OIDYqQb_VCEwYHFGH_e5-07:00:00 2025-08-11 07:00:00 2025-08-11 22:00:00   \n",
      "2  zivMUtHDofqSlzEUoK8F0-07:00:00 2025-08-11 07:00:00 2025-08-11 22:00:00   \n",
      "3  Hn0eoDFbdIiLk49QaqFeX-07:00:00 2025-08-11 07:00:00 2025-08-11 22:00:00   \n",
      "4  OI7bd_u7laDmk8SxgppK0-07:00:00 2025-08-11 07:00:00 2025-08-11 22:00:00   \n",
      "\n",
      "   headway_secs  \n",
      "0            60  \n",
      "1            60  \n",
      "2           360  \n",
      "3           540  \n",
      "4           120  \n",
      "✓ Saved cleaned data to: cleaned_data\\alexendria\\cleaned_frequencies.csv\n",
      "\n",
      "==================================================\n",
      "Processing: alexendria\\routes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (104, 7)\n",
      "\n",
      "Cleaning data for alexendria\\routes.txt...\n",
      "  ✓ Cleaned data shape: (104, 7) → (104, 7)\n",
      "\n",
      "--- Analysis for alexendria\\routes.txt ---\n",
      "Shape: (104, 7)\n",
      "Memory usage: 0.03 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object    4\n",
      "int64     3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       route_type  continuous_pickup  continuous_drop_off\n",
      "count       104.0              104.0                104.0\n",
      "mean          3.0                1.0                  1.0\n",
      "std           0.0                0.0                  0.0\n",
      "min           3.0                1.0                  1.0\n",
      "25%           3.0                1.0                  1.0\n",
      "50%           3.0                1.0                  1.0\n",
      "75%           3.0                1.0                  1.0\n",
      "max           3.0                1.0                  1.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "route_id:\n",
      "route_id\n",
      "I46ZQc9g0OMvTpnnq0RXs    1\n",
      "tv4mLSYvBC5Q4aSnL5h83    1\n",
      "d591FuxnMulU7vr6uNxrB    1\n",
      "ruQq1su0J7bVhBjmIi2kw    1\n",
      "dpTyJ7ihIOXu0gGo2F3iz    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_id:\n",
      "agency_id\n",
      "P_O_14     74\n",
      "P_B_8      13\n",
      "Bus        12\n",
      "Minibus     5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_long_name:\n",
      "route_long_name\n",
      "Asafra - Train Station (El-Shohada Square)     3\n",
      "El-Awayed - El-Sa'ah (Clock Square)            2\n",
      "El-Awayed - Sidi Gabir                         2\n",
      "Al-Maraghi - El-Awayed                         2\n",
      "Abu Qir - Train Station (El-Shohada Square)    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_short_name:\n",
      "route_short_name\n",
      "Microbus    74\n",
      "Tomnaya     13\n",
      "Bus 480      1\n",
      "Bus 739      1\n",
      "Bus 735      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "                route_id agency_id                   route_long_name  \\\n",
      "0  I46ZQc9g0OMvTpnnq0RXs    P_O_14               Asafra - Sidi Bishr   \n",
      "1  tv4mLSYvBC5Q4aSnL5h83    P_O_14       Asafra - El-Mawqaf El-Geded   \n",
      "2  d591FuxnMulU7vr6uNxrB    P_O_14                    Asafra - Hadra   \n",
      "3  ruQq1su0J7bVhBjmIi2kw    P_O_14              Asafra - El-Mansheya   \n",
      "4  dpTyJ7ihIOXu0gGo2F3iz    P_O_14  Asafra - El-Sa'ah (Clock Square)   \n",
      "\n",
      "  route_short_name  route_type  continuous_pickup  continuous_drop_off  \n",
      "0         Microbus           3                  1                    1  \n",
      "1         Microbus           3                  1                    1  \n",
      "2         Microbus           3                  1                    1  \n",
      "3         Microbus           3                  1                    1  \n",
      "4         Microbus           3                  1                    1  \n",
      "✓ Saved cleaned data to: cleaned_data\\alexendria\\cleaned_routes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: alexendria\\shapes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (29358, 4)\n",
      "\n",
      "Cleaning data for alexendria\\shapes.txt...\n",
      "  - Capped 282 outliers in 'shape_pt_sequence'\n",
      "  - Capped 2024 outliers in 'shape_pt_lat'\n",
      "  - Capped 1221 outliers in 'shape_pt_lon'\n",
      "  ✓ Cleaned data shape: (29358, 4) → (29358, 4)\n",
      "\n",
      "--- Analysis for alexendria\\shapes.txt ---\n",
      "Shape: (29358, 4)\n",
      "Memory usage: 3.02 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "float64    2\n",
      "object     1\n",
      "int64      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       shape_pt_sequence  shape_pt_lat  shape_pt_lon\n",
      "count       29358.000000  29358.000000  29358.000000\n",
      "mean          111.860685     31.200490     29.930145\n",
      "std            85.575006      0.052025      0.065542\n",
      "min             1.000000     31.087677     29.779712\n",
      "25%            41.000000     31.179520     29.900735\n",
      "50%            94.000000     31.204644     29.935609\n",
      "75%           165.000000     31.240749     29.981417\n",
      "max           351.000000     31.321844     30.072326\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "shape_id:\n",
      "shape_id\n",
      "RmCIDxJQKwF7GOCKKX3Oh_Shape    428\n",
      "MrihzTWrnXBOK-ItJhoR8_Shape    419\n",
      "LYcY_J8e-Dijvjm6uZhgZ_Shape    419\n",
      "J3ADe7YQWUaBHH8Z_00Ou_Shape    381\n",
      "NP0r90PJ04dzhZ4-fQdAY_Shape    368\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "                      shape_id  shape_pt_sequence  shape_pt_lat  shape_pt_lon\n",
      "0  OvxARhItfijPV-_xuvfnZ_Shape                  1     31.256244     29.993791\n",
      "1  OvxARhItfijPV-_xuvfnZ_Shape                  2     31.255878     29.994113\n",
      "2  OvxARhItfijPV-_xuvfnZ_Shape                  3     31.256315     29.994751\n",
      "3  OvxARhItfijPV-_xuvfnZ_Shape                  4     31.257380     29.996027\n",
      "4  OvxARhItfijPV-_xuvfnZ_Shape                  5     31.257719     29.995686\n",
      "✓ Saved cleaned data to: cleaned_data\\alexendria\\cleaned_shapes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: alexendria\\stops.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (441, 4)\n",
      "\n",
      "Cleaning data for alexendria\\stops.txt...\n",
      "  - Capped 25 outliers in 'stop_lat'\n",
      "  - Capped 6 outliers in 'stop_lon'\n",
      "  ✓ Cleaned data shape: (441, 4) → (441, 4)\n",
      "\n",
      "--- Analysis for alexendria\\stops.txt ---\n",
      "Shape: (441, 4)\n",
      "Memory usage: 0.04 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "float64    2\n",
      "int64      1\n",
      "object     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "          stop_id    stop_lat    stop_lon\n",
      "count  441.000000  441.000000  441.000000\n",
      "mean   223.859410   31.203577   29.931327\n",
      "std    129.187841    0.065617    0.087965\n",
      "min      1.000000   31.065325   29.717785\n",
      "25%    112.000000   31.178913   29.885535\n",
      "50%    223.000000   31.210804   29.948260\n",
      "75%    336.000000   31.254638   29.997369\n",
      "max    447.000000   31.320357   30.071091\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "stop_name:\n",
      "stop_name\n",
      "El Awayed                      7\n",
      "El Saah Square                 6\n",
      "Kilo 21                        5\n",
      "Sidi Gaber Station             5\n",
      "Train Station (Al Shohadaa)    5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   stop_id                  stop_name   stop_lat   stop_lon\n",
      "0        1  Borg Al-Arab Old Terminal  31.065325  29.717785\n",
      "1        2              Baheeg Square  31.065325  29.717785\n",
      "2        3            Al-Marwa Mosque  31.065325  29.717785\n",
      "3        4  Baheeg Traffic Department  31.065325  29.717785\n",
      "4        5               King Heights  31.065325  29.717785\n",
      "✓ Saved cleaned data to: cleaned_data\\alexendria\\cleaned_stops.csv\n",
      "\n",
      "==================================================\n",
      "Processing: alexendria\\stop_times.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (2547, 6)\n",
      "\n",
      "Cleaning data for alexendria\\stop_times.txt...\n",
      "  - Converted 'arrival_time' to datetime\n",
      "  - Converted 'departure_time' to datetime\n",
      "  - Converted 'timepoint' to datetime\n",
      "  - Capped 108 outliers in 'stop_sequence'\n",
      "  ✓ Cleaned data shape: (2547, 6) → (2547, 6)\n",
      "\n",
      "--- Analysis for alexendria\\stop_times.txt ---\n",
      "Shape: (2547, 6)\n",
      "Memory usage: 0.31 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "datetime64[ns]    3\n",
      "int64             2\n",
      "object            1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "           stop_id  stop_sequence\n",
      "count  2547.000000    2547.000000\n",
      "mean    237.499018      11.323518\n",
      "std     115.329346       9.282285\n",
      "min       1.000000       1.000000\n",
      "25%     164.500000       4.000000\n",
      "50%     229.000000       9.000000\n",
      "75%     329.000000      16.000000\n",
      "max     447.000000      34.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "RmCIDxJQKwF7GOCKKX3Oh-07:00:00    54\n",
      "LYcY_J8e-Dijvjm6uZhgZ-07:00:00    52\n",
      "Z-51SkRkO5YyfPeYNTS-n-07:00:00    50\n",
      "iGgUl6NwJYqGWhVkUHdiu-07:00:00    42\n",
      "Cl-oT7WLLDtvd9UF3t3WF-07:00:00    41\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "                          trip_id  stop_id  stop_sequence        arrival_time  \\\n",
      "0  _npHlyCCY7o0R20RyqvT8-07:00:00      189              1 2025-08-11 07:00:00   \n",
      "1  _npHlyCCY7o0R20RyqvT8-07:00:00      192              2 2025-08-11 07:04:58   \n",
      "2  _npHlyCCY7o0R20RyqvT8-07:00:00      197              3 2025-08-11 07:07:07   \n",
      "3  _npHlyCCY7o0R20RyqvT8-07:00:00      412              4 2025-08-11 07:11:09   \n",
      "4  _npHlyCCY7o0R20RyqvT8-07:00:00      411              5 2025-08-11 07:15:53   \n",
      "\n",
      "       departure_time  timepoint  \n",
      "0 2025-08-11 07:00:15 1970-01-01  \n",
      "1 2025-08-11 07:05:13 1970-01-01  \n",
      "2 2025-08-11 07:07:22 1970-01-01  \n",
      "3 2025-08-11 07:11:24 1970-01-01  \n",
      "4 2025-08-11 07:16:08 1970-01-01  \n",
      "✓ Saved cleaned data to: cleaned_data\\alexendria\\cleaned_stop_times.csv\n",
      "\n",
      "==================================================\n",
      "Processing: alexendria\\trips.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (192, 6)\n",
      "\n",
      "Cleaning data for alexendria\\trips.txt...\n",
      "  ✓ Cleaned data shape: (192, 6) → (192, 6)\n",
      "\n",
      "--- Analysis for alexendria\\trips.txt ---\n",
      "Shape: (192, 6)\n",
      "Memory usage: 0.07 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object    5\n",
      "int64     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       direction_id\n",
      "count    192.000000\n",
      "mean       0.494792\n",
      "std        0.501280\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        1.000000\n",
      "max        1.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "route_id:\n",
      "route_id\n",
      "I46ZQc9g0OMvTpnnq0RXs    2\n",
      "tv4mLSYvBC5Q4aSnL5h83    2\n",
      "d591FuxnMulU7vr6uNxrB    2\n",
      "ruQq1su0J7bVhBjmIi2kw    2\n",
      "dpTyJ7ihIOXu0gGo2F3iz    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "service_id:\n",
      "service_id\n",
      "Ground_Daily    192\n",
      "Name: count, dtype: int64\n",
      "\n",
      "trip_headsign:\n",
      "trip_headsign\n",
      "Train Station (El-Shohada Square)    22\n",
      "El-Awayed                            19\n",
      "El-Mansheya                          15\n",
      "El-Mawqaf El-Geded                   15\n",
      "El-Sa'ah (Clock Square)              12\n",
      "Name: count, dtype: int64\n",
      "\n",
      "shape_id:\n",
      "shape_id\n",
      "OvxARhItfijPV-_xuvfnZ_Shape    1\n",
      "zivMUtHDofqSlzEUoK8F0_Shape    1\n",
      "Wq0wtD2-ddsT-JtVfCc3g_Shape    1\n",
      "OI7bd_u7laDmk8SxgppK0_Shape    1\n",
      "I2ar40PiiuS-HMI9_KCLc_Shape    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "OvxARhItfijPV-_xuvfnZ-07:00:00    1\n",
      "zivMUtHDofqSlzEUoK8F0-07:00:00    1\n",
      "Wq0wtD2-ddsT-JtVfCc3g-07:00:00    1\n",
      "OI7bd_u7laDmk8SxgppK0-07:00:00    1\n",
      "I2ar40PiiuS-HMI9_KCLc-07:00:00    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "                route_id    service_id trip_headsign  direction_id  \\\n",
      "0  I46ZQc9g0OMvTpnnq0RXs  Ground_Daily        Asafra             1   \n",
      "1  tv4mLSYvBC5Q4aSnL5h83  Ground_Daily        Asafra             1   \n",
      "2  d591FuxnMulU7vr6uNxrB  Ground_Daily        Asafra             0   \n",
      "3  ruQq1su0J7bVhBjmIi2kw  Ground_Daily        Asafra             1   \n",
      "4  dpTyJ7ihIOXu0gGo2F3iz  Ground_Daily        Asafra             1   \n",
      "\n",
      "                      shape_id                         trip_id  \n",
      "0  OvxARhItfijPV-_xuvfnZ_Shape  OvxARhItfijPV-_xuvfnZ-07:00:00  \n",
      "1  zivMUtHDofqSlzEUoK8F0_Shape  zivMUtHDofqSlzEUoK8F0-07:00:00  \n",
      "2  Wq0wtD2-ddsT-JtVfCc3g_Shape  Wq0wtD2-ddsT-JtVfCc3g-07:00:00  \n",
      "3  OI7bd_u7laDmk8SxgppK0_Shape  OI7bd_u7laDmk8SxgppK0-07:00:00  \n",
      "4  I2ar40PiiuS-HMI9_KCLc_Shape  I2ar40PiiuS-HMI9_KCLc-07:00:00  \n",
      "✓ Saved cleaned data to: cleaned_data\\alexendria\\cleaned_trips.csv\n",
      "\n",
      "==================================================\n",
      "Processing: bamako\\agency.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 8)\n",
      "\n",
      "Cleaning data for bamako\\agency.txt...\n",
      "  - Converted 'agency_timezone' to datetime\n",
      "  ✓ Cleaned data shape: (1, 8) → (1, 7)\n",
      "\n",
      "--- Analysis for bamako\\agency.txt ---\n",
      "Shape: (1, 7)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "Missing values:\n",
      "agency_timezone    1\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "object            5\n",
      "datetime64[ns]    1\n",
      "int64             1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       agency_phone\n",
      "count  1.000000e+00\n",
      "mean   2.237368e+10\n",
      "std             NaN\n",
      "min    2.237368e+10\n",
      "25%    2.237368e+10\n",
      "50%    2.237368e+10\n",
      "75%    2.237368e+10\n",
      "max    2.237368e+10\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "agency_id:\n",
      "agency_id\n",
      "sotrama_bko    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_name:\n",
      "agency_name\n",
      "Sotrama Bamako    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_url:\n",
      "agency_url\n",
      "https://billetexpress.ml    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_lang:\n",
      "agency_lang\n",
      "fr    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_email:\n",
      "agency_email\n",
      "info@billetexpress.ml    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "     agency_id     agency_name                agency_url agency_timezone  \\\n",
      "0  sotrama_bko  Sotrama Bamako  https://billetexpress.ml             NaT   \n",
      "\n",
      "  agency_lang  agency_phone           agency_email  \n",
      "0          fr   22373678423  info@billetexpress.ml  \n",
      "✓ Saved cleaned data to: cleaned_data\\bamako\\cleaned_agency.csv\n",
      "\n",
      "==================================================\n",
      "Processing: bamako\\calendar.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 10)\n",
      "\n",
      "Cleaning data for bamako\\calendar.txt...\n",
      "  - Converted 'start_date' to datetime\n",
      "  - Converted 'end_date' to datetime\n",
      "  ✓ Cleaned data shape: (1, 10) → (1, 10)\n",
      "\n",
      "--- Analysis for bamako\\calendar.txt ---\n",
      "Shape: (1, 10)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64             7\n",
      "datetime64[ns]    2\n",
      "object            1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       monday  tuesday  wednesday  thursday  friday  saturday  sunday\n",
      "count     1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "mean      1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "std       NaN      NaN        NaN       NaN     NaN       NaN     NaN\n",
      "min       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "25%       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "50%       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "75%       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "max       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "service_id:\n",
      "service_id\n",
      "MON-SUN    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  service_id  monday  tuesday  wednesday  thursday  friday  saturday  sunday  \\\n",
      "0    MON-SUN       1        1          1         1       1         1       1   \n",
      "\n",
      "                     start_date                      end_date  \n",
      "0 1970-01-01 00:00:00.020191201 1970-01-01 00:00:00.020220131  \n",
      "✓ Saved cleaned data to: cleaned_data\\bamako\\cleaned_calendar.csv\n",
      "\n",
      "==================================================\n",
      "Processing: bamako\\calendar_dates.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (0, 3)\n",
      "⚠ Warning: bamako\\calendar_dates.txt could not be parsed into multiple columns\n",
      "\n",
      "==================================================\n",
      "Processing: bamako\\feed_info.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 6)\n",
      "\n",
      "Cleaning data for bamako\\feed_info.txt...\n",
      "  - Converted 'feed_start_date' to datetime\n",
      "  - Converted 'feed_end_date' to datetime\n",
      "  ✓ Cleaned data shape: (1, 6) → (1, 6)\n",
      "\n",
      "--- Analysis for bamako\\feed_info.txt ---\n",
      "Shape: (1, 6)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object            3\n",
      "datetime64[ns]    2\n",
      "float64           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       feed_version\n",
      "count           1.0\n",
      "mean            2.0\n",
      "std             NaN\n",
      "min             2.0\n",
      "25%             2.0\n",
      "50%             2.0\n",
      "75%             2.0\n",
      "max             2.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "feed_publisher_name:\n",
      "feed_publisher_name\n",
      "Data Transport    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_lang:\n",
      "feed_lang\n",
      "fr    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_publisher_url:\n",
      "feed_publisher_url\n",
      "https://www.data-transport.org    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  feed_publisher_name               feed_start_date  feed_version  \\\n",
      "0      Data Transport 1970-01-01 00:00:00.020191201           2.0   \n",
      "\n",
      "                  feed_end_date feed_lang              feed_publisher_url  \n",
      "0 1970-01-01 00:00:00.020220131        fr  https://www.data-transport.org  \n",
      "✓ Saved cleaned data to: cleaned_data\\bamako\\cleaned_feed_info.csv\n",
      "\n",
      "==================================================\n",
      "Processing: bamako\\frequencies.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (210, 5)\n",
      "\n",
      "Cleaning data for bamako\\frequencies.txt...\n",
      "  - Converted 'start_time' to datetime\n",
      "  - Converted 'end_time' to datetime\n",
      "  ✓ Cleaned data shape: (210, 5) → (210, 4)\n",
      "\n",
      "--- Analysis for bamako\\frequencies.txt ---\n",
      "Shape: (210, 4)\n",
      "Memory usage: 0.02 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "datetime64[ns]    2\n",
      "object            1\n",
      "int64             1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       headway_secs\n",
      "count         210.0\n",
      "mean          600.0\n",
      "std             0.0\n",
      "min           600.0\n",
      "25%           600.0\n",
      "50%           600.0\n",
      "75%           600.0\n",
      "max           600.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "TI1576360557    1\n",
      "TI1576361613    1\n",
      "TI1576362266    1\n",
      "TI1576362888    1\n",
      "TI1576363086    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "        trip_id          start_time            end_time  headway_secs\n",
      "0  TI1576360557 2025-08-11 05:00:00 2025-08-11 23:00:00           600\n",
      "1  TI1576361613 2025-08-11 05:00:00 2025-08-11 23:00:00           600\n",
      "2  TI1576362266 2025-08-11 05:00:00 2025-08-11 23:00:00           600\n",
      "3  TI1576362888 2025-08-11 05:00:00 2025-08-11 23:00:00           600\n",
      "4  TI1576363086 2025-08-11 05:00:00 2025-08-11 23:00:00           600\n",
      "✓ Saved cleaned data to: cleaned_data\\bamako\\cleaned_frequencies.csv\n",
      "\n",
      "==================================================\n",
      "Processing: bamako\\routes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (105, 10)\n",
      "\n",
      "Cleaning data for bamako\\routes.txt...\n",
      "  ✓ Cleaned data shape: (105, 10) → (105, 5)\n",
      "\n",
      "--- Analysis for bamako\\routes.txt ---\n",
      "Shape: (105, 5)\n",
      "Memory usage: 0.03 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object    3\n",
      "int64     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       route_short_name  route_type\n",
      "count        105.000000       105.0\n",
      "mean          53.000000         3.0\n",
      "std           30.454885         0.0\n",
      "min            1.000000         3.0\n",
      "25%           27.000000         3.0\n",
      "50%           53.000000         3.0\n",
      "75%           79.000000         3.0\n",
      "max          105.000000         3.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "route_id:\n",
      "route_id\n",
      "Sotrama.L1    1\n",
      "Sotrama.L2    1\n",
      "Sotrama.L6    1\n",
      "Sotrama.L7    1\n",
      "Sotrama.L8    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_id:\n",
      "agency_id\n",
      "sotrama_bko    105\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_long_name:\n",
      "route_long_name\n",
      "Sotrama 1 : Railda ⇄ Sangarébougou          1\n",
      "Sotrama 2 : Railda ⇄ Marseille              1\n",
      "Sotrama 6 : Doumanzana_Nafadji ⇄ Railda     1\n",
      "Sotrama 7 : Fadjiguila_Zèrèbatou ⇄ Raida    1\n",
      "Sotrama 8 : Fadjiguila-Fèrè ⇄ Railda        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "     route_id    agency_id  route_short_name  \\\n",
      "0  Sotrama.L1  sotrama_bko                 1   \n",
      "1  Sotrama.L2  sotrama_bko                 2   \n",
      "2  Sotrama.L6  sotrama_bko                 6   \n",
      "3  Sotrama.L7  sotrama_bko                 7   \n",
      "4  Sotrama.L8  sotrama_bko                 8   \n",
      "\n",
      "                            route_long_name  route_type  \n",
      "0        Sotrama 1 : Railda ⇄ Sangarébougou           3  \n",
      "1            Sotrama 2 : Railda ⇄ Marseille           3  \n",
      "2   Sotrama 6 : Doumanzana_Nafadji ⇄ Railda           3  \n",
      "3  Sotrama 7 : Fadjiguila_Zèrèbatou ⇄ Raida           3  \n",
      "4      Sotrama 8 : Fadjiguila-Fèrè ⇄ Railda           3  \n",
      "✓ Saved cleaned data to: cleaned_data\\bamako\\cleaned_routes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: bamako\\shapes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (50712, 5)\n",
      "\n",
      "Cleaning data for bamako\\shapes.txt...\n",
      "  - Capped 945 outliers in 'shape_pt_lat'\n",
      "  - Capped 2618 outliers in 'shape_pt_lon'\n",
      "  - Capped 735 outliers in 'shape_pt_sequence'\n",
      "  ✓ Cleaned data shape: (50712, 5) → (50712, 4)\n",
      "\n",
      "--- Analysis for bamako\\shapes.txt ---\n",
      "Shape: (50712, 4)\n",
      "Memory usage: 4.55 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "float64    3\n",
      "object     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       shape_pt_lat  shape_pt_lon  shape_pt_sequence\n",
      "count  50712.000000  50712.000000       50712.000000\n",
      "mean      12.619227     -7.989494         137.916933\n",
      "std        0.046910      0.044482          94.933619\n",
      "min       12.494358     -8.085871           1.000000\n",
      "25%       12.587670     -8.012592          61.000000\n",
      "50%       12.624820     -7.996010         123.000000\n",
      "75%       12.649877     -7.963739         198.000000\n",
      "max       12.743189     -7.890459         403.500000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "shape_id:\n",
      "shape_id\n",
      "SHI1577467646    563\n",
      "SHI1577182075    506\n",
      "SHI1577468575    486\n",
      "SHI1576967684    477\n",
      "SHI1577366055    476\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "        shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence\n",
      "0  SHI1576361537     12.650056     -7.993281                1.0\n",
      "1  SHI1576361537     12.650167     -7.992815                2.0\n",
      "2  SHI1576361537     12.650318     -7.992191                3.0\n",
      "3  SHI1576361537     12.650373     -7.991944                4.0\n",
      "4  SHI1576361537     12.650470     -7.991510                5.0\n",
      "✓ Saved cleaned data to: cleaned_data\\bamako\\cleaned_shapes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: bamako\\stops.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (3457, 14)\n",
      "\n",
      "Cleaning data for bamako\\stops.txt...\n",
      "  - Capped 144 outliers in 'stop_id'\n",
      "  - Capped 18 outliers in 'stop_lat'\n",
      "  - Capped 49 outliers in 'stop_lon'\n",
      "  ✓ Cleaned data shape: (3457, 14) → (3457, 5)\n",
      "\n",
      "--- Analysis for bamako\\stops.txt ---\n",
      "Shape: (3457, 5)\n",
      "Memory usage: 0.62 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "float64    3\n",
      "object     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "            stop_id     stop_lat     stop_lon\n",
      "count  3.457000e+03  3457.000000  3457.000000\n",
      "mean   6.976894e+09    12.621817    -7.986941\n",
      "std    5.157485e+07     0.054557     0.052037\n",
      "min    6.845042e+09    12.455685    -8.120782\n",
      "25%    6.951594e+09    12.581540    -8.020236\n",
      "50%    6.960222e+09    12.627281    -7.990448\n",
      "75%    7.022629e+09    12.665443    -7.953204\n",
      "max    7.083578e+09    12.766977    -7.852658\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "stop_name:\n",
      "stop_name\n",
      "Arrêt            283\n",
      "Arrêt Sotrama     87\n",
      "Arret             83\n",
      "Pharmacie Da      32\n",
      "Missiri Da        27\n",
      "Name: count, dtype: int64\n",
      "\n",
      "stop_desc:\n",
      "stop_desc\n",
      "Arrêt BKO            283\n",
      "Arrêt Sotrama BKO     88\n",
      "Arret BKO             83\n",
      "Pharmacie Da BKO      32\n",
      "Missiri Da BKO        27\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "        stop_id      stop_name          stop_desc   stop_lat  stop_lon\n",
      "0  6.954470e+09  Hirondelle Da  Hirondelle Da BKO  12.654686 -7.976516\n",
      "1  6.936887e+09         Railda         Railda BKO  12.650048 -7.993274\n",
      "2  6.936887e+09   Troisième Da   Troisième Da BKO  12.653119 -7.981954\n",
      "3  6.936887e+09     Express Da     Express Da BKO  12.656303 -7.971183\n",
      "4  6.936887e+09      Sirableni      Sirableni BKO  12.657582 -7.967164\n",
      "✓ Saved cleaned data to: cleaned_data\\bamako\\cleaned_stops.csv\n",
      "\n",
      "==================================================\n",
      "Processing: bamako\\stop_times.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (8826, 10)\n",
      "\n",
      "Cleaning data for bamako\\stop_times.txt...\n",
      "  - Converted 'arrival_time' to datetime\n",
      "  - Converted 'departure_time' to datetime\n",
      "  - Capped 2495 outliers in 'stop_id'\n",
      "  - Capped 275 outliers in 'stop_sequence'\n",
      "  ✓ Cleaned data shape: (8826, 10) → (8826, 5)\n",
      "\n",
      "--- Analysis for bamako\\stop_times.txt ---\n",
      "Shape: (8826, 5)\n",
      "Memory usage: 0.85 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "datetime64[ns]    2\n",
      "object            1\n",
      "float64           1\n",
      "int64             1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "            stop_id  stop_sequence\n",
      "count  8.826000e+03    8826.000000\n",
      "mean   6.958674e+09      30.107863\n",
      "std    1.989276e+07      23.762477\n",
      "min    6.922906e+09       1.000000\n",
      "25%    6.948970e+09      11.000000\n",
      "50%    6.955521e+09      24.000000\n",
      "75%    6.966346e+09      43.000000\n",
      "max    6.992411e+09      91.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "TI1577354850    138\n",
      "TI1577202076    125\n",
      "TI1577107909    122\n",
      "TI1577027873    114\n",
      "TI1577202479    114\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "        trip_id        arrival_time      departure_time       stop_id  \\\n",
      "0  TI1577055855 2025-08-11 05:00:00 2025-08-11 05:00:00  6.958399e+09   \n",
      "1  TI1577055855 2025-08-11 05:26:28 2025-08-11 05:26:28  6.952268e+09   \n",
      "2  TI1577108055 2025-08-11 05:00:00 2025-08-11 05:00:00  6.922906e+09   \n",
      "3  TI1577108055 2025-08-11 05:02:06 2025-08-11 05:02:06  6.922906e+09   \n",
      "4  TI1577108055 2025-08-11 05:03:01 2025-08-11 05:03:01  6.980256e+09   \n",
      "\n",
      "   stop_sequence  \n",
      "0              1  \n",
      "1              2  \n",
      "2              1  \n",
      "3              2  \n",
      "4              3  \n",
      "✓ Saved cleaned data to: cleaned_data\\bamako\\cleaned_stop_times.csv\n",
      "\n",
      "==================================================\n",
      "Processing: bamako\\trips.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (210, 10)\n",
      "\n",
      "Cleaning data for bamako\\trips.txt...\n",
      "  ✓ Cleaned data shape: (210, 10) → (210, 6)\n",
      "\n",
      "--- Analysis for bamako\\trips.txt ---\n",
      "Shape: (210, 6)\n",
      "Memory usage: 0.07 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object    5\n",
      "int64     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       direction_id\n",
      "count    210.000000\n",
      "mean       0.500000\n",
      "std        0.501195\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.500000\n",
      "75%        1.000000\n",
      "max        1.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "route_id:\n",
      "route_id\n",
      "Sotrama.L1    2\n",
      "Sotrama.L2    2\n",
      "Sotrama.L6    2\n",
      "Sotrama.L7    2\n",
      "Sotrama.L8    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "service_id:\n",
      "service_id\n",
      "MON-SUN    210\n",
      "Name: count, dtype: int64\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "TI1576360557    1\n",
      "TI1576361613    1\n",
      "TI1576362266    1\n",
      "TI1576362888    1\n",
      "TI1576363086    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "trip_headsign:\n",
      "trip_headsign\n",
      "Worocourou          19\n",
      "Railda              12\n",
      "CICB                 7\n",
      "Sougounikoura        6\n",
      "Tour de lAfrique     5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "shape_id:\n",
      "shape_id\n",
      "SHI1576361537    1\n",
      "SHI1576362584    1\n",
      "SHI1576363245    1\n",
      "SHI1576363863    1\n",
      "SHI1576364065    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "     route_id service_id       trip_id         trip_headsign  direction_id  \\\n",
      "0  Sotrama.L1    MON-SUN  TI1576360557         Sangarébougou             0   \n",
      "1  Sotrama.L2    MON-SUN  TI1576361613             Marseille             0   \n",
      "2  Sotrama.L6    MON-SUN  TI1576362266    Doumanzana_Nafadji             0   \n",
      "3  Sotrama.L7    MON-SUN  TI1576362888  Fadjiguila_Zèrèbatou             0   \n",
      "4  Sotrama.L8    MON-SUN  TI1576363086       Fadjiguila-Fèrè             0   \n",
      "\n",
      "        shape_id  \n",
      "0  SHI1576361537  \n",
      "1  SHI1576362584  \n",
      "2  SHI1576363245  \n",
      "3  SHI1576363863  \n",
      "4  SHI1576364065  \n",
      "✓ Saved cleaned data to: cleaned_data\\bamako\\cleaned_trips.csv\n",
      "\n",
      "==================================================\n",
      "Processing: freetown\\agency.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (4, 8)\n",
      "\n",
      "Cleaning data for freetown\\agency.txt...\n",
      "  - Converted 'agency_timezone' to datetime\n",
      "  ✓ Cleaned data shape: (4, 8) → (4, 5)\n",
      "\n",
      "--- Analysis for freetown\\agency.txt ---\n",
      "Shape: (4, 5)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "Missing values:\n",
      "agency_timezone    4\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "object            4\n",
      "datetime64[ns]    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "agency_id:\n",
      "agency_id\n",
      "Freetown_poda_poda_01       1\n",
      "Freetown_SLRTC_03           1\n",
      "Freetown_Tagrin_Ferry_01    1\n",
      "Freetown_Taxi_Cab_04        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_name:\n",
      "agency_name\n",
      "Freetown Poda-Poda                         1\n",
      "Sierra Leone Road Transport Corporation    1\n",
      "Tagrin Ferry                               1\n",
      "Freetown Taxi Cab                          1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_url:\n",
      "agency_url\n",
      "http://www.whereismytransport.com    4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_lang:\n",
      "agency_lang\n",
      "en    4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "                  agency_id                              agency_name  \\\n",
      "0     Freetown_poda_poda_01                       Freetown Poda-Poda   \n",
      "1         Freetown_SLRTC_03  Sierra Leone Road Transport Corporation   \n",
      "2  Freetown_Tagrin_Ferry_01                             Tagrin Ferry   \n",
      "3      Freetown_Taxi_Cab_04                        Freetown Taxi Cab   \n",
      "\n",
      "                          agency_url agency_timezone agency_lang  \n",
      "0  http://www.whereismytransport.com             NaT          en  \n",
      "1  http://www.whereismytransport.com             NaT          en  \n",
      "2  http://www.whereismytransport.com             NaT          en  \n",
      "3  http://www.whereismytransport.com             NaT          en  \n",
      "✓ Saved cleaned data to: cleaned_data\\freetown\\cleaned_agency.csv\n",
      "\n",
      "==================================================\n",
      "Processing: freetown\\calendar.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (3, 10)\n",
      "\n",
      "Cleaning data for freetown\\calendar.txt...\n",
      "  - Converted 'start_date' to datetime\n",
      "  - Converted 'end_date' to datetime\n",
      "  ✓ Cleaned data shape: (3, 10) → (3, 10)\n",
      "\n",
      "--- Analysis for freetown\\calendar.txt ---\n",
      "Shape: (3, 10)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64             7\n",
      "datetime64[ns]    2\n",
      "object            1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "         monday   tuesday  wednesday  thursday    friday  saturday    sunday\n",
      "count  3.000000  3.000000   3.000000  3.000000  3.000000  3.000000  3.000000\n",
      "mean   0.666667  0.666667   0.666667  0.666667  0.666667  0.666667  0.666667\n",
      "std    0.577350  0.577350   0.577350  0.577350  0.577350  0.577350  0.577350\n",
      "min    0.000000  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "25%    0.500000  0.500000   0.500000  0.500000  0.500000  0.500000  0.500000\n",
      "50%    1.000000  1.000000   1.000000  1.000000  1.000000  1.000000  1.000000\n",
      "75%    1.000000  1.000000   1.000000  1.000000  1.000000  1.000000  1.000000\n",
      "max    1.000000  1.000000   1.000000  1.000000  1.000000  1.000000  1.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "service_id:\n",
      "service_id\n",
      "service_0001    1\n",
      "service_0002    1\n",
      "service_0003    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "     service_id  monday  tuesday  wednesday  thursday  friday  saturday  \\\n",
      "0  service_0001       0        0          0         0       0         1   \n",
      "1  service_0002       1        1          1         1       1         0   \n",
      "2  service_0003       1        1          1         1       1         1   \n",
      "\n",
      "   sunday                    start_date                      end_date  \n",
      "0       1 1970-01-01 00:00:00.020180929 1970-01-01 00:00:00.020191029  \n",
      "1       0 1970-01-01 00:00:00.020180929 1970-01-01 00:00:00.020191029  \n",
      "2       1 1970-01-01 00:00:00.020181108 1970-01-01 00:00:00.020191108  \n",
      "✓ Saved cleaned data to: cleaned_data\\freetown\\cleaned_calendar.csv\n",
      "\n",
      "==================================================\n",
      "Processing: freetown\\fare_attributes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (103, 7)\n",
      "\n",
      "Cleaning data for freetown\\fare_attributes.txt...\n",
      "  - Capped 2 outliers in 'price'\n",
      "  - Capped 2 outliers in 'payment_method'\n",
      "  ✓ Cleaned data shape: (103, 7) → (103, 5)\n",
      "\n",
      "--- Analysis for freetown\\fare_attributes.txt ---\n",
      "Shape: (103, 5)\n",
      "Memory usage: 0.02 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object    3\n",
      "int64     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "             price  payment_method\n",
      "count   103.000000           103.0\n",
      "mean   2121.359223             0.0\n",
      "std     988.204996             0.0\n",
      "min    1500.000000             0.0\n",
      "25%    1500.000000             0.0\n",
      "50%    1500.000000             0.0\n",
      "75%    3000.000000             0.0\n",
      "max    5250.000000             0.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "fare_id:\n",
      "fare_id\n",
      "fare_0001    1\n",
      "fare_0002    1\n",
      "fare_0003    1\n",
      "fare_0004    1\n",
      "fare_0005    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "currency_type:\n",
      "currency_type\n",
      "SLL    103\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_id:\n",
      "agency_id\n",
      "Freetown_poda_poda_01       69\n",
      "Freetown_Taxi_Cab_04        22\n",
      "Freetown_SLRTC_03           10\n",
      "Freetown_Tagrin_Ferry_01     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "     fare_id  price currency_type  payment_method              agency_id\n",
      "0  fare_0001   1500           SLL               0  Freetown_poda_poda_01\n",
      "1  fare_0002   1500           SLL               0  Freetown_poda_poda_01\n",
      "2  fare_0003   1500           SLL               0      Freetown_SLRTC_03\n",
      "3  fare_0004   3000           SLL               0  Freetown_poda_poda_01\n",
      "4  fare_0005   1500           SLL               0   Freetown_Taxi_Cab_04\n",
      "✓ Saved cleaned data to: cleaned_data\\freetown\\cleaned_fare_attributes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: freetown\\fare_rules.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (103, 5)\n",
      "\n",
      "Cleaning data for freetown\\fare_rules.txt...\n",
      "  ✓ Cleaned data shape: (103, 5) → (103, 2)\n",
      "\n",
      "--- Analysis for freetown\\fare_rules.txt ---\n",
      "Shape: (103, 2)\n",
      "Memory usage: 0.01 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "fare_id:\n",
      "fare_id\n",
      "fare_0001    1\n",
      "fare_0002    1\n",
      "fare_0003    1\n",
      "fare_0004    1\n",
      "fare_0005    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_id:\n",
      "route_id\n",
      "route_0001    1\n",
      "route_0002    1\n",
      "route_0003    1\n",
      "route_0004    1\n",
      "route_0005    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "     fare_id    route_id\n",
      "0  fare_0001  route_0001\n",
      "1  fare_0002  route_0002\n",
      "2  fare_0003  route_0003\n",
      "3  fare_0004  route_0004\n",
      "4  fare_0005  route_0005\n",
      "✓ Saved cleaned data to: cleaned_data\\freetown\\cleaned_fare_rules.csv\n",
      "\n",
      "==================================================\n",
      "Processing: freetown\\feed_info.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 6)\n",
      "\n",
      "Cleaning data for freetown\\feed_info.txt...\n",
      "  - Converted 'feed_start_date' to datetime\n",
      "  - Converted 'feed_end_date' to datetime\n",
      "  ✓ Cleaned data shape: (1, 6) → (1, 6)\n",
      "\n",
      "--- Analysis for freetown\\feed_info.txt ---\n",
      "Shape: (1, 6)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object            3\n",
      "datetime64[ns]    2\n",
      "int64             1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       feed_version\n",
      "count           1.0\n",
      "mean            1.0\n",
      "std             NaN\n",
      "min             1.0\n",
      "25%             1.0\n",
      "50%             1.0\n",
      "75%             1.0\n",
      "max             1.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "feed_publisher_name:\n",
      "feed_publisher_name\n",
      "WhereIsMyTransport    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_publisher_url:\n",
      "feed_publisher_url\n",
      "https://www.whereismytransport.com    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_lang:\n",
      "feed_lang\n",
      "en    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  feed_publisher_name                  feed_publisher_url feed_lang  \\\n",
      "0  WhereIsMyTransport  https://www.whereismytransport.com        en   \n",
      "\n",
      "                feed_start_date                 feed_end_date  feed_version  \n",
      "0 1970-01-01 00:00:00.020170920 1970-01-01 00:00:00.020201231             1  \n",
      "✓ Saved cleaned data to: cleaned_data\\freetown\\cleaned_feed_info.csv\n",
      "\n",
      "==================================================\n",
      "Processing: freetown\\frequencies.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (860, 5)\n",
      "\n",
      "Cleaning data for freetown\\frequencies.txt...\n",
      "  - Converted 'start_time' to datetime\n",
      "  - Converted 'end_time' to datetime\n",
      "  - Converted 'exact_times' to datetime\n",
      "  - Capped 44 outliers in 'headway_secs'\n",
      "  ✓ Cleaned data shape: (860, 5) → (860, 5)\n",
      "\n",
      "--- Analysis for freetown\\frequencies.txt ---\n",
      "Shape: (860, 5)\n",
      "Memory usage: 0.08 MB\n",
      "\n",
      "Missing values:\n",
      "end_time    2\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "datetime64[ns]    3\n",
      "object            1\n",
      "int64             1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       headway_secs\n",
      "count    860.000000\n",
      "mean     812.302326\n",
      "std      643.499094\n",
      "min       60.000000\n",
      "25%      300.000000\n",
      "50%      600.000000\n",
      "75%     1200.000000\n",
      "max     2550.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "trip_0388    5\n",
      "trip_0020    5\n",
      "trip_0374    5\n",
      "trip_0372    5\n",
      "trip_0360    5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "     trip_id          start_time            end_time  headway_secs exact_times\n",
      "0  trip_0001 2025-08-11 07:00:00 2025-08-11 10:00:00           300  1970-01-01\n",
      "1  trip_0002 2025-08-11 05:00:00 2025-08-11 07:00:00           480  1970-01-01\n",
      "2  trip_0002 2025-08-11 10:00:00 2025-08-11 16:00:00           480  1970-01-01\n",
      "3  trip_0002 2025-08-11 20:00:00 2025-08-11 22:00:00           480  1970-01-01\n",
      "4  trip_0003 2025-08-11 16:00:00 2025-08-11 20:00:00           600  1970-01-01\n",
      "✓ Saved cleaned data to: cleaned_data\\freetown\\cleaned_frequencies.csv\n",
      "\n",
      "==================================================\n",
      "Processing: freetown\\routes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (103, 9)\n",
      "\n",
      "Cleaning data for freetown\\routes.txt...\n",
      "  - Capped 2 outliers in 'route_type'\n",
      "  ✓ Cleaned data shape: (103, 9) → (103, 6)\n",
      "\n",
      "--- Analysis for freetown\\routes.txt ---\n",
      "Shape: (103, 6)\n",
      "Memory usage: 0.04 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object    5\n",
      "int64     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       route_type\n",
      "count       103.0\n",
      "mean        700.0\n",
      "std           0.0\n",
      "min         700.0\n",
      "25%         700.0\n",
      "50%         700.0\n",
      "75%         700.0\n",
      "max         700.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "route_id:\n",
      "route_id\n",
      "route_0001    1\n",
      "route_0002    1\n",
      "route_0003    1\n",
      "route_0004    1\n",
      "route_0005    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_id:\n",
      "agency_id\n",
      "Freetown_poda_poda_01       69\n",
      "Freetown_Taxi_Cab_04        22\n",
      "Freetown_SLRTC_03           10\n",
      "Freetown_Tagrin_Ferry_01     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_long_name:\n",
      "route_long_name\n",
      "Sackville Street to Wellington    2\n",
      "Lumley to Regent Road             1\n",
      "Calaba Town Eastern Police        1\n",
      "Bombay to Waterloo                1\n",
      "Lumley to Aberdeen Village        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_color:\n",
      "route_color\n",
      "AAC904    3\n",
      "C95304    2\n",
      "C90416    2\n",
      "04C98D    2\n",
      "C9BD04    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_text_color:\n",
      "route_text_color\n",
      "000000    53\n",
      "FFFFFF    50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "     route_id              agency_id                route_long_name  \\\n",
      "0  route_0001  Freetown_poda_poda_01          Lumley to Regent Road   \n",
      "1  route_0002  Freetown_poda_poda_01  Congo Town to Goderich Street   \n",
      "2  route_0003      Freetown_SLRTC_03     Calaba Town Eastern Police   \n",
      "3  route_0004  Freetown_poda_poda_01             Bombay to Waterloo   \n",
      "4  route_0005   Freetown_Taxi_Cab_04     Lumley to Aberdeen Village   \n",
      "\n",
      "   route_type route_color route_text_color  \n",
      "0         700      0EC904           000000  \n",
      "1         700      4CC904           000000  \n",
      "2         700      048AC9           000000  \n",
      "3         700      04C98D           000000  \n",
      "4         700      C90408           FFFFFF  \n",
      "✓ Saved cleaned data to: cleaned_data\\freetown\\cleaned_routes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: freetown\\shapes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (29641, 5)\n",
      "\n",
      "Cleaning data for freetown\\shapes.txt...\n",
      "  - Capped 2363 outliers in 'shape_pt_lat'\n",
      "  - Capped 643 outliers in 'shape_pt_lon'\n",
      "  - Capped 1694 outliers in 'shape_pt_sequence'\n",
      "  - Capped 6114 outliers in 'shape_dist_traveled'\n",
      "  ✓ Cleaned data shape: (29641, 5) → (29641, 5)\n",
      "\n",
      "--- Analysis for freetown\\shapes.txt ---\n",
      "Shape: (29641, 5)\n",
      "Memory usage: 2.81 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "float64    3\n",
      "object     1\n",
      "int64      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       shape_pt_lat  shape_pt_lon  shape_pt_sequence  shape_dist_traveled\n",
      "count  29641.000000  29641.000000       29641.000000         29641.000000\n",
      "mean       8.464273    -13.215767         139.783779         13033.035120\n",
      "std        0.024746      0.037406         108.785479         14828.199404\n",
      "min        8.409420    -13.293041           0.000000             0.000000\n",
      "25%        8.452980    -13.244200          55.000000          2622.000000\n",
      "50%        8.474470    -13.219160         115.000000          5747.000000\n",
      "75%        8.482020    -13.192810         193.000000         17737.000000\n",
      "max        8.516630    -13.115725         400.000000         40409.500000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "shape_id:\n",
      "shape_id\n",
      "shape_0047    623\n",
      "shape_0058    619\n",
      "shape_0076    603\n",
      "shape_0023    598\n",
      "shape_0004    589\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "       shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence  \\\n",
      "0  route_0032_1       8.44450     -13.16181                  0   \n",
      "1  route_0032_1       8.44467     -13.16194                  1   \n",
      "2  route_0032_1       8.44507     -13.16227                  2   \n",
      "3  route_0032_1       8.44579     -13.16290                  3   \n",
      "4  route_0032_1       8.44647     -13.16352                  4   \n",
      "\n",
      "   shape_dist_traveled  \n",
      "0                  0.0  \n",
      "1                 23.0  \n",
      "2                 80.0  \n",
      "3                186.0  \n",
      "4                288.0  \n",
      "✓ Saved cleaned data to: cleaned_data\\freetown\\cleaned_shapes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: freetown\\stops.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (843, 12)\n",
      "\n",
      "Cleaning data for freetown\\stops.txt...\n",
      "  - Dropped column 'parent_station' (>70.0% missing)\n",
      "  - Capped 50 outliers in 'stop_lat'\n",
      "  - Capped 28 outliers in 'stop_lon'\n",
      "  - Capped 16 outliers in 'location_type'\n",
      "  ✓ Cleaned data shape: (843, 12) → (843, 5)\n",
      "\n",
      "--- Analysis for freetown\\stops.txt ---\n",
      "Shape: (843, 5)\n",
      "Memory usage: 0.13 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object     2\n",
      "float64    2\n",
      "int64      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "         stop_lat    stop_lon  location_type\n",
      "count  843.000000  843.000000          843.0\n",
      "mean     8.455266  -13.216062            0.0\n",
      "std      0.036340    0.044986            0.0\n",
      "min      8.372450  -13.288040            0.0\n",
      "25%      8.438210  -13.249710            0.0\n",
      "50%      8.470490  -13.224660            0.0\n",
      "75%      8.482050  -13.188680            0.0\n",
      "max      8.516620  -13.097135            0.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "stop_id:\n",
      "stop_id\n",
      "hub_0001    1\n",
      "hub_0002    1\n",
      "hub_0003    1\n",
      "hub_0004    1\n",
      "hub_0005    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "stop_name:\n",
      "stop_name\n",
      "PWD               9\n",
      "Wilberforce       8\n",
      "Shell             8\n",
      "Ferry Junction    8\n",
      "Lumley            7\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "    stop_id    stop_name  stop_lat   stop_lon  location_type\n",
      "0  hub_0001  Wilberforce  8.468191 -13.261957              0\n",
      "1  hub_0002       Lumley  8.456025 -13.272294              0\n",
      "2  hub_0003     Aberdeen  8.493606 -13.286955              0\n",
      "3  hub_0004          Jui  8.393121 -13.144289              0\n",
      "4  hub_0005     Waterloo  8.372450 -13.097135              0\n",
      "✓ Saved cleaned data to: cleaned_data\\freetown\\cleaned_stops.csv\n",
      "\n",
      "==================================================\n",
      "Processing: freetown\\stop_times.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (6185, 9)\n",
      "\n",
      "Cleaning data for freetown\\stop_times.txt...\n",
      "  - Dropped column 'shape_dist_traveled' (>70.0% missing)\n",
      "  - Converted 'arrival_time' to datetime\n",
      "  - Converted 'departure_time' to datetime\n",
      "  - Capped 78 outliers in 'stop_sequence'\n",
      "  ✓ Cleaned data shape: (6185, 9) → (6185, 5)\n",
      "\n",
      "--- Analysis for freetown\\stop_times.txt ---\n",
      "Shape: (6185, 5)\n",
      "Memory usage: 0.92 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object            2\n",
      "datetime64[ns]    2\n",
      "int64             1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       stop_sequence\n",
      "count    6185.000000\n",
      "mean       10.967502\n",
      "std         8.144519\n",
      "min         1.000000\n",
      "25%         4.000000\n",
      "50%         9.000000\n",
      "75%        16.000000\n",
      "max        34.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "trip_0089    41\n",
      "trip_0090    41\n",
      "trip_0091    41\n",
      "trip_0092    41\n",
      "trip_0363    40\n",
      "Name: count, dtype: int64\n",
      "\n",
      "stop_id:\n",
      "stop_id\n",
      "stop_0654    69\n",
      "stop_0627    54\n",
      "stop_0037    51\n",
      "stop_0071    51\n",
      "stop_0205    46\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "     trip_id        arrival_time      departure_time    stop_id  stop_sequence\n",
      "0  trip_0001 2025-08-11 08:15:14 2025-08-11 08:15:14  stop_0401              1\n",
      "1  trip_0001 2025-08-11 08:17:13 2025-08-11 08:17:13  stop_0443              2\n",
      "2  trip_0001 2025-08-11 08:21:51 2025-08-11 08:21:51  stop_0308              3\n",
      "3  trip_0001 2025-08-11 08:22:35 2025-08-11 08:22:35  stop_0177              4\n",
      "4  trip_0001 2025-08-11 08:23:18 2025-08-11 08:23:18  stop_0868              5\n",
      "✓ Saved cleaned data to: cleaned_data\\freetown\\cleaned_stop_times.csv\n",
      "\n",
      "==================================================\n",
      "Processing: freetown\\trips.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (404, 9)\n",
      "\n",
      "Cleaning data for freetown\\trips.txt...\n",
      "  ✓ Cleaned data shape: (404, 9) → (404, 6)\n",
      "\n",
      "--- Analysis for freetown\\trips.txt ---\n",
      "Shape: (404, 6)\n",
      "Memory usage: 0.16 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object    6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "trip_0001    1\n",
      "trip_0002    1\n",
      "trip_0003    1\n",
      "trip_0004    1\n",
      "trip_0005    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_id:\n",
      "route_id\n",
      "route_0001    4\n",
      "route_0002    4\n",
      "route_0003    4\n",
      "route_0061    4\n",
      "route_0004    4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "service_id:\n",
      "service_id\n",
      "service_0002    302\n",
      "service_0001    100\n",
      "service_0003      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "trip_headsign:\n",
      "trip_headsign\n",
      "Eastern Police       27\n",
      "SLPMB                24\n",
      "Elk Street           22\n",
      "Lumley               21\n",
      "Barracks Old Road    20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "trip_short_name:\n",
      "trip_short_name\n",
      "Off peak trip        93\n",
      "Weekend trip         90\n",
      "Evening peak trip    89\n",
      "Morning peak trip    86\n",
      "Weekdays             36\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "     trip_id    route_id    service_id trip_headsign    trip_short_name  \\\n",
      "0  trip_0001  route_0001  service_0002   Regent Road  Morning peak trip   \n",
      "1  trip_0002  route_0001  service_0002   Regent Road      Off peak trip   \n",
      "2  trip_0003  route_0001  service_0002   Regent Road  Evening peak trip   \n",
      "3  trip_0004  route_0001  service_0001   Regent Road       Weekend trip   \n",
      "4  trip_0005  route_0002  service_0002    Elk Street  Morning peak trip   \n",
      "\n",
      "     shape_id  \n",
      "0  shape_0001  \n",
      "1  shape_0001  \n",
      "2  shape_0001  \n",
      "3  shape_0001  \n",
      "4  shape_0002  \n",
      "✓ Saved cleaned data to: cleaned_data\\freetown\\cleaned_trips.csv\n",
      "\n",
      "==================================================\n",
      "Processing: kampala\\agency.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (2, 7)\n",
      "\n",
      "Cleaning data for kampala\\agency.txt...\n",
      "  - Converted 'agency_timezone' to datetime\n",
      "  ✓ Cleaned data shape: (2, 7) → (2, 5)\n",
      "\n",
      "--- Analysis for kampala\\agency.txt ---\n",
      "Shape: (2, 5)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "Missing values:\n",
      "agency_timezone    2\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "object            4\n",
      "datetime64[ns]    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "agency_id:\n",
      "agency_id\n",
      "taxi    1\n",
      "bus     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_name:\n",
      "agency_name\n",
      "14-Seater Paratransit Taxi                    1\n",
      "Buses oprated by Pioneer or Awakula Enumme    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_url:\n",
      "agency_url\n",
      "http://transportforcairo.com/    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_lang:\n",
      "agency_lang\n",
      "en    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  agency_id                                 agency_name  \\\n",
      "0      taxi                  14-Seater Paratransit Taxi   \n",
      "1       bus  Buses oprated by Pioneer or Awakula Enumme   \n",
      "\n",
      "                      agency_url agency_timezone agency_lang  \n",
      "0  http://transportforcairo.com/             NaT          en  \n",
      "1  http://transportforcairo.com/             NaT          en  \n",
      "✓ Saved cleaned data to: cleaned_data\\kampala\\cleaned_agency.csv\n",
      "\n",
      "==================================================\n",
      "Processing: kampala\\calendar.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 10)\n",
      "\n",
      "Cleaning data for kampala\\calendar.txt...\n",
      "  - Converted 'end_date' to datetime\n",
      "  - Converted 'start_date' to datetime\n",
      "  ✓ Cleaned data shape: (1, 10) → (1, 10)\n",
      "\n",
      "--- Analysis for kampala\\calendar.txt ---\n",
      "Shape: (1, 10)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64             7\n",
      "datetime64[ns]    2\n",
      "object            1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       friday  monday  saturday  sunday  thursday  tuesday  wednesday\n",
      "count     1.0     1.0       1.0     1.0       1.0      1.0        1.0\n",
      "mean      1.0     1.0       1.0     1.0       1.0      1.0        1.0\n",
      "std       NaN     NaN       NaN     NaN       NaN      NaN        NaN\n",
      "min       1.0     1.0       1.0     1.0       1.0      1.0        1.0\n",
      "25%       1.0     1.0       1.0     1.0       1.0      1.0        1.0\n",
      "50%       1.0     1.0       1.0     1.0       1.0      1.0        1.0\n",
      "75%       1.0     1.0       1.0     1.0       1.0      1.0        1.0\n",
      "max       1.0     1.0       1.0     1.0       1.0      1.0        1.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "service_id:\n",
      "service_id\n",
      "Ground_Daily    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "                       end_date  friday  monday  saturday    service_id  \\\n",
      "0 1970-01-01 00:00:00.020200929       1       1         1  Ground_Daily   \n",
      "\n",
      "                     start_date  sunday  thursday  tuesday  wednesday  \n",
      "0 1970-01-01 00:00:00.020191010       1         1        1          1  \n",
      "✓ Saved cleaned data to: cleaned_data\\kampala\\cleaned_calendar.csv\n",
      "\n",
      "==================================================\n",
      "Processing: kampala\\calendar_dates.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 3)\n",
      "\n",
      "Cleaning data for kampala\\calendar_dates.txt...\n",
      "  - Converted 'date' to datetime\n",
      "  ✓ Cleaned data shape: (1, 3) → (1, 3)\n",
      "\n",
      "--- Analysis for kampala\\calendar_dates.txt ---\n",
      "Shape: (1, 3)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object            1\n",
      "datetime64[ns]    1\n",
      "int64             1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       exception_type\n",
      "count             1.0\n",
      "mean              2.0\n",
      "std               NaN\n",
      "min               2.0\n",
      "25%               2.0\n",
      "50%               2.0\n",
      "75%               2.0\n",
      "max               2.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "service_id:\n",
      "service_id\n",
      "Ground_Daily    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "     service_id                          date  exception_type\n",
      "0  Ground_Daily 1970-01-01 00:00:00.020170104               2\n",
      "✓ Saved cleaned data to: cleaned_data\\kampala\\cleaned_calendar_dates.csv\n",
      "\n",
      "==================================================\n",
      "Processing: kampala\\feed_info.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 6)\n",
      "\n",
      "Cleaning data for kampala\\feed_info.txt...\n",
      "  - Converted 'feed_start_date' to datetime\n",
      "  - Converted 'feed_end_date' to datetime\n",
      "  ✓ Cleaned data shape: (1, 6) → (1, 6)\n",
      "\n",
      "--- Analysis for kampala\\feed_info.txt ---\n",
      "Shape: (1, 6)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object            3\n",
      "datetime64[ns]    2\n",
      "float64           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       feed_version\n",
      "count       1.00000\n",
      "mean        1.15042\n",
      "std             NaN\n",
      "min         1.15042\n",
      "25%         1.15042\n",
      "50%         1.15042\n",
      "75%         1.15042\n",
      "max         1.15042\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "feed_publisher_name:\n",
      "feed_publisher_name\n",
      "Transport for Cairo    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_publisher_url:\n",
      "feed_publisher_url\n",
      "http://transportforcairo.com/    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_lang:\n",
      "feed_lang\n",
      "en    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   feed_publisher_name             feed_publisher_url feed_lang  \\\n",
      "0  Transport for Cairo  http://transportforcairo.com/        en   \n",
      "\n",
      "                feed_start_date                 feed_end_date  feed_version  \n",
      "0 1970-01-01 00:00:00.020200101 1970-01-01 00:00:00.020210101       1.15042  \n",
      "✓ Saved cleaned data to: cleaned_data\\kampala\\cleaned_feed_info.csv\n",
      "\n",
      "==================================================\n",
      "Processing: kampala\\frequencies.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (4696, 4)\n",
      "\n",
      "Cleaning data for kampala\\frequencies.txt...\n",
      "  - Converted 'start_time' to datetime\n",
      "  - Converted 'end_time' to datetime\n",
      "  - Capped 1286 outliers in 'headway_secs'\n",
      "  ✓ Cleaned data shape: (4696, 4) → (4696, 4)\n",
      "\n",
      "--- Analysis for kampala\\frequencies.txt ---\n",
      "Shape: (4696, 4)\n",
      "Memory usage: 0.47 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "datetime64[ns]    2\n",
      "object            1\n",
      "float64           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       headway_secs\n",
      "count   4696.000000\n",
      "mean     437.392462\n",
      "std      113.009781\n",
      "min      238.500000\n",
      "25%      375.000000\n",
      "50%      466.000000\n",
      "75%      466.000000\n",
      "max      602.500000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "taxi_KA021_R (19-00-00)    1\n",
      "taxi_KA021_R (17-00-00)    1\n",
      "taxi_KA021_R (15-00-00)    1\n",
      "taxi_KA021_R (13-00-00)    1\n",
      "taxi_KA021_R (11-00-00)    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "                   trip_id          start_time            end_time  \\\n",
      "0  taxi_KA021_R (19-00-00) 2025-08-11 19:00:00 2025-08-11 23:00:00   \n",
      "1  taxi_KA021_R (17-00-00) 2025-08-11 17:00:00 2025-08-11 19:00:00   \n",
      "2  taxi_KA021_R (15-00-00) 2025-08-11 15:00:00 2025-08-11 17:00:00   \n",
      "3  taxi_KA021_R (13-00-00) 2025-08-11 13:00:00 2025-08-11 15:00:00   \n",
      "4  taxi_KA021_R (11-00-00) 2025-08-11 11:00:00 2025-08-11 13:00:00   \n",
      "\n",
      "   headway_secs  \n",
      "0         466.0  \n",
      "1         466.0  \n",
      "2         466.0  \n",
      "3         466.0  \n",
      "4         466.0  \n",
      "✓ Saved cleaned data to: cleaned_data\\kampala\\cleaned_frequencies.csv\n",
      "\n",
      "==================================================\n",
      "Processing: kampala\\routes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (397, 9)\n",
      "\n",
      "Cleaning data for kampala\\routes.txt...\n",
      "  ✓ Cleaned data shape: (397, 9) → (397, 5)\n",
      "\n",
      "--- Analysis for kampala\\routes.txt ---\n",
      "Shape: (397, 5)\n",
      "Memory usage: 0.11 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object    4\n",
      "int64     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       route_type\n",
      "count       397.0\n",
      "mean          3.0\n",
      "std           0.0\n",
      "min           3.0\n",
      "25%           3.0\n",
      "50%           3.0\n",
      "75%           3.0\n",
      "max           3.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "route_id:\n",
      "route_id\n",
      "bus_IC026    1\n",
      "bus_IC027    1\n",
      "bus_IC030    1\n",
      "bus_IC033    1\n",
      "bus_IC060    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_id:\n",
      "agency_id\n",
      "taxi    369\n",
      "bus      28\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_short_name:\n",
      "route_short_name\n",
      "IC026    2\n",
      "IC027    2\n",
      "IC030    2\n",
      "IC033    2\n",
      "IC060    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_long_name:\n",
      "route_long_name\n",
      "Bweyogerere-City Square            7\n",
      "Nateete Taxi Park-New Taxi Park    5\n",
      "Mukono Taxi Park-Old Taxi Park     4\n",
      "City Square-Kirombe Taxi Stage     4\n",
      "Old Taxi Park-Seeta Stage          4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "    route_id agency_id route_short_name                 route_long_name  \\\n",
      "0  bus_IC026       bus            IC026  Mukono Taxi Park-Old Taxi Park   \n",
      "1  bus_IC027       bus            IC027  Mukono Taxi Park-Old Taxi Park   \n",
      "2  bus_IC030       bus            IC030       Old Taxi Park-Seeta Stage   \n",
      "3  bus_IC033       bus            IC033        Old Taxi Park-Zana Stage   \n",
      "4  bus_IC060       bus            IC060        New Taxi Park-Zana Stage   \n",
      "\n",
      "   route_type  \n",
      "0           3  \n",
      "1           3  \n",
      "2           3  \n",
      "3           3  \n",
      "4           3  \n",
      "✓ Saved cleaned data to: cleaned_data\\kampala\\cleaned_routes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: kampala\\shapes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (87791, 4)\n",
      "\n",
      "Cleaning data for kampala\\shapes.txt...\n",
      "  - Capped 11220 outliers in 'shape_pt_lat'\n",
      "  - Capped 5515 outliers in 'shape_pt_lon'\n",
      "  - Capped 6148 outliers in 'shape_pt_sequence'\n",
      "  ✓ Cleaned data shape: (87791, 4) → (87791, 4)\n",
      "\n",
      "--- Analysis for kampala\\shapes.txt ---\n",
      "Shape: (87791, 4)\n",
      "Memory usage: 8.28 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "float64    3\n",
      "object     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       shape_pt_lat  shape_pt_lon  shape_pt_sequence\n",
      "count  87791.000000  87791.000000       87791.000000\n",
      "mean       0.324377     32.582079         117.421091\n",
      "std        0.047998      0.042520         102.123635\n",
      "min        0.230410     32.488460           1.000000\n",
      "25%        0.304150     32.559650          39.000000\n",
      "50%        0.326280     32.576810          85.000000\n",
      "75%        0.353310     32.607110         166.000000\n",
      "max        0.427050     32.678300         356.500000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "shape_id:\n",
      "shape_id\n",
      "taxi_IC105_R_shape    1052\n",
      "taxi_IC020_R_shape     982\n",
      "taxi_IC073_R_shape     959\n",
      "taxi_IC031_O_shape     680\n",
      "taxi_IC024_O_shape     655\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "            shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence\n",
      "0  bus_IC026_R_shape       0.35915       32.6783                1.0\n",
      "1  bus_IC026_R_shape       0.35950       32.6783                2.0\n",
      "2  bus_IC026_R_shape       0.35978       32.6783                3.0\n",
      "3  bus_IC026_R_shape       0.36065       32.6783                4.0\n",
      "4  bus_IC026_R_shape       0.36088       32.6783                5.0\n",
      "✓ Saved cleaned data to: cleaned_data\\kampala\\cleaned_shapes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: kampala\\stops.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1242, 8)\n",
      "\n",
      "Cleaning data for kampala\\stops.txt...\n",
      "  - Capped 58 outliers in 'stop_lat'\n",
      "  - Capped 49 outliers in 'stop_lon'\n",
      "  ✓ Cleaned data shape: (1242, 8) → (1242, 4)\n",
      "\n",
      "--- Analysis for kampala\\stops.txt ---\n",
      "Shape: (1242, 4)\n",
      "Memory usage: 0.21 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object     2\n",
      "float64    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "          stop_lat     stop_lon\n",
      "count  1242.000000  1242.000000\n",
      "mean      0.331367    32.583350\n",
      "std       0.041646     0.040408\n",
      "min       0.233162    32.486870\n",
      "25%       0.306625    32.560385\n",
      "50%       0.328630    32.576440\n",
      "75%       0.355600    32.609395\n",
      "max       0.429062    32.682910\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "stop_id:\n",
      "stop_id\n",
      "rivals.pinches.humidity        1\n",
      "dragonfly.shoelaces.writing    1\n",
      "deck.intruding.copiers         1\n",
      "promise.icons.employers        1\n",
      "glitter.variously.colleague    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "stop_name:\n",
      "stop_name\n",
      "Namungoona                      4\n",
      "Kalerwe Taxi Park Roundabout    4\n",
      "Kavule Taxi Stage               3\n",
      "Mulago Roundabout               3\n",
      "Total - Nakawa Business Park    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "                       stop_id                       stop_name  stop_lat  \\\n",
      "0      rivals.pinches.humidity        Hotel Lavener (Lungujja)   0.31305   \n",
      "1  dragonfly.shoelaces.writing                           Mbubi   0.30516   \n",
      "2       deck.intruding.copiers                   Free Zone Bar   0.30438   \n",
      "3      promise.icons.employers                    Lusaze Stage   0.32183   \n",
      "4  glitter.variously.colleague  Nateete Pacify Shopping Centre   0.30293   \n",
      "\n",
      "   stop_lon  \n",
      "0  32.54460  \n",
      "1  32.54808  \n",
      "2  32.54613  \n",
      "3  32.54408  \n",
      "4  32.54234  \n",
      "✓ Saved cleaned data to: cleaned_data\\kampala\\cleaned_stops.csv\n",
      "\n",
      "==================================================\n",
      "Processing: kampala\\stop_times.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (140800, 9)\n",
      "\n",
      "Cleaning data for kampala\\stop_times.txt...\n",
      "  - Converted 'arrival_time' to datetime\n",
      "  - Converted 'departure_time' to datetime\n",
      "  - Capped 2512 outliers in 'stop_sequence'\n",
      "  ✓ Cleaned data shape: (140800, 9) → (140800, 5)\n",
      "\n",
      "--- Analysis for kampala\\stop_times.txt ---\n",
      "Shape: (140800, 5)\n",
      "Memory usage: 24.64 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object            2\n",
      "datetime64[ns]    2\n",
      "int64             1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       stop_sequence\n",
      "count  140800.000000\n",
      "mean       20.980455\n",
      "std        15.634606\n",
      "min         1.000000\n",
      "25%         8.000000\n",
      "50%        18.000000\n",
      "75%        30.000000\n",
      "max        63.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "taxi_IC109_R (08-00-00)    92\n",
      "taxi_IC109_R (06-30-00)    92\n",
      "taxi_IC109_R (19-00-00)    92\n",
      "taxi_IC109_R (17-00-00)    92\n",
      "taxi_IC109_R (15-00-00)    92\n",
      "Name: count, dtype: int64\n",
      "\n",
      "stop_id:\n",
      "stop_id\n",
      "veto.swimsuits.unveils        448\n",
      "loaning.learns.sleepy         384\n",
      "fidgeting.prongs.nerve        384\n",
      "riders.reclaimed.ballooned    368\n",
      "fried.freezers.repeated       360\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "                  trip_id                    stop_id  stop_sequence  \\\n",
      "0  bus_IC026_R (06-30-00)          doses.wider.warns              1   \n",
      "1  bus_IC026_R (06-30-00)      panting.weeps.backers              2   \n",
      "2  bus_IC026_R (06-30-00)          ramps.sorry.props              3   \n",
      "3  bus_IC026_R (06-30-00)  catapult.frightens.senses              4   \n",
      "4  bus_IC026_R (06-30-00)   clutches.bogus.tolerates              5   \n",
      "\n",
      "         arrival_time      departure_time  \n",
      "0 2025-08-11 06:30:00 2025-08-11 06:30:15  \n",
      "1 2025-08-11 06:31:35 2025-08-11 06:31:50  \n",
      "2 2025-08-11 06:34:50 2025-08-11 06:35:05  \n",
      "3 2025-08-11 06:36:57 2025-08-11 06:37:12  \n",
      "4 2025-08-11 06:37:53 2025-08-11 06:38:08  \n",
      "✓ Saved cleaned data to: cleaned_data\\kampala\\cleaned_stop_times.csv\n",
      "\n",
      "==================================================\n",
      "Processing: kampala\\trips.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (4696, 7)\n",
      "\n",
      "Cleaning data for kampala\\trips.txt...\n",
      "  ✓ Cleaned data shape: (4696, 7) → (4696, 7)\n",
      "\n",
      "--- Analysis for kampala\\trips.txt ---\n",
      "Shape: (4696, 7)\n",
      "Memory usage: 1.75 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object    5\n",
      "int64     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       direction_id  wheelchair_accessible\n",
      "count   4696.000000                 4696.0\n",
      "mean       0.482112                    0.0\n",
      "std        0.499733                    0.0\n",
      "min        0.000000                    0.0\n",
      "25%        0.000000                    0.0\n",
      "50%        0.000000                    0.0\n",
      "75%        1.000000                    0.0\n",
      "max        1.000000                    0.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "route_id:\n",
      "route_id\n",
      "taxi_IC030    16\n",
      "taxi_KA047    16\n",
      "taxi_IC025    16\n",
      "taxi_IC010    16\n",
      "taxi_IC112    16\n",
      "Name: count, dtype: int64\n",
      "\n",
      "service_id:\n",
      "service_id\n",
      "Ground_Daily    4696\n",
      "Name: count, dtype: int64\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "taxi_KA021_R (19-00-00)    1\n",
      "taxi_KA021_R (17-00-00)    1\n",
      "taxi_KA021_R (15-00-00)    1\n",
      "taxi_KA021_R (13-00-00)    1\n",
      "taxi_KA021_R (11-00-00)    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "trip_short_name:\n",
      "trip_short_name\n",
      "New Taxi Park-Nateete Taxi Park    40\n",
      "Bweyogerere-City Square            40\n",
      "City Square-Bweyogerere            32\n",
      "Kyanja Taxi Stage-City Square      32\n",
      "Kirombe Taxi Stage-City Square     32\n",
      "Name: count, dtype: int64\n",
      "\n",
      "shape_id:\n",
      "shape_id\n",
      "taxi_KA021_R_shape    8\n",
      "taxi_KA130_O_shape    8\n",
      "taxi_IC058_O_shape    8\n",
      "bus_IC092_R_shape     8\n",
      "taxi_KA100_R_shape    8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "     route_id    service_id                  trip_id  \\\n",
      "0  taxi_KA021  Ground_Daily  taxi_KA021_R (19-00-00)   \n",
      "1  taxi_KA021  Ground_Daily  taxi_KA021_R (17-00-00)   \n",
      "2  taxi_KA021  Ground_Daily  taxi_KA021_R (15-00-00)   \n",
      "3  taxi_KA021  Ground_Daily  taxi_KA021_R (13-00-00)   \n",
      "4  taxi_KA021  Ground_Daily  taxi_KA021_R (11-00-00)   \n",
      "\n",
      "                   trip_short_name  direction_id            shape_id  \\\n",
      "0  Nateete Taxi Park-Old Taxi Park             1  taxi_KA021_R_shape   \n",
      "1  Nateete Taxi Park-Old Taxi Park             1  taxi_KA021_R_shape   \n",
      "2  Nateete Taxi Park-Old Taxi Park             1  taxi_KA021_R_shape   \n",
      "3  Nateete Taxi Park-Old Taxi Park             1  taxi_KA021_R_shape   \n",
      "4  Nateete Taxi Park-Old Taxi Park             1  taxi_KA021_R_shape   \n",
      "\n",
      "   wheelchair_accessible  \n",
      "0                      0  \n",
      "1                      0  \n",
      "2                      0  \n",
      "3                      0  \n",
      "4                      0  \n",
      "✓ Saved cleaned data to: cleaned_data\\kampala\\cleaned_trips.csv\n",
      "\n",
      "==================================================\n",
      "Processing: kumasi\\agency.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 6)\n",
      "\n",
      "Cleaning data for kumasi\\agency.txt...\n",
      "  - Converted 'agency_timezone' to datetime\n",
      "  ✓ Cleaned data shape: (1, 6) → (1, 5)\n",
      "\n",
      "--- Analysis for kumasi\\agency.txt ---\n",
      "Shape: (1, 5)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "Missing values:\n",
      "agency_timezone    1\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "int64             3\n",
      "datetime64[ns]    1\n",
      "object            1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       agency_id  agency_name  agency_url\n",
      "count        1.0          1.0         1.0\n",
      "mean         1.0          1.0         1.0\n",
      "std          NaN          NaN         NaN\n",
      "min          1.0          1.0         1.0\n",
      "25%          1.0          1.0         1.0\n",
      "50%          1.0          1.0         1.0\n",
      "75%          1.0          1.0         1.0\n",
      "max          1.0          1.0         1.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "agency_language:\n",
      "agency_language\n",
      "en    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   agency_id  agency_name  agency_url agency_timezone agency_language\n",
      "0          1            1           1             NaT              en\n",
      "✓ Saved cleaned data to: cleaned_data\\kumasi\\cleaned_agency.csv\n",
      "\n",
      "==================================================\n",
      "Processing: kumasi\\calendar.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 10)\n",
      "\n",
      "Cleaning data for kumasi\\calendar.txt...\n",
      "  - Converted 'start_date' to datetime\n",
      "  - Converted 'end_date' to datetime\n",
      "  ✓ Cleaned data shape: (1, 10) → (1, 10)\n",
      "\n",
      "--- Analysis for kumasi\\calendar.txt ---\n",
      "Shape: (1, 10)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64             8\n",
      "datetime64[ns]    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       service_id  monday  tuesday  wednesday  thursday  friday  saturday  \\\n",
      "count         1.0     1.0      1.0        1.0       1.0     1.0       1.0   \n",
      "mean          1.0     1.0      1.0        1.0       1.0     1.0       0.0   \n",
      "std           NaN     NaN      NaN        NaN       NaN     NaN       NaN   \n",
      "min           1.0     1.0      1.0        1.0       1.0     1.0       0.0   \n",
      "25%           1.0     1.0      1.0        1.0       1.0     1.0       0.0   \n",
      "50%           1.0     1.0      1.0        1.0       1.0     1.0       0.0   \n",
      "75%           1.0     1.0      1.0        1.0       1.0     1.0       0.0   \n",
      "max           1.0     1.0      1.0        1.0       1.0     1.0       0.0   \n",
      "\n",
      "       sunday  \n",
      "count     1.0  \n",
      "mean      0.0  \n",
      "std       NaN  \n",
      "min       0.0  \n",
      "25%       0.0  \n",
      "50%       0.0  \n",
      "75%       0.0  \n",
      "max       0.0  \n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   service_id  monday  tuesday  wednesday  thursday  friday  saturday  sunday  \\\n",
      "0           1       1        1          1         1       1         0       0   \n",
      "\n",
      "                     start_date                      end_date  \n",
      "0 1970-01-01 00:00:00.020000101 1970-01-01 00:00:00.020381231  \n",
      "✓ Saved cleaned data to: cleaned_data\\kumasi\\cleaned_calendar.csv\n",
      "\n",
      "==================================================\n",
      "Processing: kumasi\\routes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (668, 9)\n",
      "\n",
      "Cleaning data for kumasi\\routes.txt...\n",
      "  ✓ Cleaned data shape: (668, 9) → (668, 3)\n",
      "\n",
      "--- Analysis for kumasi\\routes.txt ---\n",
      "Shape: (668, 3)\n",
      "Memory usage: 0.05 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64     2\n",
      "object    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "          route_id  route_type\n",
      "count   668.000000       668.0\n",
      "mean    635.667665         3.0\n",
      "std     318.228936         0.0\n",
      "min       9.000000         3.0\n",
      "25%     386.750000         3.0\n",
      "50%     662.500000         3.0\n",
      "75%     866.250000         3.0\n",
      "max    1223.000000         3.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "route_short_name:\n",
      "route_short_name\n",
      "3304_AB    1\n",
      "3304_BA    1\n",
      "3305_AB    1\n",
      "3305_BA    1\n",
      "3601_AB    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   route_id route_short_name  route_type\n",
      "0         9          3304_AB           3\n",
      "1        10          3304_BA           3\n",
      "2        11          3305_AB           3\n",
      "3        12          3305_BA           3\n",
      "4        25          3601_AB           3\n",
      "✓ Saved cleaned data to: cleaned_data\\kumasi\\cleaned_routes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: kumasi\\routes_enriched.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (668, 9)\n",
      "\n",
      "Cleaning data for kumasi\\routes_enriched.txt...\n",
      "  ✓ Cleaned data shape: (668, 9) → (668, 4)\n",
      "\n",
      "--- Analysis for kumasi\\routes_enriched.txt ---\n",
      "Shape: (668, 4)\n",
      "Memory usage: 0.10 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64     2\n",
      "object    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "          route_id  route_type\n",
      "count   668.000000       668.0\n",
      "mean    635.667665         3.0\n",
      "std     318.228936         0.0\n",
      "min       9.000000         3.0\n",
      "25%     386.750000         3.0\n",
      "50%     662.500000         3.0\n",
      "75%     866.250000         3.0\n",
      "max    1223.000000         3.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "route_short_name:\n",
      "route_short_name\n",
      "3304_AB    1\n",
      "3304_BA    1\n",
      "3305_AB    1\n",
      "3305_BA    1\n",
      "3601_AB    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_long_name:\n",
      "route_long_name\n",
      "Abuakwa Terminal - Suame Roundabout    6\n",
      "Suame Roundabout - Abuakwa Terminal    6\n",
      "Santasi Station - Ahenema Kokobin      5\n",
      "Tafo 4 Miles - Kwabese East            4\n",
      "Sofoline - Tanoso                      4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   route_id route_short_name                  route_long_name  route_type\n",
      "0         9          3304_AB   Nhyieaso Station - Kumasi Mall           3\n",
      "1        10          3304_BA   Kumasi Mall - Nhyieaso Station           3\n",
      "2        11          3305_AB        Nhyieaso Station - Sobolo           3\n",
      "3        12          3305_BA                  Sobolo - Kuwait           3\n",
      "4        25          3601_AB  Santasi Roundabo - Sanasi Eset1           3\n",
      "✓ Saved cleaned data to: cleaned_data\\kumasi\\cleaned_routes_enriched.csv\n",
      "\n",
      "==================================================\n",
      "Processing: kumasi\\shapes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (114512, 5)\n",
      "\n",
      "Cleaning data for kumasi\\shapes.txt...\n",
      "  - Capped 6647 outliers in 'shape_pt_lat'\n",
      "  - Capped 7324 outliers in 'shape_pt_lon'\n",
      "  - Capped 2861 outliers in 'shape_pt_sequence'\n",
      "  - Capped 5832 outliers in 'shape_dist_traveled'\n",
      "  ✓ Cleaned data shape: (114512, 5) → (114512, 5)\n",
      "\n",
      "--- Analysis for kumasi\\shapes.txt ---\n",
      "Shape: (114512, 5)\n",
      "Memory usage: 4.37 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "float64    3\n",
      "int64      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "            shape_id   shape_pt_lat   shape_pt_lon  shape_pt_sequence  \\\n",
      "count  114512.000000  114512.000000  114512.000000      114512.000000   \n",
      "mean      353.011283       6.691976      -1.627725         115.494306   \n",
      "std       185.174772       0.035806       0.036222          90.841291   \n",
      "min         1.000000       6.609175      -1.707839           0.000000   \n",
      "25%       209.000000       6.670149      -1.647421          43.000000   \n",
      "50%       363.000000       6.694918      -1.627751          93.000000   \n",
      "75%       510.000000       6.710799      -1.607142         169.000000   \n",
      "max       668.000000       6.771773      -1.546724         358.000000   \n",
      "\n",
      "       shape_dist_traveled  \n",
      "count        114512.000000  \n",
      "mean              0.026857  \n",
      "std               0.019970  \n",
      "min               0.000000  \n",
      "25%               0.011500  \n",
      "50%               0.021452  \n",
      "75%               0.037120  \n",
      "max               0.075550  \n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence  \\\n",
      "0         1      6.694935     -1.621182                  0   \n",
      "1         1      6.694179     -1.620888                  1   \n",
      "2         1      6.693118     -1.620667                  2   \n",
      "3         1      6.692605     -1.620470                  3   \n",
      "4         1      6.692154     -1.620286                  4   \n",
      "\n",
      "   shape_dist_traveled  \n",
      "0             0.000000  \n",
      "1             0.055738  \n",
      "2             0.074473  \n",
      "3             0.037761  \n",
      "4             0.033470  \n",
      "✓ Saved cleaned data to: cleaned_data\\kumasi\\cleaned_shapes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: kumasi\\stops.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (704, 10)\n",
      "\n",
      "Cleaning data for kumasi\\stops.txt...\n",
      "  - Capped 15 outliers in 'stop_lat'\n",
      "  - Capped 38 outliers in 'stop_lon'\n",
      "  ✓ Cleaned data shape: (704, 10) → (704, 5)\n",
      "\n",
      "--- Analysis for kumasi\\stops.txt ---\n",
      "Shape: (704, 5)\n",
      "Memory usage: 0.07 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64      2\n",
      "float64    2\n",
      "object     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "          stop_id    stop_lat    stop_lon  location_type\n",
      "count  704.000000  704.000000  704.000000          704.0\n",
      "mean   352.500000    6.692918   -1.617378            0.0\n",
      "std    203.371581    0.031443    0.037354            0.0\n",
      "min      1.000000    6.616925   -1.698806            0.0\n",
      "25%    176.750000    6.673199   -1.637424            0.0\n",
      "50%    352.500000    6.695395   -1.619180            0.0\n",
      "75%    528.250000    6.710715   -1.596502            0.0\n",
      "max    704.000000    6.766989   -1.535119            0.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "stop_name:\n",
      "stop_name\n",
      "Wide Ring           15\n",
      "Sofoline            13\n",
      "Nsenie              11\n",
      "Tech Bus Station     9\n",
      "Makro to Sofolin     9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   stop_id  stop_name  stop_lat  stop_lon  location_type\n",
      "0        1  N10 North  6.766989 -1.645674              0\n",
      "1        2   Ampabame  6.745209 -1.671310              0\n",
      "2        3   Ampabame  6.745209 -1.671310              0\n",
      "3        4  N10 North  6.766989 -1.644862              0\n",
      "4        5  Nil Buoho  6.766989 -1.684718              0\n",
      "✓ Saved cleaned data to: cleaned_data\\kumasi\\cleaned_stops.csv\n",
      "\n",
      "==================================================\n",
      "Processing: kumasi\\stop_times.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (2519, 9)\n",
      "\n",
      "Cleaning data for kumasi\\stop_times.txt...\n",
      "  - Converted 'arrival_time' to datetime\n",
      "  - Converted 'departure_time' to datetime\n",
      "  - Capped 6 outliers in 'stop_sequence'\n",
      "  - Capped 68 outliers in 'shape_dist_traveled'\n",
      "  ✓ Cleaned data shape: (2519, 9) → (2519, 6)\n",
      "\n",
      "--- Analysis for kumasi\\stop_times.txt ---\n",
      "Shape: (2519, 6)\n",
      "Memory usage: 0.12 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64             2\n",
      "datetime64[ns]    2\n",
      "float64           2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "           trip_id      stop_id  stop_sequence  shape_dist_traveled\n",
      "count  2519.000000  2519.000000    2519.000000          2519.000000\n",
      "mean    344.040095   177.218738       2.716157             4.413193\n",
      "std     187.739281   146.461274       1.587850             4.009972\n",
      "min       1.000000     1.000000       1.000000             0.001481\n",
      "25%     189.000000    55.000000       1.000000             0.931099\n",
      "50%     347.000000   123.000000       2.000000             3.609454\n",
      "75%     502.000000   280.000000       4.000000             6.657056\n",
      "max     668.000000   535.000000       8.500000            15.245992\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   trip_id        arrival_time      departure_time  stop_id  stop_sequence  \\\n",
      "0        1 2025-08-11 00:00:04 2025-08-11 00:01:04      146            1.0   \n",
      "1        1 2025-08-11 00:00:03 2025-08-11 00:01:03      179            2.0   \n",
      "2        1 2025-08-11 00:08:57 2025-08-11 00:09:57      173            3.0   \n",
      "3        2 2025-08-11 00:00:03 2025-08-11 00:01:03      172            1.0   \n",
      "4        2 2025-08-11 00:00:03 2025-08-11 00:01:03      176            2.0   \n",
      "\n",
      "   shape_dist_traveled  \n",
      "0             0.032981  \n",
      "1             0.352566  \n",
      "2             3.729672  \n",
      "3             0.024786  \n",
      "4             0.246886  \n",
      "✓ Saved cleaned data to: cleaned_data\\kumasi\\cleaned_stop_times.csv\n",
      "\n",
      "==================================================\n",
      "Processing: kumasi\\trips.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (668, 8)\n",
      "\n",
      "Cleaning data for kumasi\\trips.txt...\n",
      "  ✓ Cleaned data shape: (668, 8) → (668, 5)\n",
      "\n",
      "--- Analysis for kumasi\\trips.txt ---\n",
      "Shape: (668, 5)\n",
      "Memory usage: 0.03 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64    5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "          route_id  service_id     trip_id  direction_id    shape_id\n",
      "count   668.000000       668.0  668.000000         668.0  668.000000\n",
      "mean    635.667665         1.0  334.500000           0.0  334.500000\n",
      "std     318.228936         0.0  192.979273           0.0  192.979273\n",
      "min       9.000000         1.0    1.000000           0.0    1.000000\n",
      "25%     386.750000         1.0  167.750000           0.0  167.750000\n",
      "50%     662.500000         1.0  334.500000           0.0  334.500000\n",
      "75%     866.250000         1.0  501.250000           0.0  501.250000\n",
      "max    1223.000000         1.0  668.000000           0.0  668.000000\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   route_id  service_id  trip_id  direction_id  shape_id\n",
      "0         9           1        1             0         1\n",
      "1        10           1        2             0         2\n",
      "2        11           1        3             0         3\n",
      "3        12           1        4             0         4\n",
      "4        25           1        5             0         5\n",
      "✓ Saved cleaned data to: cleaned_data\\kumasi\\cleaned_trips.csv\n",
      "\n",
      "==================================================\n",
      "Processing: lagos\\agency.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 8)\n",
      "\n",
      "Cleaning data for lagos\\agency.txt...\n",
      "  - Converted 'agency_timezone' to datetime\n",
      "  ✓ Cleaned data shape: (1, 8) → (1, 7)\n",
      "\n",
      "--- Analysis for lagos\\agency.txt ---\n",
      "Shape: (1, 7)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "Missing values:\n",
      "agency_timezone    1\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "object            5\n",
      "datetime64[ns]    1\n",
      "int64             1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       agency_phone\n",
      "count  1.000000e+00\n",
      "mean   2.349100e+12\n",
      "std             NaN\n",
      "min    2.349100e+12\n",
      "25%    2.349100e+12\n",
      "50%    2.349100e+12\n",
      "75%    2.349100e+12\n",
      "max    2.349100e+12\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "agency_id:\n",
      "agency_id\n",
      "LAMATA    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_name:\n",
      "agency_name\n",
      "Lagos Metropolitan Area Transport Authority    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_url:\n",
      "agency_url\n",
      "https://www.lamata-ng.com/    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_lang:\n",
      "agency_lang\n",
      "En    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_email:\n",
      "agency_email\n",
      "info@lamata-ng.com    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  agency_id                                  agency_name  \\\n",
      "0    LAMATA  Lagos Metropolitan Area Transport Authority   \n",
      "\n",
      "                   agency_url agency_timezone agency_lang   agency_phone  \\\n",
      "0  https://www.lamata-ng.com/             NaT          En  2349099526282   \n",
      "\n",
      "         agency_email  \n",
      "0  info@lamata-ng.com  \n",
      "✓ Saved cleaned data to: cleaned_data\\lagos\\cleaned_agency.csv\n",
      "\n",
      "==================================================\n",
      "Processing: lagos\\calendar.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 10)\n",
      "\n",
      "Cleaning data for lagos\\calendar.txt...\n",
      "  - Converted 'start_date' to datetime\n",
      "  - Converted 'end_date' to datetime\n",
      "  ✓ Cleaned data shape: (1, 10) → (1, 10)\n",
      "\n",
      "--- Analysis for lagos\\calendar.txt ---\n",
      "Shape: (1, 10)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64             7\n",
      "datetime64[ns]    2\n",
      "object            1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       monday  tuesday  wednesday  thursday  friday  saturday  sunday\n",
      "count     1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "mean      1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "std       NaN      NaN        NaN       NaN     NaN       NaN     NaN\n",
      "min       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "25%       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "50%       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "75%       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "max       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "service_id:\n",
      "service_id\n",
      "MON-SUN    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  service_id  monday  tuesday  wednesday  thursday  friday  saturday  sunday  \\\n",
      "0    MON-SUN       1        1          1         1       1         1       1   \n",
      "\n",
      "                     start_date                      end_date  \n",
      "0 1970-01-01 00:00:00.020230101 1970-01-01 00:00:00.020241230  \n",
      "✓ Saved cleaned data to: cleaned_data\\lagos\\cleaned_calendar.csv\n",
      "\n",
      "==================================================\n",
      "Processing: lagos\\calendar_dates.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (0, 3)\n",
      "⚠ Warning: lagos\\calendar_dates.txt could not be parsed into multiple columns\n",
      "\n",
      "==================================================\n",
      "Processing: lagos\\feed_info.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 7)\n",
      "\n",
      "Cleaning data for lagos\\feed_info.txt...\n",
      "  - Converted 'feed_start_date' to datetime\n",
      "  - Converted 'feed_end_date' to datetime\n",
      "  ✓ Cleaned data shape: (1, 7) → (1, 7)\n",
      "\n",
      "--- Analysis for lagos\\feed_info.txt ---\n",
      "Shape: (1, 7)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object            4\n",
      "datetime64[ns]    2\n",
      "float64           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       feed_version\n",
      "count           1.0\n",
      "mean            2.0\n",
      "std             NaN\n",
      "min             2.0\n",
      "25%             2.0\n",
      "50%             2.0\n",
      "75%             2.0\n",
      "max             2.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "feed_publisher_name:\n",
      "feed_publisher_name\n",
      "CPCS    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_lang:\n",
      "feed_lang\n",
      "en    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_publisher_url:\n",
      "feed_publisher_url\n",
      "https://www.cpcs.ca    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_contact_email:\n",
      "feed_contact_email\n",
      "info@cpcs.ca    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  feed_publisher_name               feed_start_date  feed_version  \\\n",
      "0                CPCS 1970-01-01 00:00:00.020220101           2.0   \n",
      "\n",
      "                  feed_end_date feed_lang   feed_publisher_url  \\\n",
      "0 1970-01-01 00:00:00.020241230        en  https://www.cpcs.ca   \n",
      "\n",
      "  feed_contact_email  \n",
      "0       info@cpcs.ca  \n",
      "✓ Saved cleaned data to: cleaned_data\\lagos\\cleaned_feed_info.csv\n",
      "\n",
      "==================================================\n",
      "Processing: lagos\\frequencies.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (8, 5)\n",
      "\n",
      "Cleaning data for lagos\\frequencies.txt...\n",
      "  - Converted 'start_time' to datetime\n",
      "  - Converted 'end_time' to datetime\n",
      "  ✓ Cleaned data shape: (8, 5) → (8, 4)\n",
      "\n",
      "--- Analysis for lagos\\frequencies.txt ---\n",
      "Shape: (8, 4)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "datetime64[ns]    2\n",
      "object            1\n",
      "int64             1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       headway_secs\n",
      "count           8.0\n",
      "mean          600.0\n",
      "std             0.0\n",
      "min           600.0\n",
      "25%           600.0\n",
      "50%           600.0\n",
      "75%           600.0\n",
      "max           600.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "1107D1136    1\n",
      "1107D111     1\n",
      "1107D112     1\n",
      "1107D113     1\n",
      "1107D114     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "     trip_id          start_time            end_time  headway_secs\n",
      "0  1107D1136 2025-08-11 05:00:00 2025-08-11 23:00:00           600\n",
      "1   1107D111 2025-08-11 05:00:00 2025-08-11 23:00:00           600\n",
      "2   1107D112 2025-08-11 05:00:00 2025-08-11 23:00:00           600\n",
      "3   1107D113 2025-08-11 05:00:00 2025-08-11 23:00:00           600\n",
      "4   1107D114 2025-08-11 05:00:00 2025-08-11 23:00:00           600\n",
      "✓ Saved cleaned data to: cleaned_data\\lagos\\cleaned_frequencies.csv\n",
      "\n",
      "==================================================\n",
      "Processing: lagos\\routes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (8, 10)\n",
      "\n",
      "Cleaning data for lagos\\routes.txt...\n",
      "  ✓ Cleaned data shape: (8, 10) → (8, 5)\n",
      "\n",
      "--- Analysis for lagos\\routes.txt ---\n",
      "Shape: (8, 5)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object    3\n",
      "int64     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       route_id  route_type\n",
      "count   8.00000         8.0\n",
      "mean   15.50000         3.0\n",
      "std     2.44949         0.0\n",
      "min    12.00000         3.0\n",
      "25%    13.75000         3.0\n",
      "50%    15.50000         3.0\n",
      "75%    17.25000         3.0\n",
      "max    19.00000         3.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "agency_id:\n",
      "agency_id\n",
      "LAMATA    8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_short_name:\n",
      "route_short_name\n",
      "1       1\n",
      "QBC2    1\n",
      "QBC3    1\n",
      "QBC4    1\n",
      "QBC5    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_long_name:\n",
      "route_long_name\n",
      "Ojuelegba – Idi Araba – Ilasamaja    1\n",
      "Iju Ishaga – Abule Egba              1\n",
      "Igando – Iyana Iba                   1\n",
      "Ketu - Alapere – Akanimodo           1\n",
      "Onipanu – Oshodi                     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   route_id agency_id route_short_name                    route_long_name  \\\n",
      "0        12    LAMATA                1  Ojuelegba – Idi Araba – Ilasamaja   \n",
      "1        13    LAMATA             QBC2            Iju Ishaga – Abule Egba   \n",
      "2        14    LAMATA             QBC3                 Igando – Iyana Iba   \n",
      "3        15    LAMATA             QBC4         Ketu - Alapere – Akanimodo   \n",
      "4        16    LAMATA             QBC5                   Onipanu – Oshodi   \n",
      "\n",
      "   route_type  \n",
      "0           3  \n",
      "1           3  \n",
      "2           3  \n",
      "3           3  \n",
      "4           3  \n",
      "✓ Saved cleaned data to: cleaned_data\\lagos\\cleaned_routes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: lagos\\shapes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (3774, 5)\n",
      "\n",
      "Cleaning data for lagos\\shapes.txt...\n",
      "  - Capped 6 outliers in 'shape_pt_sequence'\n",
      "  - Capped 54 outliers in 'shape_dist_traveled'\n",
      "  ✓ Cleaned data shape: (3774, 5) → (3774, 5)\n",
      "\n",
      "--- Analysis for lagos\\shapes.txt ---\n",
      "Shape: (3774, 5)\n",
      "Memory usage: 0.14 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "float64    4\n",
      "int64      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "          shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence  \\\n",
      "count  3774.000000   3774.000000   3774.000000        3774.000000   \n",
      "mean      4.206942      6.558849      3.307616         300.487215   \n",
      "std       1.873651      0.052121      0.068223         224.750481   \n",
      "min       1.000000      6.461217      3.199097           1.000000   \n",
      "25%       2.000000      6.512456      3.241138         118.250000   \n",
      "50%       4.000000      6.547752      3.324156         250.000000   \n",
      "75%       5.000000      6.601817      3.361820         447.000000   \n",
      "max       8.000000      6.667942      3.400698         940.125000   \n",
      "\n",
      "       shape_dist_traveled  \n",
      "count          3774.000000  \n",
      "mean           3738.130470  \n",
      "std            2882.498972  \n",
      "min               0.000000  \n",
      "25%            1446.096146  \n",
      "50%            3078.554388  \n",
      "75%            5512.294277  \n",
      "max           11611.591472  \n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence  \\\n",
      "0         1      6.510493      3.363141                1.0   \n",
      "1         1      6.510382      3.363046                2.0   \n",
      "2         1      6.510302      3.362994                3.0   \n",
      "3         1      6.510228      3.362943                4.0   \n",
      "4         1      6.510173      3.362868                5.0   \n",
      "\n",
      "   shape_dist_traveled  \n",
      "0             0.000000  \n",
      "1            16.214464  \n",
      "2            26.746660  \n",
      "3            36.667668  \n",
      "4            46.954163  \n",
      "✓ Saved cleaned data to: cleaned_data\\lagos\\cleaned_shapes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: lagos\\stops.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (171, 11)\n",
      "\n",
      "Cleaning data for lagos\\stops.txt...\n",
      "  ✓ Cleaned data shape: (171, 11) → (171, 10)\n",
      "\n",
      "--- Analysis for lagos\\stops.txt ---\n",
      "Shape: (171, 10)\n",
      "Memory usage: 0.06 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "float64    4\n",
      "object     4\n",
      "int64      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       esrignss_latitude  esrignss_longitude     stop_id    shape_id  \\\n",
      "count         171.000000          171.000000  171.000000  171.000000   \n",
      "mean            6.560934            3.315509  222.409357  222.409357   \n",
      "std             0.050523            0.062443   54.082363   54.082363   \n",
      "min             6.461283            3.199118  121.000000  121.000000   \n",
      "25%             6.512644            3.258051  179.000000  179.000000   \n",
      "50%             6.551365            3.336172  225.000000  225.000000   \n",
      "75%             6.601707            3.362109  268.500000  268.500000   \n",
      "max             6.668228            3.400652  311.000000  311.000000   \n",
      "\n",
      "         stop_lat    stop_lon  \n",
      "count  171.000000  171.000000  \n",
      "mean     6.560934    3.315513  \n",
      "std      0.050526    0.062446  \n",
      "min      6.461283    3.199118  \n",
      "25%      6.512644    3.258051  \n",
      "50%      6.551365    3.336172  \n",
      "75%      6.601708    3.362109  \n",
      "max      6.668228    3.400696  \n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "name:\n",
      "name\n",
      "ANTHONY         7\n",
      "IYANA SCHOOL    3\n",
      "OSHODI          3\n",
      "OJUELEGBA       2\n",
      "BARUWA          2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "globalid:\n",
      "globalid\n",
      "{89856929-D9D4-42E3-837D-8DFDA0AFE1EE}    1\n",
      "{D3C32A35-3691-450D-81E0-1E00D026B904}    1\n",
      "{67D5C21A-E684-415C-BB70-4A01E9300715}    1\n",
      "{0149915A-A4BE-422C-B369-F21EFCB71BD2}    1\n",
      "{6C05015C-6AA1-4E4E-A21E-B49F7C4948D9}    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "corridorname:\n",
      "corridorname\n",
      "Iyana Ipaja-Ayobo          32\n",
      "Iyana Iba-Igando           30\n",
      "Yaba-Lawanson-Cele         29\n",
      "Ketu - Mile 12- Alapere    27\n",
      "Onipanu - Oshodi           19\n",
      "Name: count, dtype: int64\n",
      "\n",
      "stop_name:\n",
      "stop_name\n",
      "Iyana School    3\n",
      "Ketu            3\n",
      "Oshodi          3\n",
      "Anthony         3\n",
      "Araromi         2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   esrignss_latitude  esrignss_longitude       name  \\\n",
      "0           6.510450            3.363065  OJUELEGBA   \n",
      "1           6.510343            3.361760    AYILARA   \n",
      "2           6.511603            3.359387     ISHAGA   \n",
      "3           6.512198            3.358968       MABO   \n",
      "4           6.512972            3.358407   ATUNRASE   \n",
      "\n",
      "                                 globalid                    corridorname  \\\n",
      "0  {89856929-D9D4-42E3-837D-8DFDA0AFE1EE}  Ojuelegba-Idi Araba -Ilasamaja   \n",
      "1  {D3C32A35-3691-450D-81E0-1E00D026B904}  Ojuelegba-Idi Araba -Ilasamaja   \n",
      "2  {67D5C21A-E684-415C-BB70-4A01E9300715}              Yaba-Lawanson-Cele   \n",
      "3  {0149915A-A4BE-422C-B369-F21EFCB71BD2}  Ojuelegba-Idi Araba -Ilasamaja   \n",
      "4  {6C05015C-6AA1-4E4E-A21E-B49F7C4948D9}  Ojuelegba-Idi Araba -Ilasamaja   \n",
      "\n",
      "   stop_id  stop_name  shape_id  stop_lat  stop_lon  \n",
      "0      121  Ojuelegba       121  6.510450  3.363065  \n",
      "1      122    Ayilara       122  6.510343  3.361760  \n",
      "2      123     Ishaga       123  6.511603  3.359387  \n",
      "3      124       Mabo       124  6.512198  3.358968  \n",
      "4      125   Atunrase       125  6.512972  3.358407  \n",
      "✓ Saved cleaned data to: cleaned_data\\lagos\\cleaned_stops.csv\n",
      "\n",
      "==================================================\n",
      "Processing: lagos\\stop_times.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (171, 7)\n",
      "\n",
      "Cleaning data for lagos\\stop_times.txt...\n",
      "  - Converted 'arrival_time' to datetime\n",
      "  - Converted 'departure_time' to datetime\n",
      "  - Converted 'timepoint' to datetime\n",
      "  ✓ Cleaned data shape: (171, 7) → (171, 6)\n",
      "\n",
      "--- Analysis for lagos\\stop_times.txt ---\n",
      "Shape: (171, 6)\n",
      "Memory usage: 0.02 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "datetime64[ns]    3\n",
      "int64             2\n",
      "object            1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "          stop_id  stop_sequence\n",
      "count  171.000000     171.000000\n",
      "mean   222.409357      24.719298\n",
      "std     54.082363      15.314838\n",
      "min    121.000000       1.000000\n",
      "25%    179.000000      11.000000\n",
      "50%    225.000000      24.000000\n",
      "75%    268.500000      38.000000\n",
      "max    311.000000      55.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "1107D115     32\n",
      "1107D112     30\n",
      "1107D116     29\n",
      "1107D113     27\n",
      "1107D1136    15\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "     trip_id        arrival_time      departure_time  stop_id  stop_sequence  \\\n",
      "0  1107D1136 2025-08-11 06:00:00 2025-08-11 06:00:20      121              1   \n",
      "1  1107D1136 2025-08-11 06:00:34 2025-08-11 06:00:54      122              2   \n",
      "2   1107D116 2025-08-11 06:01:10 2025-08-11 06:01:30      123              3   \n",
      "3  1107D1136 2025-08-11 06:01:49 2025-08-11 06:02:09      124              4   \n",
      "4  1107D1136 2025-08-11 06:02:45 2025-08-11 06:03:05      125              5   \n",
      "\n",
      "   timepoint  \n",
      "0 1970-01-01  \n",
      "1 1970-01-01  \n",
      "2 1970-01-01  \n",
      "3 1970-01-01  \n",
      "4 1970-01-01  \n",
      "✓ Saved cleaned data to: cleaned_data\\lagos\\cleaned_stop_times.csv\n",
      "\n",
      "==================================================\n",
      "Processing: lagos\\trips.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (8, 6)\n",
      "\n",
      "Cleaning data for lagos\\trips.txt...\n",
      "  ✓ Cleaned data shape: (8, 6) → (8, 6)\n",
      "\n",
      "--- Analysis for lagos\\trips.txt ---\n",
      "Shape: (8, 6)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64     3\n",
      "object    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       route_id  direction_id  shape_id\n",
      "count   8.00000           8.0   8.00000\n",
      "mean   15.50000           1.0   4.50000\n",
      "std     2.44949           0.0   2.44949\n",
      "min    12.00000           1.0   1.00000\n",
      "25%    13.75000           1.0   2.75000\n",
      "50%    15.50000           1.0   4.50000\n",
      "75%    17.25000           1.0   6.25000\n",
      "max    19.00000           1.0   8.00000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "service_id:\n",
      "service_id\n",
      "MON-SUN    8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "1107D1136    1\n",
      "1107D111     1\n",
      "1107D112     1\n",
      "1107D113     1\n",
      "1107D114     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "trip_headsign:\n",
      "trip_headsign\n",
      "Ojuelegba     1\n",
      "Iju Ishaga    1\n",
      "Igando        1\n",
      "Ketu          1\n",
      "Onipanu       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   route_id service_id    trip_id trip_headsign  direction_id  shape_id\n",
      "0        12    MON-SUN  1107D1136     Ojuelegba             1         1\n",
      "1        13    MON-SUN   1107D111    Iju Ishaga             1         3\n",
      "2        14    MON-SUN   1107D112        Igando             1         5\n",
      "3        15    MON-SUN   1107D113          Ketu             1         2\n",
      "4        16    MON-SUN   1107D114       Onipanu             1         7\n",
      "✓ Saved cleaned data to: cleaned_data\\lagos\\cleaned_trips.csv\n",
      "\n",
      "==================================================\n",
      "Processing: nairobi\\agency.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 6)\n",
      "\n",
      "Cleaning data for nairobi\\agency.txt...\n",
      "  - Converted 'agency_timezone' to datetime\n",
      "  ✓ Cleaned data shape: (1, 6) → (1, 6)\n",
      "\n",
      "--- Analysis for nairobi\\agency.txt ---\n",
      "Shape: (1, 6)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "Missing values:\n",
      "agency_timezone    1\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "object            5\n",
      "datetime64[ns]    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "agency_id:\n",
      "agency_id\n",
      "UON    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_name:\n",
      "agency_name\n",
      "Approved SACCOs - University of Nairobi C4D Lab reporting/sharing    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_url:\n",
      "agency_url\n",
      "http://www.digitalmatatus.com    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_lang:\n",
      "agency_lang\n",
      "en    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_phone:\n",
      "agency_phone\n",
      "020 - 2729200    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  agency_id                                        agency_name  \\\n",
      "0       UON  Approved SACCOs - University of Nairobi C4D La...   \n",
      "\n",
      "                      agency_url agency_timezone agency_lang   agency_phone  \n",
      "0  http://www.digitalmatatus.com             NaT          en  020 - 2729200  \n",
      "✓ Saved cleaned data to: cleaned_data\\nairobi\\cleaned_agency.csv\n",
      "\n",
      "==================================================\n",
      "Processing: nairobi\\calendar.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 10)\n",
      "\n",
      "Cleaning data for nairobi\\calendar.txt...\n",
      "  - Converted 'start_date' to datetime\n",
      "  - Converted 'end_date' to datetime\n",
      "  ✓ Cleaned data shape: (1, 10) → (1, 10)\n",
      "\n",
      "--- Analysis for nairobi\\calendar.txt ---\n",
      "Shape: (1, 10)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64             7\n",
      "datetime64[ns]    2\n",
      "object            1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       monday  tuesday  wednesday  thursday  friday  saturday  sunday\n",
      "count     1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "mean      1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "std       NaN      NaN        NaN       NaN     NaN       NaN     NaN\n",
      "min       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "25%       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "50%       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "75%       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "max       1.0      1.0        1.0       1.0     1.0       1.0     1.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "service_id:\n",
      "service_id\n",
      "DAILY    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  service_id  monday  tuesday  wednesday  thursday  friday  saturday  sunday  \\\n",
      "0      DAILY       1        1          1         1       1         1       1   \n",
      "\n",
      "                     start_date                      end_date  \n",
      "0 1970-01-01 00:00:00.020190101 1970-01-01 00:00:00.020201231  \n",
      "✓ Saved cleaned data to: cleaned_data\\nairobi\\cleaned_calendar.csv\n",
      "\n",
      "==================================================\n",
      "Processing: nairobi\\calendar_dates.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (4, 3)\n",
      "\n",
      "Cleaning data for nairobi\\calendar_dates.txt...\n",
      "  - Converted 'date' to datetime\n",
      "  ✓ Cleaned data shape: (4, 3) → (4, 3)\n",
      "\n",
      "--- Analysis for nairobi\\calendar_dates.txt ---\n",
      "Shape: (4, 3)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object            1\n",
      "datetime64[ns]    1\n",
      "int64             1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       exception_type\n",
      "count             4.0\n",
      "mean              1.0\n",
      "std               0.0\n",
      "min               1.0\n",
      "25%               1.0\n",
      "50%               1.0\n",
      "75%               1.0\n",
      "max               1.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "service_id:\n",
      "service_id\n",
      "DAILY    4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  service_id                          date  exception_type\n",
      "0      DAILY 1970-01-01 00:00:00.020191020               1\n",
      "1      DAILY 1970-01-01 00:00:00.020191212               1\n",
      "2      DAILY 1970-01-01 00:00:00.020201020               1\n",
      "3      DAILY 1970-01-01 00:00:00.020201212               1\n",
      "✓ Saved cleaned data to: cleaned_data\\nairobi\\cleaned_calendar_dates.csv\n",
      "\n",
      "==================================================\n",
      "Processing: nairobi\\feed_info.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (1, 5)\n",
      "\n",
      "Cleaning data for nairobi\\feed_info.txt...\n",
      "  - Converted 'feed_start_date' to datetime\n",
      "  - Converted 'feed_end_date' to datetime\n",
      "  ✓ Cleaned data shape: (1, 5) → (1, 5)\n",
      "\n",
      "--- Analysis for nairobi\\feed_info.txt ---\n",
      "Shape: (1, 5)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object            3\n",
      "datetime64[ns]    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "feed_publisher_name:\n",
      "feed_publisher_name\n",
      "TRAINING    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_publisher_url:\n",
      "feed_publisher_url\n",
      "http://www.digitalmatatus.com/    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_lang:\n",
      "feed_lang\n",
      "en    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  feed_publisher_name              feed_publisher_url feed_lang  \\\n",
      "0            TRAINING  http://www.digitalmatatus.com/        en   \n",
      "\n",
      "                feed_start_date                 feed_end_date  \n",
      "0 1970-01-01 00:00:00.020120302 1970-01-01 00:00:00.020201231  \n",
      "✓ Saved cleaned data to: cleaned_data\\nairobi\\cleaned_feed_info.csv\n",
      "\n",
      "==================================================\n",
      "Processing: nairobi\\frequencies.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (792, 4)\n",
      "\n",
      "Cleaning data for nairobi\\frequencies.txt...\n",
      "  - Converted 'start_time' to datetime\n",
      "  - Converted 'end_time' to datetime\n",
      "  ✓ Cleaned data shape: (792, 4) → (792, 4)\n",
      "\n",
      "--- Analysis for nairobi\\frequencies.txt ---\n",
      "Shape: (792, 4)\n",
      "Memory usage: 0.07 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "datetime64[ns]    2\n",
      "object            1\n",
      "int64             1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       headway_secs\n",
      "count    792.000000\n",
      "mean     500.000000\n",
      "std      283.021444\n",
      "min      300.000000\n",
      "25%      300.000000\n",
      "50%      300.000000\n",
      "75%      900.000000\n",
      "max      900.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "10106110    3\n",
      "10106111    3\n",
      "10107110    3\n",
      "10107111    3\n",
      "10108110    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "    trip_id          start_time            end_time  headway_secs\n",
      "0  10106110 2025-08-11 06:00:00 2025-08-11 09:00:00           300\n",
      "1  10106110 2025-08-11 09:00:00 2025-08-11 15:00:00           900\n",
      "2  10106110 2025-08-11 15:00:00 2025-08-11 21:00:00           300\n",
      "3  10106111 2025-08-11 06:00:00 2025-08-11 09:00:00           300\n",
      "4  10106111 2025-08-11 09:00:00 2025-08-11 15:00:00           900\n",
      "✓ Saved cleaned data to: cleaned_data\\nairobi\\cleaned_frequencies.csv\n",
      "\n",
      "==================================================\n",
      "Processing: nairobi\\routes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (136, 5)\n",
      "\n",
      "Cleaning data for nairobi\\routes.txt...\n",
      "  ✓ Cleaned data shape: (136, 5) → (136, 5)\n",
      "\n",
      "--- Analysis for nairobi\\routes.txt ---\n",
      "Shape: (136, 5)\n",
      "Memory usage: 0.04 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object    4\n",
      "int64     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       route_type\n",
      "count       136.0\n",
      "mean          3.0\n",
      "std           0.0\n",
      "min           3.0\n",
      "25%           3.0\n",
      "50%           3.0\n",
      "75%           3.0\n",
      "max           3.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "route_id:\n",
      "route_id\n",
      "10000107D11    1\n",
      "10000114011    1\n",
      "10000116011    1\n",
      "10100011A11    1\n",
      "10200010811    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_id:\n",
      "agency_id\n",
      "UON    136\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_short_name:\n",
      "route_short_name\n",
      "107D    1\n",
      "114R    1\n",
      "116     1\n",
      "11A     1\n",
      "108     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_long_name:\n",
      "route_long_name\n",
      "Ruaka-Ruiru                       1\n",
      "Ngara-Rwaka-Ndenderu-Limuru       1\n",
      "Koja-Ngara-Banana-Limuru          1\n",
      "Odeon-Aga Khan-Highridge          1\n",
      "UN-New Muthaiga-Gachie-Gichagi    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "      route_id agency_id route_short_name                 route_long_name  \\\n",
      "0  10000107D11       UON             107D                     Ruaka-Ruiru   \n",
      "1  10000114011       UON             114R     Ngara-Rwaka-Ndenderu-Limuru   \n",
      "2  10000116011       UON              116        Koja-Ngara-Banana-Limuru   \n",
      "3  10100011A11       UON              11A        Odeon-Aga Khan-Highridge   \n",
      "4  10200010811       UON              108  UN-New Muthaiga-Gachie-Gichagi   \n",
      "\n",
      "   route_type  \n",
      "0           3  \n",
      "1           3  \n",
      "2           3  \n",
      "3           3  \n",
      "4           3  \n",
      "✓ Saved cleaned data to: cleaned_data\\nairobi\\cleaned_routes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: nairobi\\shapes.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (36483, 4)\n",
      "\n",
      "Cleaning data for nairobi\\shapes.txt...\n",
      "  - Capped 4354 outliers in 'shape_pt_lat'\n",
      "  - Capped 1724 outliers in 'shape_pt_lon'\n",
      "  - Capped 2827 outliers in 'shape_pt_sequence'\n",
      "  ✓ Cleaned data shape: (36483, 4) → (36483, 4)\n",
      "\n",
      "--- Analysis for nairobi\\shapes.txt ---\n",
      "Shape: (36483, 4)\n",
      "Memory usage: 3.10 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "float64    2\n",
      "object     1\n",
      "int64      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       shape_pt_lat  shape_pt_lon  shape_pt_sequence\n",
      "count  36483.000000  36483.000000       36483.000000\n",
      "mean      -1.272266     36.831952          94.687060\n",
      "std        0.038674      0.070877          77.974584\n",
      "min       -1.353856     36.673816           1.000000\n",
      "25%       -1.294335     36.799328          35.000000\n",
      "50%       -1.277171     36.830367          73.000000\n",
      "75%       -1.254654     36.883003         131.000000\n",
      "max       -1.195133     37.008514         275.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "shape_id:\n",
      "shape_id\n",
      "33738110    1239\n",
      "80114111     817\n",
      "10116110     623\n",
      "7046P111     481\n",
      "7046P110     421\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence\n",
      "0  10106110     -1.195133     36.758779                  1\n",
      "1  10106110     -1.195133     36.759025                  2\n",
      "2  10106110     -1.195133     36.759267                  3\n",
      "3  10106110     -1.195133     36.759535                  4\n",
      "4  10106110     -1.195133     36.759982                  5\n",
      "✓ Saved cleaned data to: cleaned_data\\nairobi\\cleaned_shapes.csv\n",
      "\n",
      "==================================================\n",
      "Processing: nairobi\\stops.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (4284, 6)\n",
      "\n",
      "Cleaning data for nairobi\\stops.txt...\n",
      "  - Dropped column 'location_type' (>70.0% missing)\n",
      "  - Dropped column 'parent_station' (>70.0% missing)\n",
      "  - Capped 349 outliers in 'stop_lat'\n",
      "  - Capped 4 outliers in 'stop_lon'\n",
      "  ✓ Cleaned data shape: (4284, 6) → (4284, 4)\n",
      "\n",
      "--- Analysis for nairobi\\stops.txt ---\n",
      "Shape: (4284, 4)\n",
      "Memory usage: 0.61 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object     2\n",
      "float64    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "          stop_lat     stop_lon\n",
      "count  4284.000000  4284.000000\n",
      "mean     -1.273121    36.824192\n",
      "std       0.051552     0.081622\n",
      "min      -1.388754    36.629579\n",
      "25%      -1.303790    36.765932\n",
      "50%      -1.275724    36.827780\n",
      "75%      -1.247147    36.887114\n",
      "max      -1.162182    37.068887\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "stop_id:\n",
      "stop_id\n",
      "0001RLW    1\n",
      "0002KOJ    1\n",
      "0003NGR    1\n",
      "0004ODN    1\n",
      "0005AMB    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "stop_name:\n",
      "stop_name\n",
      "Tuskys       23\n",
      "Car Wash     22\n",
      "Naivas       21\n",
      "Kwa Chief    19\n",
      "Equity       17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   stop_id           stop_name  stop_lat   stop_lon\n",
      "0  0001RLW            Railways -1.290884  36.828242\n",
      "1  0002KOJ                Koja -1.281230  36.822596\n",
      "2  0003NGR               Ngara -1.274395  36.823806\n",
      "3  0004ODN               Odeon -1.282769  36.825032\n",
      "4  0005AMB  Kencom/Ambassadeur -1.285963  36.826048\n",
      "✓ Saved cleaned data to: cleaned_data\\nairobi\\cleaned_stops.csv\n",
      "\n",
      "==================================================\n",
      "Processing: nairobi\\stop_times.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (7533, 5)\n",
      "\n",
      "Cleaning data for nairobi\\stop_times.txt...\n",
      "  - Converted 'arrival_time' to datetime\n",
      "  - Converted 'departure_time' to datetime\n",
      "  - Capped 146 outliers in 'stop_sequence'\n",
      "  ✓ Cleaned data shape: (7533, 5) → (7533, 5)\n",
      "\n",
      "--- Analysis for nairobi\\stop_times.txt ---\n",
      "Shape: (7533, 5)\n",
      "Memory usage: 1.10 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object            2\n",
      "datetime64[ns]    2\n",
      "float64           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       stop_sequence\n",
      "count    7533.000000\n",
      "mean       18.137528\n",
      "std        13.336553\n",
      "min         1.000000\n",
      "25%         7.000000\n",
      "50%        15.000000\n",
      "75%        26.000000\n",
      "max        54.500000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "70103110    81\n",
      "10114111    81\n",
      "10114110    70\n",
      "50126110    68\n",
      "80114110    67\n",
      "Name: count, dtype: int64\n",
      "\n",
      "stop_id:\n",
      "stop_id\n",
      "0212SNT    28\n",
      "0102KHJ    22\n",
      "0510AGP    20\n",
      "0512BST    17\n",
      "0212GRD    17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "    trip_id        arrival_time      departure_time  stop_id  stop_sequence\n",
      "0  10106110 2025-08-11 06:00:00 2025-08-11 06:00:20  0110BAA            1.0\n",
      "1  10106110 2025-08-11 06:00:34 2025-08-11 06:00:54  0110BNI            2.0\n",
      "2  10106110 2025-08-11 06:01:10 2025-08-11 06:01:30  0110UMK            3.0\n",
      "3  10106110 2025-08-11 06:01:49 2025-08-11 06:02:09  0110AEA            4.0\n",
      "4  10106110 2025-08-11 06:02:45 2025-08-11 06:03:05  0100MOM            5.0\n",
      "✓ Saved cleaned data to: cleaned_data\\nairobi\\cleaned_stop_times.csv\n",
      "\n",
      "==================================================\n",
      "Processing: nairobi\\trips.txt\n",
      "==================================================\n",
      "Loaded with separator ',': (272, 6)\n",
      "\n",
      "Cleaning data for nairobi\\trips.txt...\n",
      "  ✓ Cleaned data shape: (272, 6) → (272, 6)\n",
      "\n",
      "--- Analysis for nairobi\\trips.txt ---\n",
      "Shape: (272, 6)\n",
      "Memory usage: 0.09 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object    5\n",
      "int64     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       direction_id\n",
      "count    272.000000\n",
      "mean       0.496324\n",
      "std        0.500908\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        1.000000\n",
      "max        1.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "route_id:\n",
      "route_id\n",
      "10000107D11    2\n",
      "10000114011    2\n",
      "10000116011    2\n",
      "10100011A11    2\n",
      "10200010811    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "service_id:\n",
      "service_id\n",
      "DAILY    272\n",
      "Name: count, dtype: int64\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "1107D110    1\n",
      "1107D111    1\n",
      "10114110    1\n",
      "10114111    1\n",
      "10116110    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "trip_headsign:\n",
      "trip_headsign\n",
      "Odeon          17\n",
      "Bus Station    10\n",
      "Koja            8\n",
      "Kayole          7\n",
      "Commercial      7\n",
      "Name: count, dtype: int64\n",
      "\n",
      "shape_id:\n",
      "shape_id\n",
      "1107D110    1\n",
      "1107D111    1\n",
      "10114110    1\n",
      "10114111    1\n",
      "10116110    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "      route_id service_id   trip_id trip_headsign  direction_id  shape_id\n",
      "0  10000107D11      DAILY  1107D110         Ruaka             0  1107D110\n",
      "1  10000107D11      DAILY  1107D111         Ruiru             1  1107D111\n",
      "2  10000114011      DAILY  10114110         Ngara             0  10114110\n",
      "3  10000114011      DAILY  10114111        Limuru             1  10114111\n",
      "4  10000116011      DAILY  10116110          Koja             0  10116110\n",
      "✓ Saved cleaned data to: cleaned_data\\nairobi\\cleaned_trips.csv\n",
      "\n",
      "==================================================\n",
      "ATTEMPTING TO COMBINE CLEANED DATASETS BY FILE NAME\n",
      "==================================================\n",
      "Found 103 cleaned CSV files across cleaned_data; 14 groups\n",
      "\n",
      "Combining 11 files for 'agency.txt' with 4 common columns\n",
      "\n",
      "--- Analysis for Combined agency.txt ---\n",
      "Shape: (133, 4)\n",
      "Memory usage: 0.03 MB\n",
      "\n",
      "Missing values:\n",
      "agency_timezone    133\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "object     3\n",
      "float64    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       agency_timezone\n",
      "count              0.0\n",
      "mean               NaN\n",
      "std                NaN\n",
      "min                NaN\n",
      "25%                NaN\n",
      "50%                NaN\n",
      "75%                NaN\n",
      "max                NaN\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "agency_id:\n",
      "agency_id\n",
      "1                    2\n",
      "AA                   2\n",
      "Gbaka d'Abobo        1\n",
      "Gbaka d'Attécoubé    1\n",
      "Gbaka d'Adjamé       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_name:\n",
      "agency_name\n",
      "Woro-woro d'Attécoubé                                   3\n",
      "East Legon-La Bawaleshie-M-A-S-A GPRTU                  3\n",
      "Lapaz Branch of Tiger Transport Services Association    2\n",
      "Gbaka d'Attécoubé                                       1\n",
      "Gbaka de Cocody                                         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "agency_url:\n",
      "agency_url\n",
      "https://en.wikipedia.org/wiki/Ghana_Private_Road_Transport_Union    91\n",
      "https://data-transport.org                                          25\n",
      "https://digitaltransport4africa.org/                                 5\n",
      "http://www.whereismytransport.com                                    4\n",
      "https://addismaptransit.com/                                         2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "              agency_id           agency_name  agency_timezone  \\\n",
      "0         Gbaka d'Abobo         Gbaka d'Abobo              NaN   \n",
      "1        Gbaka d'Adjamé        Gbaka d'Adjamé              NaN   \n",
      "2     Gbaka d'Attécoubé     Gbaka d'Attécoubé              NaN   \n",
      "3  Gbaka de Bingerville  Gbaka de Bingerville              NaN   \n",
      "4       Gbaka de Cocody       Gbaka de Cocody              NaN   \n",
      "\n",
      "                   agency_url  \n",
      "0  https://data-transport.org  \n",
      "1  https://data-transport.org  \n",
      "2  https://data-transport.org  \n",
      "3  https://data-transport.org  \n",
      "4  https://data-transport.org  \n",
      "✓ Saved combined data to: combined_data\\agency.csv\n",
      "\n",
      "Combining 11 files for 'calendar.txt' with 10 common columns\n",
      "\n",
      "--- Analysis for Combined calendar.txt ---\n",
      "Shape: (13, 10)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64     7\n",
      "object    3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "          monday    tuesday  wednesday   thursday     friday   saturday  \\\n",
      "count  13.000000  13.000000  13.000000  13.000000  13.000000  13.000000   \n",
      "mean    0.923077   0.923077   0.923077   0.923077   0.923077   0.846154   \n",
      "std     0.277350   0.277350   0.277350   0.277350   0.277350   0.375534   \n",
      "min     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
      "25%     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
      "50%     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
      "75%     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
      "max     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
      "\n",
      "          sunday  \n",
      "count  13.000000  \n",
      "mean    0.846154  \n",
      "std     0.375534  \n",
      "min     0.000000  \n",
      "25%     1.000000  \n",
      "50%     1.000000  \n",
      "75%     1.000000  \n",
      "max     1.000000  \n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "service_id:\n",
      "service_id\n",
      "Ground_Daily    2\n",
      "0               2\n",
      "MON-SUN         2\n",
      "Mo-Su           1\n",
      "service         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "start_date:\n",
      "start_date\n",
      "1970-01-01 00:00:00.020230101    3\n",
      "1970-01-01 00:00:00.020191201    3\n",
      "1970-01-01 00:00:00.020180929    2\n",
      "1970-01-01 00:00:00.020150520    1\n",
      "1970-01-01 00:00:00.020181108    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "end_date:\n",
      "end_date\n",
      "1970-01-01 00:00:00.020991231    2\n",
      "1970-01-01 00:00:00.020191029    2\n",
      "1970-01-01 00:00:00.020231231    1\n",
      "1970-01-01 00:00:00.020170531    1\n",
      "1970-01-01 00:00:00.020231230    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "     service_id  monday  tuesday  wednesday  thursday  friday  saturday  \\\n",
      "0         Mo-Su       1        1          1         1       1         1   \n",
      "1       service       1        1          1         1       1         1   \n",
      "2             0       1        1          1         1       1         1   \n",
      "3             0       1        1          1         1       1         1   \n",
      "4  Ground_Daily       1        1          1         1       1         1   \n",
      "\n",
      "   sunday                     start_date                       end_date  \n",
      "0       1  1970-01-01 00:00:00.020230101  1970-01-01 00:00:00.020231231  \n",
      "1       1  1970-01-01 00:00:00.020150520  1970-01-01 00:00:00.020170531  \n",
      "2       1  1970-01-01 00:00:00.020191201  1970-01-01 00:00:00.020991231  \n",
      "3       1  1970-01-01 00:00:00.020191201  1970-01-01 00:00:00.020991231  \n",
      "4       1  1970-01-01 00:00:00.020230101  1970-01-01 00:00:00.020231230  \n",
      "✓ Saved combined data to: combined_data\\calendar.csv\n",
      "\n",
      "Combining 9 files for 'feed_info.txt' with 5 common columns\n",
      "\n",
      "--- Analysis for Combined feed_info.txt ---\n",
      "Shape: (9, 5)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object    5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "feed_publisher_name:\n",
      "feed_publisher_name\n",
      "Data Transport             2\n",
      "AddisMap + DT4A            2\n",
      "DigitalTransport4Africa    1\n",
      "WhereIsMyTransport         1\n",
      "Transport for Cairo        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_publisher_url:\n",
      "feed_publisher_url\n",
      "https://digitaltransport4africa.org/    3\n",
      "http://data-transport.org               1\n",
      "https://www.data-transport.org          1\n",
      "https://www.whereismytransport.com      1\n",
      "http://transportforcairo.com/           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_lang:\n",
      "feed_lang\n",
      "en    7\n",
      "fr    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_start_date:\n",
      "feed_start_date\n",
      "1970-01-01 00:00:00.020191201    3\n",
      "1970-01-01 00:00:00.020230101    2\n",
      "1970-01-01 00:00:00.020170920    1\n",
      "1970-01-01 00:00:00.020200101    1\n",
      "1970-01-01 00:00:00.020220101    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "feed_end_date:\n",
      "feed_end_date\n",
      "1970-01-01 00:00:00.020991231    2\n",
      "1970-01-01 00:00:00.020201231    2\n",
      "1970-01-01 00:00:00.020231231    1\n",
      "1970-01-01 00:00:00.020240101    1\n",
      "1970-01-01 00:00:00.020220131    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "       feed_publisher_name                    feed_publisher_url feed_lang  \\\n",
      "0           Data Transport             http://data-transport.org        fr   \n",
      "1          AddisMap + DT4A  https://digitaltransport4africa.org/        en   \n",
      "2          AddisMap + DT4A  https://digitaltransport4africa.org/        en   \n",
      "3  DigitalTransport4Africa  https://digitaltransport4africa.org/        en   \n",
      "4           Data Transport        https://www.data-transport.org        fr   \n",
      "\n",
      "                 feed_start_date                  feed_end_date  \n",
      "0  1970-01-01 00:00:00.020230101  1970-01-01 00:00:00.020231231  \n",
      "1  1970-01-01 00:00:00.020191201  1970-01-01 00:00:00.020991231  \n",
      "2  1970-01-01 00:00:00.020191201  1970-01-01 00:00:00.020991231  \n",
      "3  1970-01-01 00:00:00.020230101  1970-01-01 00:00:00.020240101  \n",
      "4  1970-01-01 00:00:00.020191201  1970-01-01 00:00:00.020220131  \n",
      "✓ Saved combined data to: combined_data\\feed_info.csv\n",
      "\n",
      "Combining 9 files for 'frequencies.txt' with 4 common columns\n",
      "\n",
      "--- Analysis for Combined frequencies.txt ---\n",
      "Shape: (9207, 4)\n",
      "Memory usage: 1.98 MB\n",
      "\n",
      "Missing values:\n",
      "end_time    2\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "object     3\n",
      "float64    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       headway_secs\n",
      "count   9207.000000\n",
      "mean     956.969806\n",
      "std      983.413437\n",
      "min       60.000000\n",
      "25%      361.500000\n",
      "50%      466.000000\n",
      "75%      900.000000\n",
      "max     3600.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "367    7\n",
      "366    7\n",
      "56     7\n",
      "57     7\n",
      "13     6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "start_time:\n",
      "start_time\n",
      "2025-08-11 05:00:00    2575\n",
      "2025-08-11 09:00:00     890\n",
      "2025-08-11 15:00:00     851\n",
      "2025-08-11 17:00:00     613\n",
      "2025-08-11 08:00:00     597\n",
      "Name: count, dtype: int64\n",
      "\n",
      "end_time:\n",
      "end_time\n",
      "2025-08-11 22:00:00    2541\n",
      "2025-08-11 09:00:00     883\n",
      "2025-08-11 15:00:00     851\n",
      "2025-08-11 23:00:00     832\n",
      "2025-08-11 17:00:00     627\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  trip_id           start_time             end_time  headway_secs\n",
      "0       0  2025-08-11 05:00:00  2025-08-11 22:00:00         900.0\n",
      "1       1  2025-08-11 05:00:00  2025-08-11 22:00:00         900.0\n",
      "2      10  2025-08-11 05:00:00  2025-08-11 22:00:00         600.0\n",
      "3     100  2025-08-11 05:00:00  2025-08-11 22:00:00         420.0\n",
      "4     101  2025-08-11 05:00:00  2025-08-11 22:00:00         420.0\n",
      "✓ Saved combined data to: combined_data\\frequencies.csv\n",
      "\n",
      "Combining 11 files for 'routes.txt' with 2 common columns\n",
      "\n",
      "--- Analysis for Combined routes.txt ---\n",
      "Shape: (3351, 2)\n",
      "Memory usage: 0.18 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object    1\n",
      "int64     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "        route_type\n",
      "count  3351.000000\n",
      "mean     24.423754\n",
      "std     120.323314\n",
      "min       3.000000\n",
      "25%       3.000000\n",
      "50%       3.000000\n",
      "75%       3.000000\n",
      "max     700.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "route_id:\n",
      "route_id\n",
      "16451917.5    96\n",
      "15531489.5    48\n",
      "15748561.5     8\n",
      "15880213.0     2\n",
      "15880308.0     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   route_id  route_type\n",
      "0  10179006           3\n",
      "1  10179435           3\n",
      "2  10184139           3\n",
      "3  10184730           3\n",
      "4  10184964           3\n",
      "✓ Saved combined data to: combined_data\\routes.csv\n",
      "\n",
      "Combining 11 files for 'shapes.txt' with 4 common columns\n",
      "\n",
      "--- Analysis for Combined shapes.txt ---\n",
      "Shape: (913583, 4)\n",
      "Memory usage: 58.89 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "float64    3\n",
      "object     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "        shape_pt_lat   shape_pt_lon  shape_pt_sequence\n",
      "count  913583.000000  913583.000000      913583.000000\n",
      "mean        7.736255      21.139005         139.126591\n",
      "std         5.412942      20.181209         120.149589\n",
      "min        -1.353856     -13.293041           0.000000\n",
      "25%         5.570723      -1.617610          48.000000\n",
      "50%         8.924558      32.611010         107.000000\n",
      "75%         9.021278      38.742850         197.000000\n",
      "max        31.321844      38.847198         940.125000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "shape_id:\n",
      "shape_id\n",
      "14521488.5    33775\n",
      "15748723.5     3720\n",
      "17039848.0     1488\n",
      "17039847.0     1463\n",
      "16004298.0     1314\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   shape_id  shape_pt_lat  shape_pt_lon  shape_pt_sequence\n",
      "0  10178669      5.353258     -4.014545                0.0\n",
      "1  10178669      5.353220     -4.014481                1.0\n",
      "2  10178669      5.353076     -4.014356                2.0\n",
      "3  10178669      5.352920     -4.014262                3.0\n",
      "4  10178669      5.352342     -4.014083                4.0\n",
      "✓ Saved combined data to: combined_data\\shapes.csv\n",
      "\n",
      "Combining 11 files for 'stops.txt' with 4 common columns\n",
      "\n",
      "--- Analysis for Combined stops.txt ---\n",
      "Shape: (21705, 4)\n",
      "Memory usage: 3.12 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object     2\n",
      "float64    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "           stop_lat      stop_lon\n",
      "count  21705.000000  21705.000000\n",
      "mean       6.176181     12.661616\n",
      "std        5.815572     20.639851\n",
      "min       -1.388754    -13.288040\n",
      "25%        0.394190     -4.052802\n",
      "50%        5.553484     -0.240606\n",
      "75%        9.012392     36.822240\n",
      "max       31.320357     38.873767\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "stop_id:\n",
      "stop_id\n",
      "6845041763.5    144\n",
      "228               3\n",
      "229               3\n",
      "261               3\n",
      "262               3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "stop_name:\n",
      "stop_name\n",
      "Arrêt            301\n",
      "Arrêt Sotrama     87\n",
      "Arret             84\n",
      "Mexico            57\n",
      "Megenagna         55\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "            stop_id            stop_name  stop_lat  stop_lon\n",
      "0  node/10218963489           Chez Rifat  5.349222 -3.975893\n",
      "1  node/10218963490     Carrefour garage  5.347851 -3.975529\n",
      "2  node/10218963491    Gorille carrefour  5.346528 -3.975153\n",
      "3  node/10218963492     Carrefour lavage  5.345986 -3.974986\n",
      "4  node/10218963494  Carrefour chefferie  5.341507 -3.974229\n",
      "✓ Saved combined data to: combined_data\\stops.csv\n",
      "\n",
      "Combining 11 files for 'stop_times.txt' with 5 common columns\n",
      "\n",
      "--- Analysis for Combined stop_times.txt ---\n",
      "Shape: (201879, 5)\n",
      "Memory usage: 58.78 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object     4\n",
      "float64    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       stop_sequence\n",
      "count  201879.000000\n",
      "mean       18.684373\n",
      "std        15.719097\n",
      "min         0.000000\n",
      "25%         6.000000\n",
      "50%        14.000000\n",
      "75%        27.000000\n",
      "max        91.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "TI1577354850    138\n",
      "TI1577202076    125\n",
      "TI1577107909    122\n",
      "TI1577202479    114\n",
      "TI1577027873    114\n",
      "Name: count, dtype: int64\n",
      "\n",
      "stop_id:\n",
      "stop_id\n",
      "6992410712.125            1521\n",
      "6922905989.125             974\n",
      "veto.swimsuits.unveils     448\n",
      "fidgeting.prongs.nerve     384\n",
      "loaning.learns.sleepy      384\n",
      "Name: count, dtype: int64\n",
      "\n",
      "arrival_time:\n",
      "arrival_time\n",
      "2025-08-11 06:00:00    2629\n",
      "2025-08-11 00:00:03    1269\n",
      "2025-08-11 08:00:00     864\n",
      "2025-08-11 06:30:00     664\n",
      "2025-08-11 09:00:00     590\n",
      "Name: count, dtype: int64\n",
      "\n",
      "departure_time:\n",
      "departure_time\n",
      "2025-08-11 06:00:00    2353\n",
      "2025-08-11 00:01:03    1269\n",
      "2025-08-11 06:30:15     594\n",
      "2025-08-11 09:00:15     591\n",
      "2025-08-11 08:00:15     591\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  trip_id           stop_id  stop_sequence         arrival_time  \\\n",
      "0       0  node/10591673049            7.0  2025-08-11 07:49:56   \n",
      "1       0  node/10591673050            6.0  2025-08-11 07:45:08   \n",
      "2       0  node/10591673051            4.0  2025-08-11 07:38:38   \n",
      "3       0  node/10855579565            3.0  2025-08-11 07:37:14   \n",
      "4       0  node/10863748340           11.0  2025-08-11 08:00:00   \n",
      "\n",
      "        departure_time  \n",
      "0  2025-08-11 07:49:56  \n",
      "1  2025-08-11 07:45:08  \n",
      "2  2025-08-11 07:38:38  \n",
      "3  2025-08-11 07:37:14  \n",
      "4  2025-08-11 08:00:00  \n",
      "✓ Saved combined data to: combined_data\\stop_times.csv\n",
      "\n",
      "Combining 11 files for 'trips.txt' with 4 common columns\n",
      "\n",
      "--- Analysis for Combined trips.txt ---\n",
      "Shape: (9454, 4)\n",
      "Memory usage: 2.17 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object    4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "route_id:\n",
      "route_id\n",
      "16466920      191\n",
      "15522608       96\n",
      "taxi_WA004     16\n",
      "taxi_IC110     16\n",
      "taxi_KA056     16\n",
      "Name: count, dtype: int64\n",
      "\n",
      "service_id:\n",
      "service_id\n",
      "Ground_Daily    4888\n",
      "0               1373\n",
      "Mo-Su            980\n",
      "1                668\n",
      "service          651\n",
      "Name: count, dtype: int64\n",
      "\n",
      "shape_id:\n",
      "shape_id\n",
      "16379695              191\n",
      "15559623              126\n",
      "15736031               16\n",
      "taxi_KA130_O_shape      8\n",
      "taxi_KA048_O_shape      8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "trip_id:\n",
      "trip_id\n",
      "9      4\n",
      "89     4\n",
      "101    4\n",
      "90     4\n",
      "97     4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   route_id service_id  shape_id trip_id\n",
      "0  10179006      Mo-Su  10178669       0\n",
      "1  10179006      Mo-Su  10178996       1\n",
      "2  10185142      Mo-Su  10185123      10\n",
      "3  10461146      Mo-Su  10474251     100\n",
      "4  10461146      Mo-Su  10474250     101\n",
      "✓ Saved combined data to: combined_data\\trips.csv\n",
      "\n",
      "Only one cleaned file for 'agency-checkpoint.txt', saving as combined output\n",
      "\n",
      "--- Analysis for Combined agency-checkpoint.txt ---\n",
      "Shape: (25, 1)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "Missing values:\n",
      "agency_id_agency_name_agency_lang_agency_timezone_agency_url_agency_phone_agency_email_agency_fare_url    25\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "float64    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       agency_id_agency_name_agency_lang_agency_timezone_agency_url_agency_phone_agency_email_agency_fare_url\n",
      "count                                                0.0                                                     \n",
      "mean                                                 NaN                                                     \n",
      "std                                                  NaN                                                     \n",
      "min                                                  NaN                                                     \n",
      "25%                                                  NaN                                                     \n",
      "50%                                                  NaN                                                     \n",
      "75%                                                  NaN                                                     \n",
      "max                                                  NaN                                                     \n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   agency_id_agency_name_agency_lang_agency_timezone_agency_url_agency_phone_agency_email_agency_fare_url\n",
      "0                                                NaN                                                     \n",
      "1                                                NaN                                                     \n",
      "2                                                NaN                                                     \n",
      "3                                                NaN                                                     \n",
      "4                                                NaN                                                     \n",
      "✓ Saved combined data to: combined_data\\agency-checkpoint.csv\n",
      "\n",
      "Combining 2 files for 'fare_attributes.txt' with 4 common columns\n",
      "\n",
      "--- Analysis for Combined fare_attributes.txt ---\n",
      "Shape: (134, 4)\n",
      "Memory usage: 0.02 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object     2\n",
      "float64    1\n",
      "int64      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "             price  payment_method\n",
      "count   134.000000           134.0\n",
      "mean   1631.123507             0.0\n",
      "std    1246.377137             0.0\n",
      "min       0.500000             0.0\n",
      "25%    1500.000000             0.0\n",
      "50%    1500.000000             0.0\n",
      "75%    2000.000000             0.0\n",
      "max    5250.000000             0.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "fare_id:\n",
      "fare_id\n",
      "fare_00    1\n",
      "fare_01    1\n",
      "fare_02    1\n",
      "fare_03    1\n",
      "fare_04    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "currency_type:\n",
      "currency_type\n",
      "SLL    103\n",
      "CAD     31\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   fare_id  price currency_type  payment_method\n",
      "0  fare_00    0.5           CAD               0\n",
      "1  fare_01    0.7           CAD               0\n",
      "2  fare_02    0.8           CAD               0\n",
      "3  fare_03    0.9           CAD               0\n",
      "4  fare_04    1.0           CAD               0\n",
      "✓ Saved combined data to: combined_data\\fare_attributes.csv\n",
      "\n",
      "Combining 2 files for 'fare_rules.txt' with 2 common columns\n",
      "\n",
      "--- Analysis for Combined fare_rules.txt ---\n",
      "Shape: (711, 2)\n",
      "Memory usage: 0.09 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "route_id:\n",
      "route_id\n",
      "002A    1\n",
      "002B    1\n",
      "003A    1\n",
      "003B    1\n",
      "004B    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "fare_id:\n",
      "fare_id\n",
      "fare_09    72\n",
      "fare_07    69\n",
      "fare_14    68\n",
      "fare_08    65\n",
      "fare_06    59\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "  route_id  fare_id\n",
      "0     002A  fare_06\n",
      "1     002B  fare_06\n",
      "2     003A  fare_07\n",
      "3     003B  fare_07\n",
      "4     004B  fare_25\n",
      "✓ Saved combined data to: combined_data\\fare_rules.csv\n",
      "\n",
      "Combining 2 files for 'calendar_dates.txt' with 3 common columns\n",
      "\n",
      "--- Analysis for Combined calendar_dates.txt ---\n",
      "Shape: (5, 3)\n",
      "Memory usage: 0.00 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "object    2\n",
      "int64     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "       exception_type\n",
      "count        5.000000\n",
      "mean         1.200000\n",
      "std          0.447214\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          1.000000\n",
      "75%          1.000000\n",
      "max          2.000000\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "service_id:\n",
      "service_id\n",
      "DAILY           4\n",
      "Ground_Daily    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "date:\n",
      "date\n",
      "1970-01-01 00:00:00.020170104    1\n",
      "1970-01-01 00:00:00.020191020    1\n",
      "1970-01-01 00:00:00.020191212    1\n",
      "1970-01-01 00:00:00.020201020    1\n",
      "1970-01-01 00:00:00.020201212    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "     service_id                           date  exception_type\n",
      "0  Ground_Daily  1970-01-01 00:00:00.020170104               2\n",
      "1         DAILY  1970-01-01 00:00:00.020191020               1\n",
      "2         DAILY  1970-01-01 00:00:00.020191212               1\n",
      "3         DAILY  1970-01-01 00:00:00.020201020               1\n",
      "4         DAILY  1970-01-01 00:00:00.020201212               1\n",
      "✓ Saved combined data to: combined_data\\calendar_dates.csv\n",
      "\n",
      "Only one cleaned file for 'routes_enriched.txt', saving as combined output\n",
      "\n",
      "--- Analysis for Combined routes_enriched.txt ---\n",
      "Shape: (668, 4)\n",
      "Memory usage: 0.10 MB\n",
      "\n",
      "✓ No missing values!\n",
      "\n",
      "Data types:\n",
      "int64     2\n",
      "object    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric columns summary:\n",
      "          route_id  route_type\n",
      "count   668.000000       668.0\n",
      "mean    635.667665         3.0\n",
      "std     318.228936         0.0\n",
      "min       9.000000         3.0\n",
      "25%     386.750000         3.0\n",
      "50%     662.500000         3.0\n",
      "75%     866.250000         3.0\n",
      "max    1223.000000         3.0\n",
      "\n",
      "Categorical columns (top 5 each):\n",
      "\n",
      "route_short_name:\n",
      "route_short_name\n",
      "3304_AB    1\n",
      "3304_BA    1\n",
      "3305_AB    1\n",
      "3305_BA    1\n",
      "3601_AB    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "route_long_name:\n",
      "route_long_name\n",
      "Abuakwa Terminal - Suame Roundabout    6\n",
      "Suame Roundabout - Abuakwa Terminal    6\n",
      "Santasi Station - Ahenema Kokobin      5\n",
      "Tafo 4 Miles - Kwabese East            4\n",
      "Sofoline - Tanoso                      4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data (first 5 rows):\n",
      "   route_id route_short_name                  route_long_name  route_type\n",
      "0         9          3304_AB   Nhyieaso Station - Kumasi Mall           3\n",
      "1        10          3304_BA   Kumasi Mall - Nhyieaso Station           3\n",
      "2        11          3305_AB        Nhyieaso Station - Sobolo           3\n",
      "3        12          3305_BA                  Sobolo - Kuwait           3\n",
      "4        25          3601_AB  Santasi Roundabo - Sanasi Eset1           3\n",
      "✓ Saved combined data to: combined_data\\routes_enriched.csv\n",
      "\n",
      "==================================================\n",
      "DATA CLEANING COMPLETE!\n",
      "Finished at: 2025-08-11 02:58:22\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Enhanced TroTro Dataset Cleaning and Analysis\n",
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=== TroTro Dataset Cleaning and Analysis ===\")\n",
    "print(f\"Starting analysis at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# 1. Download dataset with error handling\n",
    "def download_dataset():\n",
    "    \"\"\"Download the TroTro dataset from Kaggle\"\"\"\n",
    "    try:\n",
    "        dataset_url = 'https://www.kaggle.com/datasets/godfredaddaiamoako/trotro'\n",
    "        print(\"Downloading dataset...\")\n",
    "        od.download(dataset_url)\n",
    "        print(\"✓ Dataset downloaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Error downloading dataset: {e}\")\n",
    "        print(\"Please ensure you have Kaggle credentials configured\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# 2. Enhanced data cleaning function\n",
    "def clean_data(df, filename=\"\"):\n",
    "    \"\"\"Comprehensive data cleaning function\"\"\"\n",
    "    print(f\"\\nCleaning data for {filename}...\")\n",
    "    original_shape = df.shape\n",
    "    \n",
    "    # Create a copy to avoid modifying original\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # 1. Remove completely empty rows and columns\n",
    "    df_clean = df_clean.dropna(how='all').dropna(axis=1, how='all')\n",
    "    \n",
    "    # 2. Clean column names\n",
    "    df_clean.columns = df_clean.columns.str.strip().str.lower()\n",
    "    df_clean.columns = df_clean.columns.str.replace(' ', '_').str.replace(r'[^\\w]', '_', regex=True)\n",
    "    \n",
    "    # 3. Handle duplicates\n",
    "    initial_rows = len(df_clean)\n",
    "    df_clean = df_clean.drop_duplicates()\n",
    "    duplicates_removed = initial_rows - len(df_clean)\n",
    "    if duplicates_removed > 0:\n",
    "        print(f\"  - Removed {duplicates_removed} duplicate rows\")\n",
    "    \n",
    "    # 4. Clean text columns\n",
    "    text_columns = df_clean.select_dtypes(include=['object']).columns\n",
    "    for col in text_columns:\n",
    "        if col in df_clean.columns:\n",
    "            # Strip whitespace and handle common issues\n",
    "            df_clean[col] = df_clean[col].astype(str).str.strip()\n",
    "            df_clean[col] = df_clean[col].replace(['nan', 'NaN', 'None', ''], np.nan)\n",
    "            \n",
    "            # Clean special characters and normalize text\n",
    "            df_clean[col] = df_clean[col].str.replace(r'\\s+', ' ', regex=True)\n",
    "            \n",
    "    # 5. Handle missing values intelligently\n",
    "    missing_threshold = 0.7  # Drop columns with >70% missing data\n",
    "    for col in df_clean.columns:\n",
    "        missing_pct = df_clean[col].isnull().sum() / len(df_clean)\n",
    "        if missing_pct > missing_threshold:\n",
    "            print(f\"  - Dropped column '{col}' (>{missing_threshold*100}% missing)\")\n",
    "            df_clean = df_clean.drop(columns=[col])\n",
    "    \n",
    "    # 6. Fill remaining missing values based on data type\n",
    "    for col in df_clean.columns:\n",
    "        if df_clean[col].isnull().any():\n",
    "            if df_clean[col].dtype in ['int64', 'float64']:\n",
    "                # For numeric columns, use median\n",
    "                df_clean[col] = df_clean[col].fillna(df_clean[col].median())\n",
    "            else:\n",
    "                # For categorical columns, use mode or 'Unknown'\n",
    "                mode_val = df_clean[col].mode()\n",
    "                if len(mode_val) > 0:\n",
    "                    df_clean[col] = df_clean[col].fillna(mode_val[0])\n",
    "                else:\n",
    "                    df_clean[col] = df_clean[col].fillna('Unknown')\n",
    "    \n",
    "    # 7. Detect and handle potential date columns\n",
    "    potential_date_cols = [col for col in df_clean.columns if 'date' in col.lower() or 'time' in col.lower()]\n",
    "    for col in potential_date_cols:\n",
    "        try:\n",
    "            df_clean[col] = pd.to_datetime(df_clean[col], errors='coerce')\n",
    "            print(f\"  - Converted '{col}' to datetime\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # 8. Clean numeric columns\n",
    "    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        # Remove outliers using IQR method\n",
    "        Q1 = df_clean[col].quantile(0.25)\n",
    "        Q3 = df_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers_before = len(df_clean[(df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)])\n",
    "        df_clean[col] = df_clean[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "        if outliers_before > 0:\n",
    "            print(f\"  - Capped {outliers_before} outliers in '{col}'\")\n",
    "    \n",
    "    print(f\"  ✓ Cleaned data shape: {original_shape} → {df_clean.shape}\")\n",
    "    return df_clean\n",
    "\n",
    "# 3. Data analysis function\n",
    "def analyze_data(df, filename=\"\"):\n",
    "    \"\"\"Perform comprehensive data analysis\"\"\"\n",
    "    print(f\"\\n--- Analysis for {filename} ---\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Missing values analysis\n",
    "    missing_data = df.isnull().sum()\n",
    "    if missing_data.sum() > 0:\n",
    "        print(\"\\nMissing values:\")\n",
    "        print(missing_data[missing_data > 0])\n",
    "    else:\n",
    "        print(\"\\n✓ No missing values!\")\n",
    "    \n",
    "    # Data types\n",
    "    print(f\"\\nData types:\")\n",
    "    print(df.dtypes.value_counts())\n",
    "    \n",
    "    # Numeric columns summary\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(f\"\\nNumeric columns summary:\")\n",
    "        print(df[numeric_cols].describe())\n",
    "    \n",
    "    # Categorical columns info\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    if len(categorical_cols) > 0:\n",
    "        print(f\"\\nCategorical columns (top 5 each):\")\n",
    "        for col in categorical_cols[:5]:  # Limit to first 5 to avoid clutter\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(df[col].value_counts().head())\n",
    "    \n",
    "    # Display sample\n",
    "    print(f\"\\nSample data (first 5 rows):\")\n",
    "    print(df.head())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 4. Main execution\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    \n",
    "    # Download dataset\n",
    "    if not download_dataset():\n",
    "        print(\"Failed to download dataset. Please check your Kaggle credentials.\")\n",
    "        return\n",
    "    \n",
    "    # ------------------------------------------\n",
    "    # 1. FIND DATA DIRECTORY\n",
    "    # ------------------------------------------\n",
    "    data_dir = './trotro/trotrolive-datasets'\n",
    "    if not os.path.exists(data_dir):\n",
    "        possible_dirs = [d for d in os.listdir('.') if 'trotro' in d.lower()]\n",
    "        if possible_dirs:\n",
    "            data_dir = possible_dirs[0]\n",
    "        else:\n",
    "            print(\"Could not find dataset directory\")\n",
    "            exit()\n",
    "    \n",
    "    print(f\"Using data directory: {data_dir}\")\n",
    "    \n",
    "    # ------------------------------------------\n",
    "    # 2. FIND TXT FILES (RECURSIVE)\n",
    "    # ------------------------------------------\n",
    "    try:\n",
    "        data_files = []\n",
    "        for root, _, files in os.walk(data_dir):\n",
    "            for f in files:\n",
    "                if f.endswith('.txt'):\n",
    "                    rel_path = os.path.relpath(os.path.join(root, f), data_dir)\n",
    "                    data_files.append(rel_path)\n",
    "        print(f\"Found {len(data_files)} TXT files.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing data directory: {e}\")\n",
    "        exit()\n",
    "    \n",
    "    if not data_files:\n",
    "        print(\"No TXT files found in the directory\")\n",
    "        exit()\n",
    "    \n",
    "    # ------------------------------------------\n",
    "    # 3. CLEAN AND SAVE CSVs (MIRROR FOLDER STRUCTURE)\n",
    "    # ------------------------------------------\n",
    "    for file in data_files:\n",
    "        try:\n",
    "            file_path = os.path.join(data_dir, file)\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Processing: {file}\")\n",
    "            print(f\"{'='*50}\")\n",
    "    \n",
    "            # Try multiple separators — validate that parsing actually worked\n",
    "            possible_separators = [\"\\t\", \",\", \"|\", r\"\\s+\"]\n",
    "            df = None\n",
    "            for sep in possible_separators:\n",
    "                try:\n",
    "                    if sep == r\"\\s+\":\n",
    "                        temp_df = pd.read_csv(file_path, sep=sep, engine=\"python\")\n",
    "                    else:\n",
    "                        temp_df = pd.read_csv(file_path, sep=sep)\n",
    "    \n",
    "                    # Check if we got multiple columns\n",
    "                    if temp_df.shape[1] > 1:\n",
    "                        df = temp_df\n",
    "                        print(f\"Loaded with separator {repr(sep)}: {df.shape}\")\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "    \n",
    "            if df is None or df.empty:\n",
    "                print(f\"⚠ Warning: {file} could not be parsed into multiple columns\")\n",
    "                continue\n",
    "    \n",
    "            # Clean\n",
    "            df_clean = clean_data(df, file)\n",
    "    \n",
    "            # Analyze\n",
    "            analyze_data(df_clean, file)\n",
    "    \n",
    "            # Build output path mirroring original folder structure\n",
    "            cleaned_filename = f'cleaned_{os.path.basename(file).replace(\".txt\", \".csv\")}'\n",
    "            output_path = os.path.join(\"cleaned_data\", os.path.dirname(file), cleaned_filename)\n",
    "    \n",
    "            # Ensure folder exists\n",
    "            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "            # Save\n",
    "            df_clean.to_csv(output_path, index=False)\n",
    "            print(f\"✓ Saved cleaned data to: {output_path}\")\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    \n",
    "    # ------------------------------------------\n",
    "    # 4. COMBINE CLEANED CSV FILES BY BASE NAME\n",
    "    # ------------------------------------------\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"ATTEMPTING TO COMBINE CLEANED DATASETS BY FILE NAME\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    grouped_cleaned = {}\n",
    "    cleaned_root = \"cleaned_data\"\n",
    "    \n",
    "    if not os.path.exists(cleaned_root):\n",
    "        print(\"No cleaned_data directory found, skipping combine step\")\n",
    "    else:\n",
    "        total_found = 0\n",
    "        for root, _, files in os.walk(cleaned_root):\n",
    "            for f in files:\n",
    "                if not f.lower().endswith(\".csv\"):\n",
    "                    continue\n",
    "                total_found += 1\n",
    "                file_path = os.path.join(root, f)\n",
    "    \n",
    "                # Match back to original TXT filename\n",
    "                filename = f\n",
    "                if filename.startswith(\"cleaned_\"):\n",
    "                    filename = filename[len(\"cleaned_\"):]\n",
    "                base_name = os.path.splitext(filename)[0] + \".txt\"\n",
    "    \n",
    "                try:\n",
    "                    df = pd.read_csv(file_path, sep=\",\")  # Ensure correct delimiter\n",
    "                    grouped_cleaned.setdefault(base_name, []).append(df)\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Error loading cleaned CSV {file_path}: {e}\")\n",
    "    \n",
    "        print(f\"Found {total_found} cleaned CSV files across cleaned_data; {len(grouped_cleaned)} groups\")\n",
    "    \n",
    "        # ------------------------------------------\n",
    "        # 5. COMBINE PER FILE GROUP\n",
    "        # ------------------------------------------\n",
    "        for base_name, df_list in grouped_cleaned.items():\n",
    "            try:\n",
    "                if len(df_list) > 1:\n",
    "                    all_columns = [set(df.columns) for df in df_list]\n",
    "                    common_columns = set.intersection(*all_columns)\n",
    "                else:\n",
    "                    common_columns = set(df_list[0].columns)\n",
    "    \n",
    "                if not common_columns:\n",
    "                    print(f\"⚠ No common columns found for '{base_name}' - skipping\")\n",
    "                    continue\n",
    "    \n",
    "                if len(df_list) > 1:\n",
    "                    print(f\"\\nCombining {len(df_list)} files for '{base_name}' with {len(common_columns)} common columns\")\n",
    "                else:\n",
    "                    print(f\"\\nOnly one cleaned file for '{base_name}', saving as combined output\")\n",
    "    \n",
    "                # Keep column order from first DF\n",
    "                reference_df = df_list[0]\n",
    "                common_cols_ordered = [c for c in reference_df.columns if c in common_columns]\n",
    "    \n",
    "                combined_dfs = [df[common_cols_ordered].copy() for df in df_list]\n",
    "                combined_data = pd.concat(combined_dfs, ignore_index=True)\n",
    "    \n",
    "                # Analyze\n",
    "                analyze_data(combined_data, f\"Combined {base_name}\")\n",
    "    \n",
    "                # Save\n",
    "                os.makedirs(\"combined_data\", exist_ok=True)\n",
    "                combined_filename = os.path.splitext(base_name)[0] + \".csv\"\n",
    "                combined_path = os.path.join(\"combined_data\", combined_filename)\n",
    "                combined_data.to_csv(combined_path, index=False)\n",
    "                print(f\"✓ Saved combined data to: {combined_path}\")\n",
    "    \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error combining datasets for '{base_name}': {e}\")\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"DATA CLEANING COMPLETE!\")\n",
    "    print(f\"Finished at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed29655-2e1b-41e0-ac27-70d64a1f90b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
